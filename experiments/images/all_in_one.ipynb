{"cells":[{"cell_type":"markdown","metadata":{"id":"E0XqgiuFQChU"},"source":["## Metrics Classes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2017,"status":"ok","timestamp":1668400317864,"user":{"displayName":"himangshu bhantana","userId":"00316151722707244448"},"user_tz":300},"id":"jrYFj1hUMLGz","outputId":"aa20fce5-af8a-41fe-a165-d6ef3f8e7ec8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Proofpoint\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/Proofpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14468,"status":"ok","timestamp":1668431050517,"user":{"displayName":"himangshu bhantana","userId":"00316151722707244448"},"user_tz":300},"id":"0HNYgwCALVxO","outputId":"27b60c19-f33f-4257-e767-43f7a8ff17cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 17.0 MB 30.9 MB/s \n","\u001b[K     |████████████████████████████████| 209 kB 92.8 MB/s \n","\u001b[K     |████████████████████████████████| 79 kB 3.6 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 77.8 MB/s \n","\u001b[K     |████████████████████████████████| 77 kB 7.0 MB/s \n","\u001b[K     |████████████████████████████████| 147 kB 84.6 MB/s \n","\u001b[K     |████████████████████████████████| 78 kB 7.7 MB/s \n","\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 140 kB 102.3 MB/s \n","\u001b[K     |████████████████████████████████| 55 kB 3.9 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n","\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install mlflow --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"opvxTwtWLRgl"},"outputs":[],"source":["import torch\n","from torchsummary import summary\n","import torchvision\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import mlflow\n","import mlflow.sklearn\n","import sys\n","import os\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0I5JDskO01c3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUJXNI7i-twc"},"outputs":[],"source":["\"\"\"\n","This script contains functions and classes to compute churn metrics\n","UNTESTED\n","\"\"\"\n","\n","import numpy as np\n","import torch\n","from typing import Union\n","\n","class ChurnMetric:\n","    \"\"\"\n","    Super class for metrics. \n","    \"\"\"\n","    def __init__(self, tensor_type=\"numpy\") -\u003e None:\n","        tensor_types = {\"numpy\": np.ndarray, \"torch\": torch.Tensor}\n","        if tensor_type not in tensor_types:\n","            raise NotImplementedError(\"Unknown object type\")\n","        self.tensor_type = tensor_types[tensor_type]\n","    \n","    def call_sanitize_inputs(self, **preds):\n","        \"\"\"\n","        preds can be true labels as well\n","        Shape of tensors need to be the same.\n","        Tensor dim len must not be \u003e2\n","        \"\"\"\n","        for p in preds:\n","            if not isinstance(preds[p], self.tensor_type):\n","                raise TypeError(f\"{p} is not an instance of {str(self.tensor_type)}\")\n","            if len(preds[p].shape) \u003e 2:\n","                raise ValueError(f\"Too many dims in {p}\")\n","        shapes = set([preds[p].shape for p in preds])\n","        if len(shapes) \u003e 1: #TODO extend to force only first dim to be the same\n","            raise ValueError(f\"shape mismatch. shapes of preds must be same\")\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AG_sFp6TO_6j"},"outputs":[],"source":["class Churn(ChurnMetric):\n","    \"\"\"\n","    Simple Churn. Calculates number of classification disagreements, along axis:0. \n","    Will take argmax if multiple columns.\n","    \"\"\"\n","    def __init__(self, tensor_type=\"numpy\", output_mode=\"proportion\") -\u003e None:\n","        super().__init__(tensor_type=tensor_type)\n","        if output_mode not in {\"proportion\", \"count\"}:\n","            raise ValueError(\"Unknown output_mode\")\n","        self.output_mode = output_mode\n","    \n","    def __call__(self, predA: Union[np.ndarray, torch.Tensor], predB:Union[np.ndarray, torch.Tensor]) -\u003e None:\n","        self.call_sanitize_inputs(predA=predA, predB=predB)\n","        \n","        if len(predA.shape) \u003e 1:\n","            predA = predA.argmax(1)\n","            predB = predB.argmax(1)\n","        \n","        churn = sum(predA!=predB)\n","\n","        if self.output_mode == \"proportion\":\n","            return churn / predA.shape[0]\n","        if self.output_mode == \"count\":\n","            return churn\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lgTqDjtCPNNO"},"outputs":[],"source":["class WinLossRatio(ChurnMetric):\n","    \"\"\"\n","    Lateral Churns are not loss\n","    \"\"\"\n","    def __init__(self, tensor_type=\"numpy\") -\u003e None:\n","        super().__init__(tensor_type)\n","    \n","    def __call__(self, true_labels, pred_teacher, pred_student):\n","        self.call_sanitize_inputs(true_labels=true_labels, pred_teacher=pred_teacher, pred_student=pred_student)\n","\n","        if len(pred_teacher.shape) \u003e 1:\n","            pred_teacher = pred_teacher.argmax(1)\n","            pred_student = pred_student.argmax(1)\n","            true_labels = true_labels.argmax(1)\n","\n","        pred_teacher = pred_teacher == true_labels\n","        pred_student = pred_student == true_labels\n","        wins = sum(pred_student \u003e pred_teacher)\n","        losses = sum(pred_student \u003c pred_teacher)\n","\n","        return wins , losses\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nPfWVkJePQ6x"},"outputs":[],"source":["\n","class ChurnRatio(ChurnMetric):\n","    def __init__(self, tensor_type=\"numpy\") -\u003e None:\n","        super().__init__(tensor_type)\n","    \n","    def __call__(self, pred_teacher, pred_student, pred_control):\n","        self.call_sanitize_inputs(pred_teacher, pred_student, pred_control)\n","        \n","        pred_teacher = pred_teacher.argmax(1)\n","        pred_student = pred_student.argmax(1)\n","        pred_control = pred_control.argmax(1)\n","\n","        churnratio = sum(pred_student!=pred_teacher) / sum(pred_control!=pred_teacher)\n","        return churnratio\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXNRTe0CPUD4"},"outputs":[],"source":["class GoodBadChurn(ChurnMetric):\n","    \"\"\"\n","    lateral churn is bad\n","    \"\"\"\n","    def __init__(self, tensor_type=\"numpy\", mode=None, output_mode=\"proportion\") -\u003e None:\n","        super().__init__(tensor_type)\n","        if mode is None or mode not in {\"good\", \"bad\"}:\n","            raise ValueError(\"Please specify mode as good or bad\")\n","        self.mode = mode\n","        if output_mode not in {\"proportion\", \"count\"}:\n","            raise ValueError(\"Unknown output_mode\")\n","        self.output_mode = output_mode\n","\n","    def __call__(self, true_labels, pred_teacher, pred_student):\n","        self.call_sanitize_inputs(true_labels=true_labels, pred_teacher=pred_teacher, pred_student=pred_student)\n","        \n","        pred_teacher = pred_teacher.argmax(1)\n","        pred_student = pred_student.argmax(1)\n","        true_labels = true_labels.argmax(1)\n","\n","        \n","        if self.mode == \"good\":\n","            pred_teacher = pred_teacher == true_labels\n","            pred_student = pred_student == true_labels    \n","            churn = sum(pred_student \u003e pred_teacher)\n","        elif self.mode == \"bad\":\n","            churn = sum((pred_student \u003c pred_teacher))\n","\n","        if self.output_mode == \"proportion\":\n","            return churn / pred_teacher.shape[0]\n","        if self.output_mode == \"count\":\n","            return churn"]},{"cell_type":"markdown","metadata":{"id":"-EPIpW-OICW6"},"source":["### Label Modification Methods"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0kc9LmD6ICGz"},"outputs":[],"source":["#y_true when fed outside as argument to call should be one_hot encoded\n","class ChurnMethod():\n","    \"\"\"\n","    Place Holder class that is other label modification methodology classes shold inherit from.\n","    Does nothing right now but can be modified to bring some functionality to all methods at once\n","    \"\"\"\n","    def __init__(self):\n","        pass\n","\n","class Distillation(ChurnMethod):\n","    def __init__(self, teacher, lamda=0.5):\n","        super().__init__()\n","        self.lamda = lamda\n","        self.teacher = teacher\n","\n","    def __call__(self, X, y_true): #call an instance of the class to run this function. y_true needs to be one_hot encoded in this implementation\n","        with torch.no_grad(): #To ensure that pytorch is not creating gradients on the teacher model. i.e, all learning happens in student and double-ensuring teacher is static.\n","            teacher_pred = self.teacher(X) # The last layer of teacher model is just 10 neurons, all of which can take any real value\n","            teacher_label = nn.functional.softmax(self.teacher(X), dim=1) #convert output of model to softmax, getting probabilities for each class\n","            new_label = teacher_label * self.lamda + y_true * (1 - self.lamda) #distillation equation\n","            return new_label\n","\n","class Anchor_RCP(ChurnMethod):\n","    def __init__(self, teacher, alpha=0.5, epsilon=0.5): #two hyperparams of anchor\n","        super().__init__()\n","        self.alpha = alpha\n","        self.epsilon = epsilon\n","        self.teacher = teacher\n","\n","    def __call__(self, X, y_true):\n","        with torch.no_grad(): \n","            teacher_pred = self.teacher(X)\n","            teacher_label = nn.functional.softmax(self.teacher(X), dim=1)\n","            correct_indices = y_true.argmax(1) == teacher_label.argmax(1) #see which indices are correct pred\n","            device = X.get_device() #in torch, all operations between models and variables can only be done when they are on the same device (cpu, gpu). here we get device of X. In general if you see something.cuda() being done somewhere, that sends the object to gpu\n","            new_label = torch.zeros(y_true.shape).to(device) #new variables are by default created on cpu. this line will transfer the new_label to whichever device X was on\n","            new_label[~correct_indices,:] = self.epsilon * y_true[~correct_indices,:] #all incorrect labels and are given the epsilon treatment from the rcp equation\n","            new_label[correct_indices,:] = teacher_label[correct_indices,:] * self.alpha + y_true[correct_indices,:] * (1 - self.alpha) #correct preds are given the alpha treatment from the rcp equation\n","            return new_label\n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"elapsed":18679,"status":"ok","timestamp":1668431078863,"user":{"displayName":"himangshu bhantana","userId":"00316151722707244448"},"user_tz":300},"id":"Pofg3ySG6sR0","outputId":"96d0b439-7e62-4d72-e9e2-464c218c5a41"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c41c59e7a5134d598c32c2301b432382","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/170498071 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n"]}],"source":["size, padding = 32, 4\n","transform = transforms.Compose(\n","    [\n","        transforms.RandomCrop(size, padding), transforms.RandomHorizontalFlip(p=0.5),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    ]\n",")\n","\n","trainvalset = torchvision.datasets.CIFAR10(\n","    root='./data',\n","    train=True,\n","    download=True,\n","    transform=transform\n",")\n","\n","split1 = torch.utils.data.random_split(trainvalset, [40000, 10000])\n","split2 = torch.utils.data.random_split(split1[0], [30000, 10000])\n","newtrainset = split1[0]\n","valset = split1[1]\n","oldtrainset = split2[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9aRn158-nMu"},"outputs":[],"source":["from torch.optim import lr_scheduler\n","old_train_loader = torch.utils.data.DataLoader(\n","        oldtrainset,\n","        batch_size=128,\n","        shuffle=True,\n","        num_workers=4,\n","        pin_memory=True\n",")\n","new_train_loader = torch.utils.data.DataLoader(\n","        newtrainset,\n","        batch_size=128,\n","        shuffle=True,\n","        num_workers=4,\n","        pin_memory=True\n",")\n","val_loader = torch.utils.data.DataLoader(\n","        valset,\n","        batch_size=128,\n","        shuffle=True,\n","        num_workers=4,\n","        pin_memory=True\n",")\n","\n","# batchsize = 128\n","# SGD lr=0.1\n","# lr_scheduler\n","# random_crop, flipping, rotating\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"woalTkv7_BIP"},"outputs":[],"source":["class newmodel(nn.Module):\n","    def __init__(self, resnet) -\u003e None:\n","        super().__init__()\n","        self.resnet = resnet\n","        self.final_layer = nn.Linear(1000, 10)\n","\n","    def forward(self, x):\n","        x = nn.functional.relu(self.resnet(x))\n","        x = self.final_layer(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDwisqRn_LgH"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def accuracy(output, target):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = 1\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in [1]:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res[0]\n","\n","\n","\n","\n","\n","    #handle the learning rate scheduler.\n","\n","# print(simple_churn(target_var, output.argmax(1)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668400322514,"user":{"displayName":"himangshu bhantana","userId":"00316151722707244448"},"user_tz":300},"id":"dqp4hMWU2IET","outputId":"c9fb6fba-27a6-41d4-940f-388a2a297e2b"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022/11/14 04:32:01 INFO mlflow.tracking.fluent: Experiment with name 'New run 2' does not exist. Creating a new experiment.\n"]},{"data":{"text/plain":["\u003cExperiment: artifact_location='file:///content/drive/MyDrive/Proofpoint/mlruns/2', creation_time=1668400321332, experiment_id='2', last_update_time=1668400321332, lifecycle_stage='active', name='New run 2', tags={}\u003e"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["\n","mlflow.set_experiment('New run 2')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjTU94vAq7ue"},"outputs":[],"source":["def baseline_chunk():\n","    DECAY_EPOCHS= [20,120]\n","    DECAY= 0.1\n","    num_epochs = 30\n","    best_acc=0\n","    current_learning_rate = 0.1\n","    train_losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","\n","    baseline_model = newmodel(torch.hub.load('pytorch/vision:v0.13.1', 'resnet18', pretrained=False))\n","    criterion = nn.CrossEntropyLoss()\n","    baseline_optimizer = torch.optim.SGD(baseline_model.parameters(), lr=0.1, momentum=0.9)\n","\n","    baseline_model.cuda()\n","    \n","    for epoch in range(0,num_epochs):\n","        if epoch in DECAY_EPOCHS and epoch != 0:\n","            current_learning_rate = current_learning_rate * DECAY\n","            for param_group in baseline_optimizer.param_groups:\n","                param_group['lr'] = current_learning_rate\n","            print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n","        per_epoch_losses = []\n","        per_epoch_accuracies = []\n","        print(epoch)\n","        for j, (input, target) in enumerate(new_train_loader):\n","            target = target.cuda()\n","            input_var = input.cuda()\n","            target_var = target\n","            \n","            # compute output\n","            output = baseline_model(input_var)            \n","            loss = criterion(output, target_var)\n","\n","            # compute gradient and do SGD step\n","            baseline_optimizer.zero_grad()\n","            loss.backward()\n","            baseline_optimizer.step()\n","\n","            output = output.float()\n","            loss = loss.float()\n","            \n","            # measure accuracy and record loss\n","            per_epoch_accuracies.append(accuracy(output.data, target))\n","            per_epoch_losses.append(loss.item())\n","\n","        per_epoch_val_losses = []\n","        per_epoch_val_accuracies = []\n","        for j, (input, target) in enumerate(val_loader):\n","            target = target.cuda()\n","            input_var = input.cuda()\n","            target_var = target\n","            output = baseline_model(input_var)\n","            loss = criterion(output, target_var)\n","            output = output.float()\n","            loss = loss.float()\n","            \n","            # measure accuracy and record loss\n","            per_epoch_val_accuracies.append(accuracy(output.data, target))\n","            per_epoch_val_losses.append(loss.item())\n","      \n","        train_losses.append(sum(per_epoch_losses) / len(per_epoch_losses))\n","        val_losses.append(sum(per_epoch_val_losses) / len(per_epoch_val_losses))\n","        train_accuracies.append(sum(per_epoch_accuracies) / len(per_epoch_accuracies))\n","        val_accuracies.append(sum(per_epoch_val_accuracies) / len(per_epoch_val_accuracies))\n","      \n","        mlflow.log_metric(\"Baseline Train accuracy\", train_accuracies[-1])\n","        mlflow.log_metric(\"Baseline Train loss\", train_losses[-1])\n","        mlflow.log_metric(\"Baseline Val loss\", val_losses[-1])\n","        mlflow.log_metric(\"Baseline Val accuracy\", val_accuracies[-1])\n","\n","        print(\"Training loss: %.4f, Training accuracy: %.4f, Val loss: %.4f, Val accuracy: %.4f, \" %(train_losses[-1], train_accuracies[-1], val_losses[-1], val_accuracies[-1]))\n","        if val_accuracies[-1] \u003e best_acc:\n","            best_acc = val_accuracies[-1]\n","            print('')\n","\n","    print(f\"=\u003e Best: {best_acc:.4f}\")\n","    return baseline_model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QghyJcjJFlfh"},"outputs":[],"source":["def teacher_chunk():\n","    model = newmodel(torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False))\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)  \n","    model.cuda()\n","    DECAY_EPOCHS= [20,120]\n","    DECAY= 0.1\n","    num_epochs  = 30\n","    best_acc=0\n","    current_learning_rate = 0.1\n","    train_losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","    for epoch in range(0,num_epochs):\n","        print(\"Epoch : %d\" % epoch)\n","        if epoch in DECAY_EPOCHS and epoch != 0:\n","            current_learning_rate = current_learning_rate * DECAY\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = current_learning_rate\n","            print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n","        per_epoch_losses = []\n","        per_epoch_accuracies = []\n","        for j, (input, target) in enumerate(old_train_loader):\n","            target = target.cuda()\n","            input_var = input.cuda()\n","            target_var = target\n","            \n","            # compute output\n","            output = model(input_var)\n","            loss = criterion(output, target_var)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            output = output.float()\n","            loss = loss.float()\n","            \n","            # measure accuracy and record loss\n","            per_epoch_accuracies.append(accuracy(output.data, target))\n","            per_epoch_losses.append(loss.item())\n","\n","        per_epoch_val_losses = []\n","        per_epoch_val_accuracies = []\n","        for j, (input, target) in enumerate(val_loader):\n","            target = target.cuda()\n","            input_var = input.cuda()\n","            target_var = target\n","            output = model(input_var)\n","            loss = criterion(output, target_var)\n","            output = output.float()\n","            loss = loss.float()\n","            \n","            # measure accuracy and record loss\n","            per_epoch_val_accuracies.append(accuracy(output.data, target))\n","            per_epoch_val_losses.append(loss.item())\n","        \n","        train_losses.append(sum(per_epoch_losses) / len(per_epoch_losses))\n","        val_losses.append(sum(per_epoch_val_losses) / len(per_epoch_val_losses))\n","        train_accuracies.append(sum(per_epoch_accuracies) / len(per_epoch_accuracies))\n","        val_accuracies.append(sum(per_epoch_val_accuracies) / len(per_epoch_val_accuracies))\n","      \n","        mlflow.log_metric(\"Teacher Train accuracy\", train_accuracies[-1])\n","        mlflow.log_metric(\"Teacher Train loss\", train_losses[-1])\n","        mlflow.log_metric(\"Teacher Val loss\", val_losses[-1])\n","        mlflow.log_metric(\"Teacher Val accuracy\", val_accuracies[-1])\n","\n","        print(\"Training loss: %.4f, Training accuracy: %.4f, Val loss: %.4f, Val accuracy: %.4f, \" %(train_losses[-1], train_accuracies[-1], val_losses[-1], val_accuracies[-1]))\n","        if val_accuracies[-1] \u003e best_acc:\n","            best_acc = val_accuracies[-1]\n","            print('')\n","\n","    print(f\"=\u003e Best: {best_acc:.4f}\")\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c374PZAB6PCr"},"outputs":[],"source":["def student_chunk_rcp(model):\n","    DECAY_EPOCHS= [20,120]\n","    DECAY= 0.1\n","    num_epochs  = 30\n","    alphas = [0.2, 0.4, 0.6, 0.8]\n","    epsilon = 1.    \n","\n","    student_models = {}\n","    for alpha in alphas:\n","\n","      best_acc=0\n","      current_learning_rate = 0.1\n","      train_losses = []\n","      val_losses = []\n","      train_accuracies = []\n","      val_accuracies = []\n","      label_modifier = Anchor_RCP(model, alpha=alpha, epsilon=epsilon)\n","        ### END OF CHANGES ####\n","      print(f\"alpha = {alpha}\")\n","      print(f\"epsilon = {epsilon}\")\n","      student_model = newmodel(torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False))\n","      student_models[(alpha, epsilon)] = student_model\n","      criterion = nn.CrossEntropyLoss()\n","      student_optimizer = torch.optim.SGD(student_model.parameters(), lr=0.1, momentum=0.9)\n","\n","      student_model.cuda()\n","      model.eval()\n","\n","      for epoch in range(0,num_epochs):\n","          print(\"Epoch : %d\" % epoch)\n","          if epoch in DECAY_EPOCHS and epoch != 0:\n","              current_learning_rate = current_learning_rate * DECAY\n","              for param_group in student_optimizer.param_groups:\n","                  param_group['lr'] = current_learning_rate\n","              print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n","          per_epoch_losses = []\n","          per_epoch_accuracies = []\n","          for j, (input, target) in enumerate(old_train_loader):\n","              target = target.cuda()\n","              input_var = input.cuda()\n","              target_var = nn.functional.one_hot(target, num_classes= 10)\n","              \n","              # compute output\n","              output = student_model(input_var)\n","              new_label = label_modifier(input_var, target_var)\n","              loss = criterion(output, new_label)\n","              student_optimizer.zero_grad()\n","              loss.backward()\n","              student_optimizer.step()\n","              output = output.float()\n","              loss = loss.float()\n","              \n","              # measure accuracy and record loss\n","              per_epoch_accuracies.append(accuracy(output.data, target))\n","              per_epoch_losses.append(loss.item())\n","\n","          per_epoch_val_losses = []\n","          per_epoch_val_accuracies = []\n","          for j, (input, target) in enumerate(val_loader):\n","              target = target.cuda()\n","              input_var = input.cuda()\n","              target_var = target\n","              output = student_model(input_var)\n","              loss = criterion(output, target_var)\n","              output = output.float()\n","              loss = loss.float()\n","              \n","              # measure accuracy and record loss\n","              per_epoch_val_accuracies.append(accuracy(output.data, target))\n","              per_epoch_val_losses.append(loss.item())\n","          \n","          train_losses.append(sum(per_epoch_losses) / len(per_epoch_losses))\n","          val_losses.append(sum(per_epoch_val_losses) / len(per_epoch_val_losses))\n","          train_accuracies.append(sum(per_epoch_accuracies) / len(per_epoch_accuracies))\n","          val_accuracies.append(sum(per_epoch_val_accuracies) / len(per_epoch_val_accuracies))\n","        \n","          mlflow.log_metric(f\"Student RCP Train accuracy_{alpha}\", train_accuracies[-1])\n","          mlflow.log_metric(f\"Student RCP  Train loss_{alpha}\", train_losses[-1])\n","          mlflow.log_metric(f\"Student RCP  Val loss_{alpha}\", val_losses[-1])\n","          mlflow.log_metric(f\"Student RCP  Val accuracy_{alpha}\", val_accuracies[-1])\n","          \n","\n","          print(\"Training loss: %.4f, Training accuracy: %.4f, Val loss: %.4f, Val accuracy: %.4f, \" %(train_losses[-1], train_accuracies[-1], val_losses[-1], val_accuracies[-1]))\n","          if val_accuracies[-1] \u003e best_acc:\n","              best_acc = val_accuracies[-1]\n","              print('')\n","\n","      print(f\"=\u003e Best: {best_acc:.4f}\")\n","      torch.save(student_model.state_dict(), f\"alpha={alpha}_epsilon_{epsilon}.model\")\n","    return student_models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nozLmE5Oxp8-"},"outputs":[],"source":["def student_chunk_dist(model):\n","    DECAY_EPOCHS= [20,120]\n","    DECAY= 0.1\n","    num_epochs  = 30\n","    \n","    lamdas = [0.2, 0.4, 0.6, 0.8]\n","    student_models = {}\n","    for lamda in lamdas:\n","\n","      best_acc=0\n","      current_learning_rate = 0.1\n","      train_losses = []\n","      val_losses = []\n","      train_accuracies = []\n","      val_accuracies = []\n","      label_modifier = Distillation(model,lamda=lamda)\n","      print(f\"lamda = {lamda}\")\n","      student_model = newmodel(torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False))\n","      student_models[lamda] = student_model\n","      criterion = nn.CrossEntropyLoss()\n","      student_optimizer = torch.optim.SGD(student_model.parameters(), lr=0.1, momentum=0.9)\n","\n","      student_model.cuda()\n","      model.eval()\n","\n","\n","      for epoch in range(0,num_epochs):\n","          print(\"Epoch : %d\" % epoch)\n","          if epoch in DECAY_EPOCHS and epoch != 0:\n","              current_learning_rate = current_learning_rate * DECAY\n","              for param_group in student_optimizer.param_groups:\n","                  param_group['lr'] = current_learning_rate\n","              print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n","          per_epoch_losses = []\n","          per_epoch_accuracies = []\n","          for j, (input, target) in enumerate(new_train_loader):\n","              target = target.cuda()\n","              input_var = input.cuda()\n","              target_var = nn.functional.one_hot(target)\n","\n","              # compute output\n","              output = student_model(input_var)\n","              teacher_label = nn.functional.softmax(model(input_var), dim=1)\n","              new_label = label_modifier(input_var, target_var)\n","              loss = criterion(output, new_label)\n","\n","              # compute gradient and do SGD step\n","              student_optimizer.zero_grad()\n","              loss.backward()\n","              student_optimizer.step()\n","\n","              output = output.float()\n","              loss = loss.float()\n","              \n","              # measure accuracy and record loss\n","              per_epoch_accuracies.append(accuracy(output.data, target))\n","              per_epoch_losses.append(loss.item())\n","\n","          per_epoch_val_losses = []\n","          per_epoch_val_accuracies = []\n","          for j, (input, target) in enumerate(val_loader):\n","              target = target.cuda()\n","              input_var = input.cuda()\n","              target_var = target\n","              output = student_model(input_var)\n","              loss = criterion(output, target_var)\n","              output = output.float()\n","              loss = loss.float()\n","              \n","              # measure accuracy and record loss\n","              per_epoch_val_accuracies.append(accuracy(output.data, target))\n","              per_epoch_val_losses.append(loss.item())\n","          \n","          train_losses.append(sum(per_epoch_losses) / len(per_epoch_losses))\n","          val_losses.append(sum(per_epoch_val_losses) / len(per_epoch_val_losses))\n","          train_accuracies.append(sum(per_epoch_accuracies) / len(per_epoch_accuracies))\n","          val_accuracies.append(sum(per_epoch_val_accuracies) / len(per_epoch_val_accuracies))\n","        \n","          mlflow.log_metric(f\"Student Distill Train accuracy_{lamda}\", train_accuracies[-1])\n","          mlflow.log_metric(f\"Student Distill Train loss_{lamda}\", train_losses[-1])\n","          mlflow.log_metric(f\"Student Distill Val loss_{lamda}\", val_losses[-1])\n","          mlflow.log_metric(f\"Student Distill Val accuracy_{lamda}\", val_accuracies[-1])\n","\n","          print(\"Training loss: %.4f, Training accuracy: %.4f, Val loss: %.4f, Val accuracy: %.4f, \" %(train_losses[-1], train_accuracies[-1], val_losses[-1], val_accuracies[-1]))\n","          if val_accuracies[-1] \u003e best_acc:\n","              best_acc = val_accuracies[-1]\n","              print('')\n","\n","      print(f\"=\u003e Best: {best_acc:.4f}\")\n","      torch.save(student_model.state_dict(), f\"lambda{lamda}.modeel\")\n","    return student_models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_B_WyS93urw4"},"outputs":[],"source":["#torch.save(model.state_dict(), f\"teacher.modeel\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iYrNKZD8teMO"},"outputs":[],"source":["def metric_chunk_dist(model, baseline_model, run_no):\n","  simple_churn = Churn(tensor_type=\"torch\", output_mode=\"count\")\n","  good_churn = GoodBadChurn(tensor_type=\"torch\", mode=\"good\", output_mode=\"count\")\n","  bad_churn = GoodBadChurn(tensor_type=\"torch\", mode=\"bad\", output_mode=\"count\")\n","  wlr = WinLossRatio(tensor_type=\"torch\")\n","\n","  baseline_wins = 0\n","  baseline_losses = 0\n","  baseline_good_churn = 0\n","  baseline_bad_churn = 0\n","  baseline_model.eval()\n","  churn_count_baseline = 0\n","  baseline_acc = 0\n","  teacher_acc = 0\n","\n","  for i, (input, target) in enumerate(val_loader):\n","      input_var = input.cuda()\n","      target_var = target.cuda()\n","      target_var_oh = nn.functional.one_hot(target_var, num_classes=10)\n","      churn_count_baseline += simple_churn(model(input_var), baseline_model(input_var))\n","      baseline_acc += torch.sum(baseline_model(input_var).argmax(1) == target_var)\n","      teacher_acc += torch.sum(model(input_var).argmax(1) == target_var)\n","      baseline_win, baseline_loss = wlr(target_var_oh, model(input_var), baseline_model(input_var))\n","      baseline_wins += baseline_win\n","      baseline_losses += baseline_loss\n","      baseline_good_churn = good_churn(target_var_oh, model(input_var), baseline_model(input_var))\n","      baseline_bad_churn = bad_churn(target_var_oh, model(input_var), baseline_model(input_var))\n","\n","  lamdas = [0.2, 0.4, 0.6, 0.8]\n","\n","  for lamda in lamdas:\n","      student_model = newmodel(torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False))\n","      student_model.load_state_dict(torch.load(f\"lambda{lamda}.modeel\"))\n","      student_model.cuda()\n","      mlflow.pytorch.log_model(student_model, f\"student_model_Val_{lamda}\")\n","      \n","      simple_churn = Churn(tensor_type=\"torch\", output_mode=\"count\")\n","      good_churn = GoodBadChurn(tensor_type=\"torch\", mode=\"good\", output_mode=\"count\")\n","      bad_churn = GoodBadChurn(tensor_type=\"torch\", mode=\"bad\", output_mode=\"count\")\n","      wlr = WinLossRatio(tensor_type=\"torch\")\n","\n","      churn_count_student = 0\n","      student_acc = 0\n","      student_model.eval()\n","      student_wins = 0\n","      student_losses = 0\n","      student_good_churn = 0\n","      student_bad_churn = 0\n","\n","\n","\n","      for i, (input, target) in enumerate(val_loader):\n","          input_var = input.cuda()\n","          target_var = target.cuda()\n","          target_var_oh = nn.functional.one_hot(target_var, num_classes=10)\n","          churn_count_student += simple_churn(model(input_var), student_model(input_var))        \n","          student_acc += torch.sum(student_model(input_var).argmax(1) == target_var)        \n","          student_win, student_loss = wlr(target_var_oh, model(input_var), student_model(input_var))        \n","          student_wins += student_win        \n","          student_losses += student_loss        \n","          student_good_churn += good_churn(target_var_oh, model(input_var), student_model(input_var))\n","          student_bad_churn = bad_churn(target_var_oh, model(input_var), student_model(input_var))\n","          \n","\n","      churn_student = churn_count_student.item() / len(valset)\n","      churn_baseline = churn_count_baseline.item() / len(valset)\n","      print(f\"\\n\\nlamda = {lamda}\\n\", )\n","      print(f\"student churn = {churn_student}\", )\n","      print(f\"baseline churn = {churn_baseline}\")\n","      print(f\"student accuracy = {student_acc.item() / len(valset)}\")\n","      print(f\"baseline accuracy = {baseline_acc.item() / len(valset)}\")\n","      print(f\"teacher accuracy = {teacher_acc.item() / len(valset)}\")\n","      print(f\"student wlr = {(student_wins / student_losses)}\")\n","      print(f\"baseline wlr = {(baseline_wins / baseline_losses)}\")\n","      print(f\"churn ratio = {(churn_student/ churn_baseline)}\")\n","      print(f\"student good_churn = {student_good_churn.item() / len(valset)}\")\n","      print(f\"student bad_churn = {student_bad_churn.item() / len(valset)}\")\n","      print(f\"baseline good_churn = {baseline_good_churn.item() / len(valset)}\")\n","      print(f\"baseline bad_churn = {baseline_bad_churn.item() / len(valset)}\")\n","      \n","      mlflow.log_metric(f\"{run_no} student_churn_{lamda}\", churn_student)\n","      mlflow.log_metric(f\"{run_no} baseline churn_{lamda}\", churn_baseline)\n","      mlflow.log_metric(f\"{run_no} student accuracy_{lamda}\", student_acc.item() / len(valset))\n","      mlflow.log_metric(f\"{run_no} baseline accuracy_{lamda}\", baseline_acc.item() / len(valset))\n","      mlflow.log_metric(f\"{run_no} teacher accuracy _{lamda}\", teacher_acc.item() / len(valset))\n","      mlflow.log_metric(f\"{run_no} student wlr_{lamda}\", (student_wins / student_losses))\n","      mlflow.log_metric(f\"{run_no} baseline wlr_{lamda}\", (baseline_wins / baseline_losses))\n","      mlflow.log_metric(f\"{run_no} churn ratio_{lamda}\", (churn_student/ churn_baseline))\n","      mlflow.log_metric(f\"{run_no} student good_churn_{lamda}\", student_good_churn.item() / len(valset))\n","      mlflow.log_metric(f\"{run_no} student bad_churn _{lamda}\", student_bad_churn.item() / len(valset))\n","      mlflow.log_metric(f\"{run_no} baseline good_churn_{lamda}\",baseline_good_churn.item() / len(valset))\n","      mlflow.log_metric(f\"{run_no} baseline bad_churn_{lamda}\", baseline_bad_churn.item() / len(valset))\n","      \n","      mlflow.pytorch.log_model(baseline_model, f\"baseline_model_Val_{lamda}\")\n","\n","\n","\n","\n","      "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_Qg0ze5jn9C"},"outputs":[],"source":["def metric_chunk_rcp(model, baseline_model, run_no):\n","  simple_churn = Churn(tensor_type=\"torch\", output_mode=\"count\")\n","  good_churn = GoodBadChurn(tensor_type=\"torch\", mode=\"good\", output_mode=\"count\")\n","  bad_churn = GoodBadChurn(tensor_type=\"torch\", mode=\"bad\", output_mode=\"count\")\n","  wlr = WinLossRatio(tensor_type=\"torch\")\n","\n","  baseline_wins = 0\n","  baseline_losses = 0\n","  baseline_good_churn = 0\n","  baseline_bad_churn = 0\n","  baseline_model.eval()\n","  churn_count_baseline = 0\n","  baseline_acc = 0\n","  teacher_acc = 0\n","\n","  for i, (input, target) in enumerate(val_loader):\n","      input_var = input.cuda()\n","      target_var = target.cuda()\n","      target_var_oh = nn.functional.one_hot(target_var, num_classes=10)\n","      churn_count_baseline += simple_churn(model(input_var), baseline_model(input_var))\n","      baseline_acc += torch.sum(baseline_model(input_var).argmax(1) == target_var)\n","      teacher_acc += torch.sum(model(input_var).argmax(1) == target_var)\n","      baseline_win, baseline_loss = wlr(target_var_oh, model(input_var), baseline_model(input_var))\n","      baseline_wins += baseline_win\n","      baseline_losses += baseline_loss\n","      baseline_good_churn = good_churn(target_var_oh, model(input_var), baseline_model(input_var))\n","      baseline_bad_churn = bad_churn(target_var_oh, model(input_var), baseline_model(input_var))\n","\n","  alphas = [0.2, 0.4, 0.6, 0.8]\n","  epsilon = 1.\n","\n","\n","  for alpha in alphas:\n","        student_model = newmodel(torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False))\n","        student_model.load_state_dict(torch.load(f\"alpha={alpha}_epsilon_{epsilon}.model\"))\n","        student_model.cuda()\n","        mlflow.pytorch.log_model(student_model, f\"Student_RCP_accuracy_alpha_{alpha}_epsilon_{epsilon}.model\")\n","        \n","        simple_churn = Churn(tensor_type=\"torch\", output_mode=\"count\")\n","        good_churn = GoodBadChurn(tensor_type=\"torch\", mode=\"good\", output_mode=\"count\")\n","        bad_churn = GoodBadChurn(tensor_type=\"torch\", mode=\"bad\", output_mode=\"count\")\n","        wlr = WinLossRatio(tensor_type=\"torch\")\n","\n","        churn_count_student = 0\n","        student_acc = 0\n","        student_model.eval()\n","        student_wins = 0\n","        student_losses = 0\n","        student_good_churn = 0\n","        student_bad_churn = 0\n","\n","\n","\n","        for i, (input, target) in enumerate(val_loader):\n","            input_var = input.cuda()\n","            target_var = target.cuda()\n","            target_var_oh = nn.functional.one_hot(target_var, num_classes=10)\n","            churn_count_student += simple_churn(model(input_var), student_model(input_var))        \n","            student_acc += torch.sum(student_model(input_var).argmax(1) == target_var)        \n","            student_win, student_loss = wlr(target_var_oh, model(input_var), student_model(input_var))        \n","            student_wins += student_win        \n","            student_losses += student_loss        \n","            student_good_churn += good_churn(target_var_oh, model(input_var), student_model(input_var))\n","            student_bad_churn = bad_churn(target_var_oh, model(input_var), student_model(input_var))\n","            \n","\n","        churn_student = churn_count_student.item() / len(valset)\n","        churn_baseline = churn_count_baseline.item() / len(valset)\n","        print(f\"\\n\\nalpha = {alpha}\\n\", )\n","        print(f\"\\n\\nEpsilon = {epsilon}\\n\",)\n","        print(f\"student churn = {churn_student}\", )\n","        print(f\"baseline churn = {churn_baseline}\")\n","        print(f\"student accuracy = {student_acc.item() / len(valset)}\")\n","        print(f\"baseline accuracy = {baseline_acc.item() / len(valset)}\")\n","        print(f\"teacher accuracy = {teacher_acc.item() / len(valset)}\")\n","        print(f\"student wlr = {(student_wins / student_losses)}\")\n","        print(f\"baseline wlr = {(baseline_wins / baseline_losses)}\")\n","        print(f\"churn ratio = {(churn_student/ churn_baseline)}\")\n","        print(f\"student good_churn = {student_good_churn.item() / len(valset)}\")\n","        print(f\"student bad_churn = {student_bad_churn.item() / len(valset)}\")\n","        print(f\"baseline good_churn = {baseline_good_churn.item() / len(valset)}\")\n","        print(f\"baseline bad_churn = {baseline_bad_churn.item() / len(valset)}\")\n","        \n","        mlflow.log_metric(f\"{run_no} student_churn_alpha_{alpha}_epsilon_{epsilon}\", churn_student)\n","        mlflow.log_metric(f\"{run_no} baseline churn_alpha_{alpha}_epsilon_{epsilon}\", churn_baseline)\n","        mlflow.log_metric(f\"{run_no} student accuracy_alpha_{alpha}_epsilon_{epsilon}\", student_acc.item() / len(valset))\n","        mlflow.log_metric(f\"{run_no} baseline accuracy_alpha_{alpha}_epsilon_{epsilon}\", baseline_acc.item() / len(valset))\n","        mlflow.log_metric(f\"{run_no} teacher accuracy _alpha_{alpha}_epsilon_{epsilon}\", teacher_acc.item() / len(valset))\n","        mlflow.log_metric(f\"{run_no} student wlr_alpha_{alpha}_epsilon_{epsilon}\", (student_wins / student_losses))\n","        mlflow.log_metric(f\"{run_no} baseline wlr_alpha_{alpha}_epsilon_{epsilon}\", (baseline_wins / baseline_losses))\n","        mlflow.log_metric(f\"{run_no} churn ratio_alpha_{alpha}_epsilon_{epsilon}\", (churn_student/ churn_baseline))\n","        mlflow.log_metric(f\"{run_no} student good_churn_{alpha}_epsilon_{epsilon}\", student_good_churn.item() / len(valset))\n","        mlflow.log_metric(f\"{run_no} student bad_churn _alpha_{alpha}_epsilon_{epsilon}\", student_bad_churn.item() / len(valset))\n","        mlflow.log_metric(f\"{run_no} baseline good_churn_alpha_{alpha}_epsilon_{epsilon}\",baseline_good_churn.item() / len(valset))\n","        mlflow.log_metric(f\"{run_no} baseline bad_churn_alpha_{alpha}_epsilon_{epsilon}\", baseline_bad_churn.item() / len(valset))\n","        \n","        mlflow.pytorch.log_model(baseline_model, f\"RCP baseline_model_Val_{alpha}_epsilon_{epsilon}\")\n","\n","\n","\n","\n","      "]},{"cell_type":"markdown","metadata":{"id":"KEKuvPAoMFh3"},"source":["Main loop for MLFlow:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"dJLfoKomMDqs"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 0\n","Training loss: 1.8454, Training accuracy: 31.6035, Val loss: 1.7637, Val accuracy: 35.7496, \n","\n","Epoch : 1\n","Training loss: 1.5903, Training accuracy: 42.0756, Val loss: 1.5129, Val accuracy: 45.1048, \n","\n","Epoch : 2\n","Training loss: 1.4101, Training accuracy: 49.0559, Val loss: 1.3630, Val accuracy: 51.8790, \n","\n","Epoch : 3\n","Training loss: 1.2824, Training accuracy: 54.6144, Val loss: 1.3046, Val accuracy: 55.7753, \n","\n","Epoch : 4\n","Training loss: 1.1684, Training accuracy: 58.8597, Val loss: 1.1646, Val accuracy: 58.8212, \n","\n","Epoch : 5\n","Training loss: 1.0897, Training accuracy: 61.5913, Val loss: 1.0963, Val accuracy: 61.0562, \n","\n","Epoch : 6\n","Training loss: 1.0214, Training accuracy: 64.0913, Val loss: 1.0717, Val accuracy: 63.0044, \n","\n","Epoch : 7\n","Training loss: 0.9648, Training accuracy: 65.9497, Val loss: 1.0343, Val accuracy: 64.3592, \n","\n","Epoch : 8\n","Training loss: 0.9235, Training accuracy: 67.6031, Val loss: 0.9567, Val accuracy: 66.7029, \n","\n","Epoch : 9\n","Training loss: 0.8678, Training accuracy: 70.0820, Val loss: 0.9487, Val accuracy: 66.3964, \n","Epoch : 10\n","Training loss: 0.8534, Training accuracy: 70.4366, Val loss: 0.9008, Val accuracy: 69.2049, \n","\n","Epoch : 11\n","Training loss: 0.8038, Training accuracy: 72.0612, Val loss: 0.8839, Val accuracy: 69.5708, \n","\n","Epoch : 12\n","Training loss: 0.7688, Training accuracy: 73.3245, Val loss: 0.8744, Val accuracy: 69.7884, \n","\n","Epoch : 13\n","Training loss: 0.7425, Training accuracy: 74.4016, Val loss: 0.8652, Val accuracy: 70.8861, \n","\n","Epoch : 14\n","Training loss: 0.7209, Training accuracy: 75.1042, Val loss: 0.8247, Val accuracy: 71.9937, \n","\n","Epoch : 15\n","Training loss: 0.6874, Training accuracy: 76.1126, Val loss: 0.8099, Val accuracy: 73.3287, \n","\n","Epoch : 16\n","Training loss: 0.6771, Training accuracy: 76.6068, Val loss: 0.8095, Val accuracy: 72.1618, \n","Epoch : 17\n","Training loss: 0.6524, Training accuracy: 77.2861, Val loss: 0.7989, Val accuracy: 72.8441, \n","Epoch : 18\n","Training loss: 0.6322, Training accuracy: 78.1970, Val loss: 0.8531, Val accuracy: 71.6080, \n","Epoch : 19\n","Training loss: 0.6550, Training accuracy: 77.3149, Val loss: 0.8056, Val accuracy: 72.7453, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5236, Training accuracy: 81.9337, Val loss: 0.6971, Val accuracy: 76.3647, \n","\n","Epoch : 21\n","Training loss: 0.4835, Training accuracy: 83.0596, Val loss: 0.6915, Val accuracy: 76.9383, \n","\n","Epoch : 22\n","Training loss: 0.4672, Training accuracy: 83.7633, Val loss: 0.6742, Val accuracy: 77.6404, \n","\n","Epoch : 23\n","Training loss: 0.4560, Training accuracy: 84.3440, Val loss: 0.6870, Val accuracy: 76.7900, \n","Epoch : 24\n","Training loss: 0.4473, Training accuracy: 84.4293, Val loss: 0.6891, Val accuracy: 77.1262, \n","Epoch : 25\n","Training loss: 0.4384, Training accuracy: 84.6875, Val loss: 0.6633, Val accuracy: 77.1855, \n","Epoch : 26\n","Training loss: 0.4311, Training accuracy: 84.9280, Val loss: 0.6829, Val accuracy: 77.1460, \n","Epoch : 27\n","Training loss: 0.4209, Training accuracy: 85.2981, Val loss: 0.6703, Val accuracy: 77.8976, \n","\n","Epoch : 28\n","Training loss: 0.4202, Training accuracy: 85.3812, Val loss: 0.6774, Val accuracy: 77.4229, \n","Epoch : 29\n","Training loss: 0.4097, Training accuracy: 85.7125, Val loss: 0.6676, Val accuracy: 77.9865, \n","\n","=\u003e Best: 77.9865\n","alpha = 0.2\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8422, Training accuracy: 32.1775, Val loss: 1.6435, Val accuracy: 40.5360, \n","\n","Epoch : 1\n","Training loss: 1.6042, Training accuracy: 42.1509, Val loss: 1.5578, Val accuracy: 42.0589, \n","\n","Epoch : 2\n","Training loss: 1.4263, Training accuracy: 49.0304, Val loss: 1.3973, Val accuracy: 48.3287, \n","\n","Epoch : 3\n","Training loss: 1.3229, Training accuracy: 53.5040, Val loss: 1.2680, Val accuracy: 55.6665, \n","\n","Epoch : 4\n","Training loss: 1.1756, Training accuracy: 58.5539, Val loss: 1.1570, Val accuracy: 58.9893, \n","\n","Epoch : 5\n","Training loss: 1.0753, Training accuracy: 62.7050, Val loss: 1.1098, Val accuracy: 61.7188, \n","\n","Epoch : 6\n","Training loss: 1.0149, Training accuracy: 65.0620, Val loss: 1.0522, Val accuracy: 63.0340, \n","\n","Epoch : 7\n","Training loss: 0.9595, Training accuracy: 67.0900, Val loss: 0.9518, Val accuracy: 67.0985, \n","\n","Epoch : 8\n","Training loss: 0.9064, Training accuracy: 69.1245, Val loss: 0.9321, Val accuracy: 67.4842, \n","\n","Epoch : 9\n","Training loss: 0.8568, Training accuracy: 70.9242, Val loss: 0.9045, Val accuracy: 69.3038, \n","\n","Epoch : 10\n","Training loss: 0.8225, Training accuracy: 72.1033, Val loss: 0.8711, Val accuracy: 70.1740, \n","\n","Epoch : 11\n","Training loss: 0.7904, Training accuracy: 73.3433, Val loss: 0.8422, Val accuracy: 71.2915, \n","\n","Epoch : 12\n","Training loss: 0.7657, Training accuracy: 74.2354, Val loss: 0.8564, Val accuracy: 71.0740, \n","Epoch : 13\n","Training loss: 0.7248, Training accuracy: 75.5375, Val loss: 0.8028, Val accuracy: 72.2805, \n","\n","Epoch : 14\n","Training loss: 0.7074, Training accuracy: 76.4362, Val loss: 0.7890, Val accuracy: 72.7947, \n","\n","Epoch : 15\n","Training loss: 0.6852, Training accuracy: 76.9016, Val loss: 0.7839, Val accuracy: 72.9035, \n","\n","Epoch : 16\n","Training loss: 0.6669, Training accuracy: 77.8845, Val loss: 0.7343, Val accuracy: 75.0000, \n","\n","Epoch : 17\n","Training loss: 0.6470, Training accuracy: 78.4142, Val loss: 0.7332, Val accuracy: 75.3165, \n","\n","Epoch : 18\n","Training loss: 0.6415, Training accuracy: 78.6879, Val loss: 0.7434, Val accuracy: 75.2176, \n","Epoch : 19\n","Training loss: 0.6189, Training accuracy: 79.2985, Val loss: 0.7359, Val accuracy: 74.5055, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5224, Training accuracy: 82.9599, Val loss: 0.6681, Val accuracy: 77.5910, \n","\n","Epoch : 21\n","Training loss: 0.4819, Training accuracy: 84.2996, Val loss: 0.6542, Val accuracy: 78.2140, \n","\n","Epoch : 22\n","Training loss: 0.4734, Training accuracy: 84.9125, Val loss: 0.6515, Val accuracy: 78.4118, \n","\n","Epoch : 23\n","Training loss: 0.4643, Training accuracy: 85.0421, Val loss: 0.6421, Val accuracy: 78.4513, \n","\n","Epoch : 24\n","Training loss: 0.4565, Training accuracy: 85.0332, Val loss: 0.6315, Val accuracy: 78.6689, \n","\n","Epoch : 25\n","Training loss: 0.4511, Training accuracy: 85.5984, Val loss: 0.6372, Val accuracy: 78.5997, \n","Epoch : 26\n","Training loss: 0.4468, Training accuracy: 85.6161, Val loss: 0.6310, Val accuracy: 78.4711, \n","Epoch : 27\n","Training loss: 0.4446, Training accuracy: 85.5629, Val loss: 0.6242, Val accuracy: 79.0249, \n","\n","Epoch : 28\n","Training loss: 0.4402, Training accuracy: 85.9486, Val loss: 0.6332, Val accuracy: 79.0348, \n","\n","Epoch : 29\n","Training loss: 0.4315, Training accuracy: 85.9608, Val loss: 0.6461, Val accuracy: 78.2041, \n","=\u003e Best: 79.0348\n","alpha = 0.4\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8388, Training accuracy: 32.4468, Val loss: 1.6555, Val accuracy: 38.4988, \n","\n","Epoch : 1\n","Training loss: 1.5707, Training accuracy: 43.1006, Val loss: 1.4437, Val accuracy: 48.0222, \n","\n","Epoch : 2\n","Training loss: 1.3797, Training accuracy: 51.0417, Val loss: 1.3113, Val accuracy: 52.5910, \n","\n","Epoch : 3\n","Training loss: 1.2535, Training accuracy: 55.9586, Val loss: 1.2124, Val accuracy: 56.9225, \n","\n","Epoch : 4\n","Training loss: 1.1434, Training accuracy: 60.2338, Val loss: 1.1274, Val accuracy: 60.9177, \n","\n","Epoch : 5\n","Training loss: 1.0711, Training accuracy: 63.2136, Val loss: 1.0602, Val accuracy: 63.0241, \n","\n","Epoch : 6\n","Training loss: 1.0035, Training accuracy: 65.8754, Val loss: 1.0269, Val accuracy: 63.7757, \n","\n","Epoch : 7\n","Training loss: 0.9594, Training accuracy: 67.3116, Val loss: 0.9759, Val accuracy: 66.4260, \n","\n","Epoch : 8\n","Training loss: 0.9098, Training accuracy: 69.0171, Val loss: 0.9788, Val accuracy: 66.1788, \n","Epoch : 9\n","Training loss: 0.8732, Training accuracy: 70.6261, Val loss: 0.8691, Val accuracy: 69.7884, \n","\n","Epoch : 10\n","Training loss: 0.8435, Training accuracy: 71.5891, Val loss: 0.8643, Val accuracy: 69.6005, \n","Epoch : 11\n","Training loss: 0.8175, Training accuracy: 72.7504, Val loss: 0.8539, Val accuracy: 70.3422, \n","\n","Epoch : 12\n","Training loss: 0.8042, Training accuracy: 73.0308, Val loss: 0.8309, Val accuracy: 71.3212, \n","\n","Epoch : 13\n","Training loss: 0.7631, Training accuracy: 74.9656, Val loss: 0.8184, Val accuracy: 71.8256, \n","\n","Epoch : 14\n","Training loss: 0.7323, Training accuracy: 75.9741, Val loss: 0.7952, Val accuracy: 72.7354, \n","\n","Epoch : 15\n","Training loss: 0.7289, Training accuracy: 76.2899, Val loss: 0.8113, Val accuracy: 71.8157, \n","Epoch : 16\n","Training loss: 0.7162, Training accuracy: 76.9127, Val loss: 0.7850, Val accuracy: 72.7749, \n","\n","Epoch : 17\n","Training loss: 0.6883, Training accuracy: 77.6995, Val loss: 0.7541, Val accuracy: 74.1792, \n","\n","Epoch : 18\n","Training loss: 0.6690, Training accuracy: 78.5406, Val loss: 0.7428, Val accuracy: 74.9604, \n","\n","Epoch : 19\n","Training loss: 0.6640, Training accuracy: 79.0115, Val loss: 0.7078, Val accuracy: 75.8307, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5640, Training accuracy: 82.5598, Val loss: 0.6618, Val accuracy: 77.4723, \n","\n","Epoch : 21\n","Training loss: 0.5383, Training accuracy: 83.4497, Val loss: 0.6583, Val accuracy: 77.5811, \n","\n","Epoch : 22\n","Training loss: 0.5233, Training accuracy: 83.8298, Val loss: 0.6537, Val accuracy: 77.5613, \n","Epoch : 23\n","Training loss: 0.5168, Training accuracy: 84.1855, Val loss: 0.6525, Val accuracy: 77.7789, \n","\n","Epoch : 24\n","Training loss: 0.5122, Training accuracy: 84.1190, Val loss: 0.6285, Val accuracy: 77.9865, \n","\n","Epoch : 25\n","Training loss: 0.5038, Training accuracy: 84.8360, Val loss: 0.6311, Val accuracy: 78.2635, \n","\n","Epoch : 26\n","Training loss: 0.4941, Training accuracy: 84.9645, Val loss: 0.6379, Val accuracy: 78.0360, \n","Epoch : 27\n","Training loss: 0.4881, Training accuracy: 85.4388, Val loss: 0.6542, Val accuracy: 77.4525, \n","Epoch : 28\n","Training loss: 0.4917, Training accuracy: 85.2017, Val loss: 0.6278, Val accuracy: 78.6392, \n","\n","Epoch : 29\n","Training loss: 0.4838, Training accuracy: 85.5829, Val loss: 0.6298, Val accuracy: 78.5898, \n","=\u003e Best: 78.6392\n","alpha = 0.6\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8243, Training accuracy: 33.4375, Val loss: 1.6276, Val accuracy: 39.8141, \n","\n","Epoch : 1\n","Training loss: 1.5620, Training accuracy: 43.7422, Val loss: 1.4502, Val accuracy: 47.1717, \n","\n","Epoch : 2\n","Training loss: 1.3783, Training accuracy: 51.4040, Val loss: 1.2992, Val accuracy: 53.2931, \n","\n","Epoch : 3\n","Training loss: 1.2473, Training accuracy: 56.8296, Val loss: 1.1431, Val accuracy: 60.1958, \n","\n","Epoch : 4\n","Training loss: 1.1423, Training accuracy: 60.9375, Val loss: 1.1314, Val accuracy: 60.2848, \n","\n","Epoch : 5\n","Training loss: 1.0637, Training accuracy: 63.9428, Val loss: 1.0852, Val accuracy: 61.4419, \n","\n","Epoch : 6\n","Training loss: 1.0082, Training accuracy: 65.8400, Val loss: 1.0082, Val accuracy: 65.1009, \n","\n","Epoch : 7\n","Training loss: 0.9444, Training accuracy: 68.4386, Val loss: 0.9618, Val accuracy: 66.6337, \n","\n","Epoch : 8\n","Training loss: 0.9083, Training accuracy: 69.9457, Val loss: 0.9049, Val accuracy: 68.4731, \n","\n","Epoch : 9\n","Training loss: 0.8549, Training accuracy: 71.7376, Val loss: 0.8770, Val accuracy: 69.8477, \n","\n","Epoch : 10\n","Training loss: 0.8297, Training accuracy: 72.8757, Val loss: 0.8576, Val accuracy: 70.7279, \n","\n","Epoch : 11\n","Training loss: 0.7951, Training accuracy: 74.2442, Val loss: 0.8660, Val accuracy: 70.0851, \n","Epoch : 12\n","Training loss: 0.7756, Training accuracy: 75.1551, Val loss: 0.8027, Val accuracy: 72.9727, \n","\n","Epoch : 13\n","Training loss: 0.7578, Training accuracy: 75.6316, Val loss: 0.8173, Val accuracy: 71.2619, \n","Epoch : 14\n","Training loss: 0.7329, Training accuracy: 76.5714, Val loss: 0.7913, Val accuracy: 72.4585, \n","Epoch : 15\n","Training loss: 0.7128, Training accuracy: 77.6396, Val loss: 0.7689, Val accuracy: 73.3188, \n","\n","Epoch : 16\n","Training loss: 0.6960, Training accuracy: 78.0474, Val loss: 0.7471, Val accuracy: 74.3968, \n","\n","Epoch : 17\n","Training loss: 0.6840, Training accuracy: 78.7566, Val loss: 0.7549, Val accuracy: 74.1693, \n","Epoch : 18\n","Training loss: 0.6707, Training accuracy: 79.1135, Val loss: 0.7058, Val accuracy: 75.2077, \n","\n","Epoch : 19\n","Training loss: 0.6504, Training accuracy: 79.9789, Val loss: 0.7397, Val accuracy: 74.5451, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5700, Training accuracy: 83.3256, Val loss: 0.6652, Val accuracy: 77.0471, \n","\n","Epoch : 21\n","Training loss: 0.5470, Training accuracy: 84.2265, Val loss: 0.6407, Val accuracy: 78.0063, \n","\n","Epoch : 22\n","Training loss: 0.5337, Training accuracy: 84.7241, Val loss: 0.6368, Val accuracy: 78.0360, \n","\n","Epoch : 23\n","Training loss: 0.5268, Training accuracy: 85.1031, Val loss: 0.6375, Val accuracy: 78.5206, \n","\n","Epoch : 24\n","Training loss: 0.5238, Training accuracy: 84.8881, Val loss: 0.6409, Val accuracy: 77.9173, \n","Epoch : 25\n","Training loss: 0.5217, Training accuracy: 85.0887, Val loss: 0.6354, Val accuracy: 78.1250, \n","Epoch : 26\n","Training loss: 0.5129, Training accuracy: 85.4721, Val loss: 0.6329, Val accuracy: 78.1052, \n","Epoch : 27\n","Training loss: 0.5090, Training accuracy: 85.6893, Val loss: 0.6351, Val accuracy: 78.0953, \n","Epoch : 28\n","Training loss: 0.5115, Training accuracy: 85.6937, Val loss: 0.6218, Val accuracy: 79.0249, \n","\n","Epoch : 29\n","Training loss: 0.5016, Training accuracy: 86.0949, Val loss: 0.6330, Val accuracy: 78.4711, \n","=\u003e Best: 79.0249\n","alpha = 0.8\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8335, Training accuracy: 32.6053, Val loss: 1.7399, Val accuracy: 35.2354, \n","\n","Epoch : 1\n","Training loss: 1.5698, Training accuracy: 43.7633, Val loss: 1.4827, Val accuracy: 46.2520, \n","\n","Epoch : 2\n","Training loss: 1.4013, Training accuracy: 50.7425, Val loss: 1.3354, Val accuracy: 50.6527, \n","\n","Epoch : 3\n","Training loss: 1.2648, Training accuracy: 56.0007, Val loss: 1.2091, Val accuracy: 57.1203, \n","\n","Epoch : 4\n","Training loss: 1.1562, Training accuracy: 60.4776, Val loss: 1.1183, Val accuracy: 59.8991, \n","\n","Epoch : 5\n","Training loss: 1.1155, Training accuracy: 62.1077, Val loss: 1.0590, Val accuracy: 62.5989, \n","\n","Epoch : 6\n","Training loss: 1.0304, Training accuracy: 65.3568, Val loss: 1.0301, Val accuracy: 64.3888, \n","\n","Epoch : 7\n","Training loss: 0.9790, Training accuracy: 67.5964, Val loss: 0.9597, Val accuracy: 66.0601, \n","\n","Epoch : 8\n","Training loss: 0.9502, Training accuracy: 68.7744, Val loss: 0.9453, Val accuracy: 67.1578, \n","\n","Epoch : 9\n","Training loss: 0.9118, Training accuracy: 69.9856, Val loss: 0.9293, Val accuracy: 67.5336, \n","\n","Epoch : 10\n","Training loss: 0.8700, Training accuracy: 71.7398, Val loss: 0.8750, Val accuracy: 69.5609, \n","\n","Epoch : 11\n","Training loss: 0.8457, Training accuracy: 72.7383, Val loss: 0.8545, Val accuracy: 70.1543, \n","\n","Epoch : 12\n","Training loss: 0.8299, Training accuracy: 73.7777, Val loss: 0.8720, Val accuracy: 69.9268, \n","Epoch : 13\n","Training loss: 0.8000, Training accuracy: 74.6265, Val loss: 0.8236, Val accuracy: 71.6179, \n","\n","Epoch : 14\n","Training loss: 0.7806, Training accuracy: 75.6028, Val loss: 0.7930, Val accuracy: 72.9233, \n","\n","Epoch : 15\n","Training loss: 0.7612, Training accuracy: 76.5281, Val loss: 0.8148, Val accuracy: 72.0926, \n","Epoch : 16\n","Training loss: 0.7631, Training accuracy: 76.0383, Val loss: 0.7921, Val accuracy: 72.9628, \n","\n","Epoch : 17\n","Training loss: 0.7317, Training accuracy: 77.5521, Val loss: 0.7853, Val accuracy: 73.3881, \n","\n","Epoch : 18\n","Training loss: 0.7135, Training accuracy: 78.4508, Val loss: 0.7483, Val accuracy: 74.4165, \n","\n","Epoch : 19\n","Training loss: 0.6998, Training accuracy: 78.7976, Val loss: 0.7418, Val accuracy: 74.7528, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.6198, Training accuracy: 82.2418, Val loss: 0.6792, Val accuracy: 76.5526, \n","\n","Epoch : 21\n","Training loss: 0.5987, Training accuracy: 83.1859, Val loss: 0.6707, Val accuracy: 77.1361, \n","\n","Epoch : 22\n","Training loss: 0.5856, Training accuracy: 83.4574, Val loss: 0.6482, Val accuracy: 78.1151, \n","\n","Epoch : 23\n","Training loss: 0.5805, Training accuracy: 83.7766, Val loss: 0.6618, Val accuracy: 77.2053, \n","Epoch : 24\n","Training loss: 0.5743, Training accuracy: 84.0991, Val loss: 0.6419, Val accuracy: 77.8778, \n","Epoch : 25\n","Training loss: 0.5695, Training accuracy: 84.3484, Val loss: 0.6515, Val accuracy: 77.4822, \n","Epoch : 26\n","Training loss: 0.5645, Training accuracy: 84.6443, Val loss: 0.6402, Val accuracy: 77.9470, \n","Epoch : 27\n","Training loss: 0.5620, Training accuracy: 84.7717, Val loss: 0.6438, Val accuracy: 78.2338, \n","\n","Epoch : 28\n","Training loss: 0.5576, Training accuracy: 84.8382, Val loss: 0.6487, Val accuracy: 77.7591, \n","Epoch : 29\n","Training loss: 0.5549, Training accuracy: 85.0754, Val loss: 0.6341, Val accuracy: 77.8976, \n","=\u003e Best: 78.2338\n","lamda = 0.2\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7522, Training accuracy: 35.7803, Val loss: 1.5831, Val accuracy: 41.6040, \n","\n","Epoch : 1\n","Training loss: 1.4399, Training accuracy: 48.2478, Val loss: 1.4275, Val accuracy: 49.1396, \n","\n","Epoch : 2\n","Training loss: 1.2355, Training accuracy: 56.0828, Val loss: 1.2371, Val accuracy: 56.3983, \n","\n","Epoch : 3\n","Training loss: 1.1055, Training accuracy: 61.0448, Val loss: 1.0881, Val accuracy: 61.7385, \n","\n","Epoch : 4\n","Training loss: 1.0020, Training accuracy: 64.8537, Val loss: 1.0493, Val accuracy: 63.3505, \n","\n","Epoch : 5\n","Training loss: 0.9327, Training accuracy: 67.4795, Val loss: 0.9637, Val accuracy: 67.0688, \n","\n","Epoch : 6\n","Training loss: 0.8653, Training accuracy: 70.0679, Val loss: 0.9403, Val accuracy: 67.2073, \n","\n","Epoch : 7\n","Training loss: 0.8279, Training accuracy: 71.4457, Val loss: 0.8791, Val accuracy: 69.3631, \n","\n","Epoch : 8\n","Training loss: 0.7759, Training accuracy: 73.3701, Val loss: 0.8352, Val accuracy: 71.6278, \n","\n","Epoch : 9\n","Training loss: 0.7471, Training accuracy: 74.3161, Val loss: 0.8415, Val accuracy: 71.3311, \n","Epoch : 10\n","Training loss: 0.7159, Training accuracy: 75.5541, Val loss: 0.8191, Val accuracy: 72.4189, \n","\n","Epoch : 11\n","Training loss: 0.6975, Training accuracy: 76.2430, Val loss: 0.7934, Val accuracy: 73.0518, \n","\n","Epoch : 12\n","Training loss: 0.6888, Training accuracy: 76.7048, Val loss: 0.8022, Val accuracy: 72.9134, \n","Epoch : 13\n","Training loss: 0.6595, Training accuracy: 77.8380, Val loss: 0.7751, Val accuracy: 73.3584, \n","\n","Epoch : 14\n","Training loss: 0.6387, Training accuracy: 78.4994, Val loss: 0.7137, Val accuracy: 75.4055, \n","\n","Epoch : 15\n","Training loss: 0.6204, Training accuracy: 79.0835, Val loss: 0.7166, Val accuracy: 75.6626, \n","\n","Epoch : 16\n","Training loss: 0.6046, Training accuracy: 79.8198, Val loss: 0.6784, Val accuracy: 77.3932, \n","\n","Epoch : 17\n","Training loss: 0.5791, Training accuracy: 80.9405, Val loss: 0.7054, Val accuracy: 76.5032, \n","Epoch : 18\n","Training loss: 0.5721, Training accuracy: 81.0104, Val loss: 0.6765, Val accuracy: 77.0866, \n","Epoch : 19\n","Training loss: 0.5574, Training accuracy: 81.6668, Val loss: 0.6811, Val accuracy: 76.6812, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.4820, Training accuracy: 84.4574, Val loss: 0.6222, Val accuracy: 79.5194, \n","\n","Epoch : 21\n","Training loss: 0.4576, Training accuracy: 85.5306, Val loss: 0.6121, Val accuracy: 79.6677, \n","\n","Epoch : 22\n","Training loss: 0.4496, Training accuracy: 85.8776, Val loss: 0.6139, Val accuracy: 79.6183, \n","Epoch : 23\n","Training loss: 0.4454, Training accuracy: 86.0124, Val loss: 0.5989, Val accuracy: 80.2314, \n","\n","Epoch : 24\n","Training loss: 0.4400, Training accuracy: 86.3468, Val loss: 0.5855, Val accuracy: 80.3006, \n","\n","Epoch : 25\n","Training loss: 0.4338, Training accuracy: 86.3119, Val loss: 0.5926, Val accuracy: 80.0435, \n","Epoch : 26\n","Training loss: 0.4323, Training accuracy: 86.4691, Val loss: 0.5932, Val accuracy: 80.2710, \n","Epoch : 27\n","Training loss: 0.4245, Training accuracy: 86.7312, Val loss: 0.5947, Val accuracy: 79.7765, \n","Epoch : 28\n","Training loss: 0.4229, Training accuracy: 86.8485, Val loss: 0.5889, Val accuracy: 80.4193, \n","\n","Epoch : 29\n","Training loss: 0.4245, Training accuracy: 86.9109, Val loss: 0.5902, Val accuracy: 79.9743, \n","=\u003e Best: 80.4193\n","lamda = 0.4\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7411, Training accuracy: 35.9150, Val loss: 1.5591, Val accuracy: 43.0380, \n","\n","Epoch : 1\n","Training loss: 1.4138, Training accuracy: 48.8768, Val loss: 1.3249, Val accuracy: 52.7492, \n","\n","Epoch : 2\n","Training loss: 1.1946, Training accuracy: 57.2359, Val loss: 1.2365, Val accuracy: 56.8434, \n","\n","Epoch : 3\n","Training loss: 1.0745, Training accuracy: 62.2329, Val loss: 1.0965, Val accuracy: 60.8683, \n","\n","Epoch : 4\n","Training loss: 0.9772, Training accuracy: 65.7872, Val loss: 1.0078, Val accuracy: 64.6855, \n","\n","Epoch : 5\n","Training loss: 0.9036, Training accuracy: 68.2907, Val loss: 0.9376, Val accuracy: 67.7907, \n","\n","Epoch : 6\n","Training loss: 0.8441, Training accuracy: 70.6170, Val loss: 0.8809, Val accuracy: 69.5609, \n","\n","Epoch : 7\n","Training loss: 0.7961, Training accuracy: 72.5539, Val loss: 0.8638, Val accuracy: 70.4608, \n","\n","Epoch : 8\n","Training loss: 0.7570, Training accuracy: 74.2637, Val loss: 0.8263, Val accuracy: 71.9244, \n","\n","Epoch : 9\n","Training loss: 0.7187, Training accuracy: 75.4892, Val loss: 0.7690, Val accuracy: 73.4078, \n","\n","Epoch : 10\n","Training loss: 0.6948, Training accuracy: 76.4502, Val loss: 0.7804, Val accuracy: 73.5562, \n","\n","Epoch : 11\n","Training loss: 0.6665, Training accuracy: 77.6533, Val loss: 0.7540, Val accuracy: 74.5550, \n","\n","Epoch : 12\n","Training loss: 0.6447, Training accuracy: 78.4719, Val loss: 0.7374, Val accuracy: 74.9308, \n","\n","Epoch : 13\n","Training loss: 0.6242, Training accuracy: 79.3530, Val loss: 0.7219, Val accuracy: 75.3560, \n","\n","Epoch : 14\n","Training loss: 0.6080, Training accuracy: 79.9271, Val loss: 0.7127, Val accuracy: 76.1373, \n","\n","Epoch : 15\n","Training loss: 0.5957, Training accuracy: 80.4887, Val loss: 0.6829, Val accuracy: 76.8790, \n","\n","Epoch : 16\n","Training loss: 0.5883, Training accuracy: 80.8906, Val loss: 0.6878, Val accuracy: 76.9581, \n","\n","Epoch : 17\n","Training loss: 0.5771, Training accuracy: 81.5720, Val loss: 0.6805, Val accuracy: 77.1460, \n","\n","Epoch : 18\n","Training loss: 0.5635, Training accuracy: 82.0562, Val loss: 0.6689, Val accuracy: 77.6207, \n","\n","Epoch : 19\n","Training loss: 0.5504, Training accuracy: 82.6253, Val loss: 0.6564, Val accuracy: 78.1448, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.4935, Training accuracy: 85.0290, Val loss: 0.6031, Val accuracy: 79.5194, \n","\n","Epoch : 21\n","Training loss: 0.4753, Training accuracy: 85.9550, Val loss: 0.5970, Val accuracy: 79.5392, \n","\n","Epoch : 22\n","Training loss: 0.4739, Training accuracy: 85.9675, Val loss: 0.5798, Val accuracy: 80.3402, \n","\n","Epoch : 23\n","Training loss: 0.4700, Training accuracy: 86.0823, Val loss: 0.5829, Val accuracy: 80.0138, \n","Epoch : 24\n","Training loss: 0.4628, Training accuracy: 86.3419, Val loss: 0.5768, Val accuracy: 80.4292, \n","\n","Epoch : 25\n","Training loss: 0.4588, Training accuracy: 86.7138, Val loss: 0.5719, Val accuracy: 80.3105, \n","Epoch : 26\n","Training loss: 0.4575, Training accuracy: 86.6638, Val loss: 0.5778, Val accuracy: 80.2512, \n","Epoch : 27\n","Training loss: 0.4557, Training accuracy: 86.7787, Val loss: 0.5738, Val accuracy: 80.0633, \n","Epoch : 28\n","Training loss: 0.4509, Training accuracy: 86.9509, Val loss: 0.5737, Val accuracy: 80.1226, \n","Epoch : 29\n","Training loss: 0.4539, Training accuracy: 86.9384, Val loss: 0.5739, Val accuracy: 80.6764, \n","\n","=\u003e Best: 80.6764\n","lamda = 0.6\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7179, Training accuracy: 36.6389, Val loss: 1.5514, Val accuracy: 43.3643, \n","\n","Epoch : 1\n","Training loss: 1.3829, Training accuracy: 50.0649, Val loss: 1.2896, Val accuracy: 53.1349, \n","\n","Epoch : 2\n","Training loss: 1.1603, Training accuracy: 58.9906, Val loss: 1.1535, Val accuracy: 59.7211, \n","\n","Epoch : 3\n","Training loss: 1.0136, Training accuracy: 64.1648, Val loss: 1.0258, Val accuracy: 63.9241, \n","\n","Epoch : 4\n","Training loss: 0.9160, Training accuracy: 68.1659, Val loss: 0.9438, Val accuracy: 67.0490, \n","\n","Epoch : 5\n","Training loss: 0.8408, Training accuracy: 70.7044, Val loss: 0.8887, Val accuracy: 68.8489, \n","\n","Epoch : 6\n","Training loss: 0.7859, Training accuracy: 72.8410, Val loss: 0.8394, Val accuracy: 71.4794, \n","\n","Epoch : 7\n","Training loss: 0.7404, Training accuracy: 74.6331, Val loss: 0.7901, Val accuracy: 72.8343, \n","\n","Epoch : 8\n","Training loss: 0.7115, Training accuracy: 75.7738, Val loss: 0.7765, Val accuracy: 73.4771, \n","\n","Epoch : 9\n","Training loss: 0.6786, Training accuracy: 77.0892, Val loss: 0.7724, Val accuracy: 73.6946, \n","\n","Epoch : 10\n","Training loss: 0.6706, Training accuracy: 77.5434, Val loss: 0.7463, Val accuracy: 75.1879, \n","\n","Epoch : 11\n","Training loss: 0.6413, Training accuracy: 78.6741, Val loss: 0.7120, Val accuracy: 75.2571, \n","\n","Epoch : 12\n","Training loss: 0.6265, Training accuracy: 79.5702, Val loss: 0.6986, Val accuracy: 75.8900, \n","\n","Epoch : 13\n","Training loss: 0.6094, Training accuracy: 80.2391, Val loss: 0.6722, Val accuracy: 76.7010, \n","\n","Epoch : 14\n","Training loss: 0.6002, Training accuracy: 80.7708, Val loss: 0.6682, Val accuracy: 77.1262, \n","\n","Epoch : 15\n","Training loss: 0.5889, Training accuracy: 81.0653, Val loss: 0.6824, Val accuracy: 76.3944, \n","Epoch : 16\n","Training loss: 0.5830, Training accuracy: 81.4771, Val loss: 0.6603, Val accuracy: 77.3240, \n","\n","Epoch : 17\n","Training loss: 0.5728, Training accuracy: 81.9564, Val loss: 0.6533, Val accuracy: 77.4525, \n","\n","Epoch : 18\n","Training loss: 0.5639, Training accuracy: 82.4930, Val loss: 0.6399, Val accuracy: 77.9272, \n","\n","Epoch : 19\n","Training loss: 0.5593, Training accuracy: 82.6428, Val loss: 0.6250, Val accuracy: 78.4513, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5121, Training accuracy: 84.8692, Val loss: 0.5954, Val accuracy: 79.5985, \n","\n","Epoch : 21\n","Training loss: 0.4981, Training accuracy: 85.2137, Val loss: 0.5835, Val accuracy: 80.0435, \n","\n","Epoch : 22\n","Training loss: 0.4970, Training accuracy: 85.4882, Val loss: 0.5699, Val accuracy: 80.5083, \n","\n","Epoch : 23\n","Training loss: 0.4940, Training accuracy: 85.4483, Val loss: 0.5780, Val accuracy: 80.1820, \n","Epoch : 24\n","Training loss: 0.4913, Training accuracy: 85.6929, Val loss: 0.5682, Val accuracy: 80.8643, \n","\n","Epoch : 25\n","Training loss: 0.4912, Training accuracy: 85.5581, Val loss: 0.5869, Val accuracy: 79.7963, \n","Epoch : 26\n","Training loss: 0.4903, Training accuracy: 85.7503, Val loss: 0.5717, Val accuracy: 80.2116, \n","Epoch : 27\n","Training loss: 0.4877, Training accuracy: 85.8826, Val loss: 0.5697, Val accuracy: 80.5676, \n","Epoch : 28\n","Training loss: 0.4853, Training accuracy: 86.2295, Val loss: 0.5694, Val accuracy: 80.3402, \n","Epoch : 29\n","Training loss: 0.4838, Training accuracy: 86.0373, Val loss: 0.5679, Val accuracy: 80.7457, \n","=\u003e Best: 80.8643\n","lamda = 0.8\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7179, Training accuracy: 36.5141, Val loss: 1.5178, Val accuracy: 44.6499, \n","\n","Epoch : 1\n","Training loss: 1.3642, Training accuracy: 50.5666, Val loss: 1.3525, Val accuracy: 51.2362, \n","\n","Epoch : 2\n","Training loss: 1.1547, Training accuracy: 59.0480, Val loss: 1.1070, Val accuracy: 61.2144, \n","\n","Epoch : 3\n","Training loss: 1.0018, Training accuracy: 64.4843, Val loss: 0.9893, Val accuracy: 65.0119, \n","\n","Epoch : 4\n","Training loss: 0.9093, Training accuracy: 67.6992, Val loss: 0.9334, Val accuracy: 67.2765, \n","\n","Epoch : 5\n","Training loss: 0.8310, Training accuracy: 70.7393, Val loss: 0.8692, Val accuracy: 69.6203, \n","\n","Epoch : 6\n","Training loss: 0.7785, Training accuracy: 72.5689, Val loss: 0.8651, Val accuracy: 70.5498, \n","\n","Epoch : 7\n","Training loss: 0.7376, Training accuracy: 73.8593, Val loss: 0.8167, Val accuracy: 71.9343, \n","\n","Epoch : 8\n","Training loss: 0.7074, Training accuracy: 75.4593, Val loss: 0.7766, Val accuracy: 73.3386, \n","\n","Epoch : 9\n","Training loss: 0.6734, Training accuracy: 76.7622, Val loss: 0.7543, Val accuracy: 73.8627, \n","\n","Epoch : 10\n","Training loss: 0.6542, Training accuracy: 77.7781, Val loss: 0.7284, Val accuracy: 75.0989, \n","\n","Epoch : 11\n","Training loss: 0.6380, Training accuracy: 78.3871, Val loss: 0.7093, Val accuracy: 75.7714, \n","\n","Epoch : 12\n","Training loss: 0.6262, Training accuracy: 79.0186, Val loss: 0.7205, Val accuracy: 75.1978, \n","Epoch : 13\n","Training loss: 0.6138, Training accuracy: 79.6451, Val loss: 0.7050, Val accuracy: 75.7812, \n","\n","Epoch : 14\n","Training loss: 0.6033, Training accuracy: 80.2092, Val loss: 0.6997, Val accuracy: 76.1076, \n","\n","Epoch : 15\n","Training loss: 0.5899, Training accuracy: 80.6410, Val loss: 0.6671, Val accuracy: 77.0273, \n","\n","Epoch : 16\n","Training loss: 0.5856, Training accuracy: 80.6485, Val loss: 0.6769, Val accuracy: 76.8592, \n","Epoch : 17\n","Training loss: 0.5785, Training accuracy: 81.2899, Val loss: 0.6465, Val accuracy: 77.9964, \n","\n","Epoch : 18\n","Training loss: 0.5687, Training accuracy: 81.7467, Val loss: 0.6674, Val accuracy: 77.0075, \n","Epoch : 19\n","Training loss: 0.5682, Training accuracy: 81.9339, Val loss: 0.6722, Val accuracy: 77.3339, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5301, Training accuracy: 83.5039, Val loss: 0.6045, Val accuracy: 79.3612, \n","\n","Epoch : 21\n","Training loss: 0.5206, Training accuracy: 83.8833, Val loss: 0.6042, Val accuracy: 79.0447, \n","Epoch : 22\n","Training loss: 0.5179, Training accuracy: 83.9956, Val loss: 0.6047, Val accuracy: 78.9656, \n","Epoch : 23\n","Training loss: 0.5152, Training accuracy: 84.0081, Val loss: 0.5996, Val accuracy: 79.3414, \n","Epoch : 24\n","Training loss: 0.5106, Training accuracy: 84.3176, Val loss: 0.6018, Val accuracy: 79.2623, \n","Epoch : 25\n","Training loss: 0.5112, Training accuracy: 84.2277, Val loss: 0.5968, Val accuracy: 79.1337, \n","Epoch : 26\n","Training loss: 0.5104, Training accuracy: 84.5023, Val loss: 0.6035, Val accuracy: 79.1930, \n","Epoch : 27\n","Training loss: 0.5099, Training accuracy: 84.4574, Val loss: 0.5942, Val accuracy: 79.8754, \n","\n","Epoch : 28\n","Training loss: 0.5076, Training accuracy: 84.5298, Val loss: 0.5943, Val accuracy: 79.4699, \n","Epoch : 29\n","Training loss: 0.5073, Training accuracy: 84.6121, Val loss: 0.6023, Val accuracy: 79.1238, \n","=\u003e Best: 79.8754\n"]},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://github.com/pytorch/vision/zipball/v0.13.1\" to /root/.cache/torch/hub/v0.13.1.zip\n"]},{"name":"stdout","output_type":"stream","text":["0\n","Training loss: 1.8048, Training accuracy: 33.4590, Val loss: 1.5977, Val accuracy: 42.7809, \n","\n","1\n","Training loss: 1.4601, Training accuracy: 46.8426, Val loss: 1.3801, Val accuracy: 49.8912, \n","\n","2\n","Training loss: 1.2785, Training accuracy: 54.3705, Val loss: 1.2178, Val accuracy: 56.9620, \n","\n","3\n","Training loss: 1.1362, Training accuracy: 59.7769, Val loss: 1.1226, Val accuracy: 61.4023, \n","\n","4\n","Training loss: 1.0419, Training accuracy: 63.3786, Val loss: 1.0776, Val accuracy: 62.6681, \n","\n","5\n","Training loss: 0.9790, Training accuracy: 65.7947, Val loss: 0.9867, Val accuracy: 64.9130, \n","\n","6\n","Training loss: 0.9174, Training accuracy: 67.8215, Val loss: 0.9446, Val accuracy: 67.3556, \n","\n","7\n","Training loss: 0.8590, Training accuracy: 70.1003, Val loss: 0.8937, Val accuracy: 69.2939, \n","\n","8\n","Training loss: 0.8180, Training accuracy: 71.8251, Val loss: 0.8826, Val accuracy: 69.5609, \n","\n","9\n","Training loss: 0.7896, Training accuracy: 72.7137, Val loss: 0.8669, Val accuracy: 69.5411, \n","10\n","Training loss: 0.7692, Training accuracy: 73.4699, Val loss: 0.8266, Val accuracy: 71.4893, \n","\n","11\n","Training loss: 0.7337, Training accuracy: 74.7604, Val loss: 0.8131, Val accuracy: 72.7650, \n","\n","12\n","Training loss: 0.7222, Training accuracy: 74.9401, Val loss: 0.8274, Val accuracy: 72.3596, \n","13\n","Training loss: 0.7267, Training accuracy: 75.3419, Val loss: 0.8342, Val accuracy: 70.9553, \n","14\n","Training loss: 0.6976, Training accuracy: 76.2330, Val loss: 0.7572, Val accuracy: 74.7726, \n","\n","15\n","Training loss: 0.6400, Training accuracy: 78.3397, Val loss: 0.7490, Val accuracy: 75.0000, \n","\n","16\n","Training loss: 0.6199, Training accuracy: 78.9287, Val loss: 0.7475, Val accuracy: 75.0989, \n","\n","17\n","Training loss: 0.5930, Training accuracy: 79.6001, Val loss: 0.7272, Val accuracy: 75.3956, \n","\n","18\n","Training loss: 0.5763, Training accuracy: 80.0120, Val loss: 0.7144, Val accuracy: 76.1373, \n","\n","19\n","Training loss: 0.5687, Training accuracy: 80.4313, Val loss: 0.7423, Val accuracy: 75.2769, \n","Current learning rate has decayed to 0.010000\n","20\n","Training loss: 0.4685, Training accuracy: 83.7909, Val loss: 0.6337, Val accuracy: 78.5107, \n","\n","21\n","Training loss: 0.4384, Training accuracy: 84.5897, Val loss: 0.6061, Val accuracy: 79.4502, \n","\n","22\n","Training loss: 0.4221, Training accuracy: 85.2885, Val loss: 0.6113, Val accuracy: 79.7271, \n","\n","23\n","Training loss: 0.4121, Training accuracy: 85.7678, Val loss: 0.6264, Val accuracy: 79.3809, \n","24\n","Training loss: 0.4039, Training accuracy: 85.7977, Val loss: 0.6093, Val accuracy: 79.5392, \n","25\n","Training loss: 0.3984, Training accuracy: 86.0972, Val loss: 0.6000, Val accuracy: 79.7765, \n","\n","26\n","Training loss: 0.3918, Training accuracy: 86.3918, Val loss: 0.6239, Val accuracy: 79.6677, \n","27\n","Training loss: 0.3916, Training accuracy: 86.3843, Val loss: 0.5990, Val accuracy: 80.2314, \n","\n","28\n","Training loss: 0.3811, Training accuracy: 86.6014, Val loss: 0.5987, Val accuracy: 80.3303, \n","\n","29\n","Training loss: 0.3784, Training accuracy: 86.8710, Val loss: 0.6000, Val accuracy: 80.0534, \n","=\u003e Best: 80.3303\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 13:59:08 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 13:59:13 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmputc5tw3y/model/data, flavor: pytorch), fall back to return ['torch==1.12.1', 'cloudpickle==1.5.0']. Set logging level to DEBUG to see the full traceback.\n","2022/11/14 13:59:17 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.2\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1627\n","baseline churn = 0.1716\n","student accuracy = 0.792\n","baseline accuracy = 0.8076\n","teacher accuracy = 0.7863\n","student wlr = 1.031301498413086\n","baseline wlr = 1.390109896659851\n","churn ratio = 0.9481351981351982\n","student good_churn = 0.0626\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0003\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 13:59:21 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","2022/11/14 13:59:21 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 13:59:25 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 13:59:29 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.4\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.167\n","baseline churn = 0.1716\n","student accuracy = 0.7889\n","baseline accuracy = 0.8076\n","teacher accuracy = 0.7863\n","student wlr = 1.0197869539260864\n","baseline wlr = 1.390109896659851\n","churn ratio = 0.9731934731934733\n","student good_churn = 0.067\n","student bad_churn = 0.0002\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0003\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 13:59:33 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 13:59:33 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 13:59:37 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 13:59:41 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.6\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1646\n","baseline churn = 0.1716\n","student accuracy = 0.7885\n","baseline accuracy = 0.8076\n","teacher accuracy = 0.7863\n","student wlr = 1.0739495754241943\n","baseline wlr = 1.390109896659851\n","churn ratio = 0.9592074592074592\n","student good_churn = 0.0639\n","student bad_churn = 0.0002\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0003\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 13:59:44 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 13:59:45 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 13:59:48 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 13:59:53 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.8\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1665\n","baseline churn = 0.1716\n","student accuracy = 0.7809\n","baseline accuracy = 0.8076\n","teacher accuracy = 0.7863\n","student wlr = 0.9567233324050903\n","baseline wlr = 1.390109896659851\n","churn ratio = 0.9702797202797203\n","student good_churn = 0.0619\n","student bad_churn = 0.0\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0003\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 13:59:56 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:00:01 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:00:05 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:00:09 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.2\n","\n","student churn = 0.164\n","baseline churn = 0.1625\n","student accuracy = 0.804\n","baseline accuracy = 0.808\n","teacher accuracy = 0.791\n","student wlr = 1.2620320320129395\n","baseline wlr = 1.3142329454421997\n","churn ratio = 1.0092307692307692\n","student good_churn = 0.0708\n","student bad_churn = 0.0003\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:00:13 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:00:13 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:00:17 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:00:21 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.4\n","\n","student churn = 0.1456\n","baseline churn = 0.1625\n","student accuracy = 0.8097\n","baseline accuracy = 0.808\n","teacher accuracy = 0.791\n","student wlr = 1.5011235475540161\n","baseline wlr = 1.3142329454421997\n","churn ratio = 0.896\n","student good_churn = 0.0668\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:00:25 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:00:25 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:00:29 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:00:33 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.6\n","\n","student churn = 0.1373\n","baseline churn = 0.1625\n","student accuracy = 0.8076\n","baseline accuracy = 0.808\n","teacher accuracy = 0.791\n","student wlr = 1.4562647342681885\n","baseline wlr = 1.3142329454421997\n","churn ratio = 0.8449230769230769\n","student good_churn = 0.0616\n","student bad_churn = 0.0\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:00:37 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:00:37 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:00:41 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:00:45 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.8\n","\n","student churn = 0.1278\n","baseline churn = 0.1625\n","student accuracy = 0.8005\n","baseline accuracy = 0.808\n","teacher accuracy = 0.791\n","student wlr = 1.3679012060165405\n","baseline wlr = 1.3142329454421997\n","churn ratio = 0.7864615384615384\n","student good_churn = 0.0554\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:00:49 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 0\n","Training loss: 1.8209, Training accuracy: 32.6507, Val loss: 1.6359, Val accuracy: 39.9328, \n","\n","Epoch : 1\n","Training loss: 1.5537, Training accuracy: 43.5561, Val loss: 1.4786, Val accuracy: 45.1543, \n","\n","Epoch : 2\n","Training loss: 1.3651, Training accuracy: 51.2134, Val loss: 1.3163, Val accuracy: 52.4525, \n","\n","Epoch : 3\n","Training loss: 1.2396, Training accuracy: 56.1835, Val loss: 1.2298, Val accuracy: 55.3006, \n","\n","Epoch : 4\n","Training loss: 1.1449, Training accuracy: 59.4836, Val loss: 1.1626, Val accuracy: 59.3651, \n","\n","Epoch : 5\n","Training loss: 1.0535, Training accuracy: 62.8923, Val loss: 1.0876, Val accuracy: 62.5791, \n","\n","Epoch : 6\n","Training loss: 1.0006, Training accuracy: 64.9701, Val loss: 1.0289, Val accuracy: 64.7152, \n","\n","Epoch : 7\n","Training loss: 0.9412, Training accuracy: 67.0047, Val loss: 1.0363, Val accuracy: 63.8054, \n","Epoch : 8\n","Training loss: 0.9257, Training accuracy: 67.5831, Val loss: 0.9336, Val accuracy: 67.2468, \n","\n","Epoch : 9\n","Training loss: 0.8621, Training accuracy: 70.1740, Val loss: 0.9387, Val accuracy: 67.7314, \n","\n","Epoch : 10\n","Training loss: 0.8402, Training accuracy: 71.0716, Val loss: 0.9095, Val accuracy: 68.9775, \n","\n","Epoch : 11\n","Training loss: 0.7981, Training accuracy: 72.4468, Val loss: 0.9106, Val accuracy: 68.3544, \n","Epoch : 12\n","Training loss: 0.7685, Training accuracy: 73.1150, Val loss: 0.8728, Val accuracy: 70.1642, \n","\n","Epoch : 13\n","Training loss: 1.0705, Training accuracy: 62.7261, Val loss: 0.9588, Val accuracy: 67.3457, \n","Epoch : 14\n","Training loss: 0.8289, Training accuracy: 70.9574, Val loss: 0.8632, Val accuracy: 70.0455, \n","Epoch : 15\n","Training loss: 0.7689, Training accuracy: 73.2547, Val loss: 0.8640, Val accuracy: 70.9059, \n","\n","Epoch : 16\n","Training loss: 0.7297, Training accuracy: 74.9523, Val loss: 0.8259, Val accuracy: 72.3101, \n","\n","Epoch : 17\n","Training loss: 0.6973, Training accuracy: 75.8765, Val loss: 0.8110, Val accuracy: 71.9244, \n","Epoch : 18\n","Training loss: 0.6716, Training accuracy: 76.6512, Val loss: 0.8029, Val accuracy: 72.5475, \n","\n","Epoch : 19\n","Training loss: 0.6475, Training accuracy: 77.5089, Val loss: 0.7969, Val accuracy: 72.9529, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5409, Training accuracy: 81.1082, Val loss: 0.7252, Val accuracy: 76.0582, \n","\n","Epoch : 21\n","Training loss: 0.5058, Training accuracy: 82.4125, Val loss: 0.7047, Val accuracy: 76.7801, \n","\n","Epoch : 22\n","Training loss: 0.4910, Training accuracy: 82.9887, Val loss: 0.6772, Val accuracy: 77.3734, \n","\n","Epoch : 23\n","Training loss: 0.4866, Training accuracy: 83.0652, Val loss: 0.6946, Val accuracy: 76.6119, \n","Epoch : 24\n","Training loss: 0.4745, Training accuracy: 83.6558, Val loss: 0.6781, Val accuracy: 77.1855, \n","Epoch : 25\n","Training loss: 0.4658, Training accuracy: 83.6525, Val loss: 0.6912, Val accuracy: 77.1657, \n","Epoch : 26\n","Training loss: 0.4627, Training accuracy: 83.6913, Val loss: 0.6971, Val accuracy: 76.8592, \n","Epoch : 27\n","Training loss: 0.4554, Training accuracy: 84.1367, Val loss: 0.6760, Val accuracy: 77.6998, \n","\n","Epoch : 28\n","Training loss: 0.4480, Training accuracy: 84.1057, Val loss: 0.6901, Val accuracy: 77.1756, \n","Epoch : 29\n","Training loss: 0.4456, Training accuracy: 84.2509, Val loss: 0.6939, Val accuracy: 77.3932, \n","=\u003e Best: 77.6998\n","alpha = 0.2\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8484, Training accuracy: 31.9814, Val loss: 1.6771, Val accuracy: 39.0328, \n","\n","Epoch : 1\n","Training loss: 1.5758, Training accuracy: 42.6152, Val loss: 1.4885, Val accuracy: 44.4422, \n","\n","Epoch : 2\n","Training loss: 1.4094, Training accuracy: 49.2775, Val loss: 1.3433, Val accuracy: 51.9086, \n","\n","Epoch : 3\n","Training loss: 1.2782, Training accuracy: 55.1186, Val loss: 1.2682, Val accuracy: 54.1733, \n","\n","Epoch : 4\n","Training loss: 1.1745, Training accuracy: 58.8231, Val loss: 1.1594, Val accuracy: 59.2563, \n","\n","Epoch : 5\n","Training loss: 1.0985, Training accuracy: 61.4993, Val loss: 1.1189, Val accuracy: 60.3936, \n","\n","Epoch : 6\n","Training loss: 1.0282, Training accuracy: 64.1201, Val loss: 1.0447, Val accuracy: 63.4494, \n","\n","Epoch : 7\n","Training loss: 0.9705, Training accuracy: 66.5171, Val loss: 1.0347, Val accuracy: 63.5384, \n","\n","Epoch : 8\n","Training loss: 0.9341, Training accuracy: 67.8557, Val loss: 0.9381, Val accuracy: 67.7314, \n","\n","Epoch : 9\n","Training loss: 0.8853, Training accuracy: 69.4625, Val loss: 0.9417, Val accuracy: 66.9502, \n","Epoch : 10\n","Training loss: 0.9786, Training accuracy: 66.4184, Val loss: 1.0133, Val accuracy: 64.5965, \n","Epoch : 11\n","Training loss: 0.9094, Training accuracy: 68.8819, Val loss: 0.9140, Val accuracy: 68.3050, \n","\n","Epoch : 12\n","Training loss: 0.8292, Training accuracy: 71.6190, Val loss: 0.9001, Val accuracy: 68.7401, \n","\n","Epoch : 13\n","Training loss: 0.7877, Training accuracy: 73.2480, Val loss: 0.8566, Val accuracy: 70.8366, \n","\n","Epoch : 14\n","Training loss: 0.7498, Training accuracy: 74.5290, Val loss: 0.8423, Val accuracy: 71.0146, \n","\n","Epoch : 15\n","Training loss: 0.7470, Training accuracy: 75.1086, Val loss: 0.8309, Val accuracy: 71.2619, \n","\n","Epoch : 16\n","Training loss: 0.7073, Training accuracy: 76.1037, Val loss: 0.8255, Val accuracy: 71.3805, \n","\n","Epoch : 17\n","Training loss: 0.7005, Training accuracy: 76.6656, Val loss: 0.8060, Val accuracy: 72.1519, \n","\n","Epoch : 18\n","Training loss: 0.6803, Training accuracy: 77.3138, Val loss: 0.7850, Val accuracy: 73.2397, \n","\n","Epoch : 19\n","Training loss: 0.6472, Training accuracy: 78.5461, Val loss: 0.7690, Val accuracy: 73.9320, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5510, Training accuracy: 82.0612, Val loss: 0.7013, Val accuracy: 75.9296, \n","\n","Epoch : 21\n","Training loss: 0.5242, Training accuracy: 82.9765, Val loss: 0.6874, Val accuracy: 76.7306, \n","\n","Epoch : 22\n","Training loss: 0.5219, Training accuracy: 82.9100, Val loss: 0.6739, Val accuracy: 76.9284, \n","\n","Epoch : 23\n","Training loss: 0.5057, Training accuracy: 83.5805, Val loss: 0.6766, Val accuracy: 76.9779, \n","\n","Epoch : 24\n","Training loss: 0.4983, Training accuracy: 84.0182, Val loss: 0.6764, Val accuracy: 77.1163, \n","\n","Epoch : 25\n","Training loss: 0.4917, Training accuracy: 84.1445, Val loss: 0.6766, Val accuracy: 77.2350, \n","\n","Epoch : 26\n","Training loss: 0.4854, Training accuracy: 84.3805, Val loss: 0.6787, Val accuracy: 77.0372, \n","Epoch : 27\n","Training loss: 0.4813, Training accuracy: 84.3595, Val loss: 0.6680, Val accuracy: 76.9779, \n","Epoch : 28\n","Training loss: 0.4751, Training accuracy: 84.5966, Val loss: 0.6605, Val accuracy: 77.3932, \n","\n","Epoch : 29\n","Training loss: 0.4722, Training accuracy: 84.6764, Val loss: 0.6673, Val accuracy: 77.3141, \n","=\u003e Best: 77.3932\n","alpha = 0.4\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8295, Training accuracy: 32.1875, Val loss: 1.6824, Val accuracy: 38.1725, \n","\n","Epoch : 1\n","Training loss: 1.5746, Training accuracy: 43.0419, Val loss: 1.5291, Val accuracy: 44.0467, \n","\n","Epoch : 2\n","Training loss: 1.3756, Training accuracy: 50.9264, Val loss: 1.3022, Val accuracy: 54.1139, \n","\n","Epoch : 3\n","Training loss: 1.2500, Training accuracy: 56.2289, Val loss: 1.2207, Val accuracy: 56.5961, \n","\n","Epoch : 4\n","Training loss: 1.1525, Training accuracy: 60.0355, Val loss: 1.1567, Val accuracy: 59.5036, \n","\n","Epoch : 5\n","Training loss: 1.0783, Training accuracy: 63.1549, Val loss: 1.0440, Val accuracy: 63.4197, \n","\n","Epoch : 6\n","Training loss: 1.0158, Training accuracy: 65.4555, Val loss: 1.0202, Val accuracy: 64.2010, \n","\n","Epoch : 7\n","Training loss: 0.9707, Training accuracy: 67.0501, Val loss: 1.0218, Val accuracy: 65.3976, \n","\n","Epoch : 8\n","Training loss: 0.9172, Training accuracy: 68.9539, Val loss: 0.9391, Val accuracy: 67.5336, \n","\n","Epoch : 9\n","Training loss: 0.8819, Training accuracy: 70.4344, Val loss: 0.9926, Val accuracy: 66.0008, \n","Epoch : 10\n","Training loss: 0.9293, Training accuracy: 68.8575, Val loss: 0.9144, Val accuracy: 68.4731, \n","\n","Epoch : 11\n","Training loss: 0.8429, Training accuracy: 71.6312, Val loss: 0.9058, Val accuracy: 68.5918, \n","\n","Epoch : 12\n","Training loss: 0.8076, Training accuracy: 73.1549, Val loss: 0.8390, Val accuracy: 71.5289, \n","\n","Epoch : 13\n","Training loss: 0.7785, Training accuracy: 74.3739, Val loss: 0.8641, Val accuracy: 70.5993, \n","Epoch : 14\n","Training loss: 0.7593, Training accuracy: 74.6620, Val loss: 0.8438, Val accuracy: 70.8070, \n","Epoch : 15\n","Training loss: 0.7372, Training accuracy: 76.0129, Val loss: 0.8105, Val accuracy: 72.2310, \n","\n","Epoch : 16\n","Training loss: 0.7169, Training accuracy: 76.6223, Val loss: 0.7758, Val accuracy: 72.9233, \n","\n","Epoch : 17\n","Training loss: 0.6954, Training accuracy: 77.3925, Val loss: 0.7729, Val accuracy: 73.7243, \n","\n","Epoch : 18\n","Training loss: 0.6873, Training accuracy: 77.8989, Val loss: 0.7619, Val accuracy: 74.3473, \n","\n","Epoch : 19\n","Training loss: 0.6649, Training accuracy: 78.5317, Val loss: 0.7636, Val accuracy: 74.1100, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5760, Training accuracy: 82.0257, Val loss: 0.6767, Val accuracy: 76.6416, \n","\n","Epoch : 21\n","Training loss: 0.5475, Training accuracy: 82.9344, Val loss: 0.6647, Val accuracy: 77.1064, \n","\n","Epoch : 22\n","Training loss: 0.5400, Training accuracy: 83.6181, Val loss: 0.6554, Val accuracy: 77.5415, \n","\n","Epoch : 23\n","Training loss: 0.5294, Training accuracy: 84.1489, Val loss: 0.6552, Val accuracy: 77.9371, \n","\n","Epoch : 24\n","Training loss: 0.5190, Training accuracy: 84.2088, Val loss: 0.6712, Val accuracy: 76.9482, \n","Epoch : 25\n","Training loss: 0.5148, Training accuracy: 84.5567, Val loss: 0.6536, Val accuracy: 77.5119, \n","Epoch : 26\n","Training loss: 0.5155, Training accuracy: 84.6465, Val loss: 0.6661, Val accuracy: 77.1657, \n","Epoch : 27\n","Training loss: 0.5109, Training accuracy: 84.7285, Val loss: 0.6469, Val accuracy: 78.4118, \n","\n","Epoch : 28\n","Training loss: 0.5029, Training accuracy: 85.0554, Val loss: 0.6560, Val accuracy: 77.7591, \n","Epoch : 29\n","Training loss: 0.4967, Training accuracy: 85.2017, Val loss: 0.6471, Val accuracy: 78.2536, \n","=\u003e Best: 78.4118\n","alpha = 0.6\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8190, Training accuracy: 33.2879, Val loss: 1.6577, Val accuracy: 37.6582, \n","\n","Epoch : 1\n","Training loss: 1.5465, Training accuracy: 45.0089, Val loss: 1.4322, Val accuracy: 47.6661, \n","\n","Epoch : 2\n","Training loss: 1.3605, Training accuracy: 51.6090, Val loss: 1.3291, Val accuracy: 52.3438, \n","\n","Epoch : 3\n","Training loss: 1.2532, Training accuracy: 56.2434, Val loss: 1.2001, Val accuracy: 57.2686, \n","\n","Epoch : 4\n","Training loss: 1.1481, Training accuracy: 60.6316, Val loss: 1.1488, Val accuracy: 60.2551, \n","\n","Epoch : 5\n","Training loss: 1.0775, Training accuracy: 63.1516, Val loss: 1.0786, Val accuracy: 62.3418, \n","\n","Epoch : 6\n","Training loss: 1.0174, Training accuracy: 65.7114, Val loss: 1.0295, Val accuracy: 63.5779, \n","\n","Epoch : 7\n","Training loss: 0.9657, Training accuracy: 67.7704, Val loss: 0.9475, Val accuracy: 66.9205, \n","\n","Epoch : 8\n","Training loss: 0.9239, Training accuracy: 69.6221, Val loss: 0.9326, Val accuracy: 67.6721, \n","\n","Epoch : 9\n","Training loss: 0.8804, Training accuracy: 71.3974, Val loss: 0.8808, Val accuracy: 68.8192, \n","\n","Epoch : 10\n","Training loss: 0.8648, Training accuracy: 71.9559, Val loss: 0.8718, Val accuracy: 69.9862, \n","\n","Epoch : 11\n","Training loss: 0.8283, Training accuracy: 73.3865, Val loss: 0.8534, Val accuracy: 70.9355, \n","\n","Epoch : 12\n","Training loss: 0.8031, Training accuracy: 74.4326, Val loss: 0.8501, Val accuracy: 70.1246, \n","Epoch : 13\n","Training loss: 0.7757, Training accuracy: 75.1718, Val loss: 0.8302, Val accuracy: 71.4399, \n","\n","Epoch : 14\n","Training loss: 0.7620, Training accuracy: 75.9829, Val loss: 0.8325, Val accuracy: 71.0740, \n","Epoch : 15\n","Training loss: 0.7723, Training accuracy: 75.7347, Val loss: 1.0594, Val accuracy: 66.6139, \n","Epoch : 16\n","Training loss: 0.7651, Training accuracy: 75.9364, Val loss: 0.7976, Val accuracy: 72.6562, \n","\n","Epoch : 17\n","Training loss: 0.7180, Training accuracy: 77.9521, Val loss: 0.7324, Val accuracy: 75.0000, \n","\n","Epoch : 18\n","Training loss: 0.6959, Training accuracy: 78.6137, Val loss: 0.7749, Val accuracy: 73.7836, \n","Epoch : 19\n","Training loss: 0.6789, Training accuracy: 79.4603, Val loss: 0.7399, Val accuracy: 75.0890, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5953, Training accuracy: 82.7383, Val loss: 0.6766, Val accuracy: 76.7900, \n","\n","Epoch : 21\n","Training loss: 0.5737, Training accuracy: 83.3677, Val loss: 0.6366, Val accuracy: 78.2041, \n","\n","Epoch : 22\n","Training loss: 0.5630, Training accuracy: 83.8331, Val loss: 0.6434, Val accuracy: 77.2449, \n","Epoch : 23\n","Training loss: 0.5573, Training accuracy: 84.0791, Val loss: 0.6275, Val accuracy: 78.0953, \n","Epoch : 24\n","Training loss: 0.5505, Training accuracy: 84.2575, Val loss: 0.6476, Val accuracy: 77.9668, \n","Epoch : 25\n","Training loss: 0.5438, Training accuracy: 84.6110, Val loss: 0.6488, Val accuracy: 77.3932, \n","Epoch : 26\n","Training loss: 0.5398, Training accuracy: 84.9302, Val loss: 0.6358, Val accuracy: 78.4909, \n","\n","Epoch : 27\n","Training loss: 0.5369, Training accuracy: 85.3624, Val loss: 0.6301, Val accuracy: 78.4118, \n","Epoch : 28\n","Training loss: 0.5293, Training accuracy: 85.2715, Val loss: 0.6199, Val accuracy: 79.0150, \n","\n","Epoch : 29\n","Training loss: 0.5266, Training accuracy: 85.6084, Val loss: 0.6441, Val accuracy: 77.6998, \n","=\u003e Best: 79.0150\n","alpha = 0.8\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8335, Training accuracy: 32.6640, Val loss: 1.6457, Val accuracy: 39.7547, \n","\n","Epoch : 1\n","Training loss: 1.5736, Training accuracy: 43.2469, Val loss: 1.4991, Val accuracy: 46.0443, \n","\n","Epoch : 2\n","Training loss: 1.4072, Training accuracy: 50.1285, Val loss: 1.3477, Val accuracy: 51.8592, \n","\n","Epoch : 3\n","Training loss: 1.2657, Training accuracy: 55.8644, Val loss: 1.1697, Val accuracy: 58.0202, \n","\n","Epoch : 4\n","Training loss: 1.1643, Training accuracy: 60.4222, Val loss: 1.1224, Val accuracy: 59.7805, \n","\n","Epoch : 5\n","Training loss: 1.0772, Training accuracy: 63.8132, Val loss: 1.0865, Val accuracy: 61.2638, \n","\n","Epoch : 6\n","Training loss: 1.0159, Training accuracy: 66.2090, Val loss: 1.0111, Val accuracy: 63.4296, \n","\n","Epoch : 7\n","Training loss: 0.9715, Training accuracy: 68.3810, Val loss: 0.9305, Val accuracy: 67.4644, \n","\n","Epoch : 8\n","Training loss: 0.9217, Training accuracy: 70.1252, Val loss: 0.9166, Val accuracy: 67.5831, \n","\n","Epoch : 9\n","Training loss: 0.8886, Training accuracy: 71.1813, Val loss: 0.8866, Val accuracy: 69.0566, \n","\n","Epoch : 10\n","Training loss: 0.8539, Training accuracy: 72.6651, Val loss: 0.8527, Val accuracy: 70.4015, \n","\n","Epoch : 11\n","Training loss: 0.8239, Training accuracy: 73.9628, Val loss: 0.8538, Val accuracy: 70.5202, \n","\n","Epoch : 12\n","Training loss: 0.8075, Training accuracy: 74.8593, Val loss: 0.8417, Val accuracy: 70.8861, \n","\n","Epoch : 13\n","Training loss: 0.7915, Training accuracy: 75.2139, Val loss: 0.7881, Val accuracy: 72.9925, \n","\n","Epoch : 14\n","Training loss: 0.7811, Training accuracy: 75.8178, Val loss: 0.7829, Val accuracy: 72.9134, \n","Epoch : 15\n","Training loss: 0.7621, Training accuracy: 76.8384, Val loss: 0.7556, Val accuracy: 73.6847, \n","\n","Epoch : 16\n","Training loss: 0.7389, Training accuracy: 77.4690, Val loss: 0.7557, Val accuracy: 73.3782, \n","Epoch : 17\n","Training loss: 0.7226, Training accuracy: 78.3322, Val loss: 0.7666, Val accuracy: 73.2990, \n","Epoch : 18\n","Training loss: 0.7123, Training accuracy: 78.8176, Val loss: 0.7485, Val accuracy: 74.1891, \n","\n","Epoch : 19\n","Training loss: 0.7022, Training accuracy: 79.3285, Val loss: 0.7174, Val accuracy: 75.2472, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.6212, Training accuracy: 82.2119, Val loss: 0.6594, Val accuracy: 77.1163, \n","\n","Epoch : 21\n","Training loss: 0.5970, Training accuracy: 83.7035, Val loss: 0.6547, Val accuracy: 77.6009, \n","\n","Epoch : 22\n","Training loss: 0.5920, Training accuracy: 83.8974, Val loss: 0.6419, Val accuracy: 78.2437, \n","\n","Epoch : 23\n","Training loss: 0.5835, Training accuracy: 84.0747, Val loss: 0.6355, Val accuracy: 78.1250, \n","Epoch : 24\n","Training loss: 0.5859, Training accuracy: 84.3739, Val loss: 0.6557, Val accuracy: 77.0767, \n","Epoch : 25\n","Training loss: 0.5759, Training accuracy: 84.5445, Val loss: 0.6397, Val accuracy: 77.9767, \n","Epoch : 26\n","Training loss: 0.5732, Training accuracy: 84.7562, Val loss: 0.6431, Val accuracy: 77.6899, \n","Epoch : 27\n","Training loss: 0.5687, Training accuracy: 84.7883, Val loss: 0.6351, Val accuracy: 78.1744, \n","Epoch : 28\n","Training loss: 0.5674, Training accuracy: 84.7839, Val loss: 0.6288, Val accuracy: 78.3129, \n","\n","Epoch : 29\n","Training loss: 0.5660, Training accuracy: 85.2582, Val loss: 0.6269, Val accuracy: 78.3821, \n","\n","=\u003e Best: 78.3821\n","lamda = 0.2\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7838, Training accuracy: 34.1254, Val loss: 1.5785, Val accuracy: 41.3271, \n","\n","Epoch : 1\n","Training loss: 1.4547, Training accuracy: 47.3018, Val loss: 1.3453, Val accuracy: 50.8109, \n","\n","Epoch : 2\n","Training loss: 1.2399, Training accuracy: 56.0678, Val loss: 1.2517, Val accuracy: 56.0819, \n","\n","Epoch : 3\n","Training loss: 1.1008, Training accuracy: 61.5665, Val loss: 1.0699, Val accuracy: 62.8461, \n","\n","Epoch : 4\n","Training loss: 0.9949, Training accuracy: 65.4228, Val loss: 1.0039, Val accuracy: 65.3382, \n","\n","Epoch : 5\n","Training loss: 0.9197, Training accuracy: 68.0486, Val loss: 0.9542, Val accuracy: 66.9798, \n","\n","Epoch : 6\n","Training loss: 0.8657, Training accuracy: 70.2376, Val loss: 0.9150, Val accuracy: 68.4434, \n","\n","Epoch : 7\n","Training loss: 0.8312, Training accuracy: 71.3334, Val loss: 0.8637, Val accuracy: 70.1246, \n","\n","Epoch : 8\n","Training loss: 0.7915, Training accuracy: 72.8235, Val loss: 0.8351, Val accuracy: 71.3014, \n","\n","Epoch : 9\n","Training loss: 0.7435, Training accuracy: 74.6506, Val loss: 0.8260, Val accuracy: 72.1123, \n","\n","Epoch : 10\n","Training loss: 0.7203, Training accuracy: 75.3320, Val loss: 0.7760, Val accuracy: 73.5661, \n","\n","Epoch : 11\n","Training loss: 0.6903, Training accuracy: 76.6049, Val loss: 0.7733, Val accuracy: 73.8825, \n","\n","Epoch : 12\n","Training loss: 0.6607, Training accuracy: 77.6533, Val loss: 0.7566, Val accuracy: 74.8418, \n","\n","Epoch : 13\n","Training loss: 0.6363, Training accuracy: 78.4470, Val loss: 0.7464, Val accuracy: 74.4165, \n","Epoch : 14\n","Training loss: 0.6246, Training accuracy: 79.1933, Val loss: 0.7277, Val accuracy: 74.8912, \n","\n","Epoch : 15\n","Training loss: 0.6111, Training accuracy: 79.7449, Val loss: 0.6900, Val accuracy: 76.9680, \n","\n","Epoch : 16\n","Training loss: 0.6117, Training accuracy: 79.7324, Val loss: 0.7241, Val accuracy: 75.6725, \n","Epoch : 17\n","Training loss: 0.5865, Training accuracy: 80.7533, Val loss: 0.6755, Val accuracy: 77.4426, \n","\n","Epoch : 18\n","Training loss: 0.5709, Training accuracy: 81.3573, Val loss: 0.6862, Val accuracy: 77.0965, \n","Epoch : 19\n","Training loss: 0.5517, Training accuracy: 82.1136, Val loss: 0.6647, Val accuracy: 76.8196, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.4813, Training accuracy: 84.9516, Val loss: 0.5976, Val accuracy: 79.9150, \n","\n","Epoch : 21\n","Training loss: 0.4616, Training accuracy: 85.4383, Val loss: 0.6087, Val accuracy: 79.4601, \n","Epoch : 22\n","Training loss: 0.4503, Training accuracy: 85.9400, Val loss: 0.5872, Val accuracy: 79.7765, \n","Epoch : 23\n","Training loss: 0.4477, Training accuracy: 86.2245, Val loss: 0.5933, Val accuracy: 79.9545, \n","\n","Epoch : 24\n","Training loss: 0.4402, Training accuracy: 86.5740, Val loss: 0.5810, Val accuracy: 80.6369, \n","\n","Epoch : 25\n","Training loss: 0.4360, Training accuracy: 86.6439, Val loss: 0.5946, Val accuracy: 79.8754, \n","Epoch : 26\n","Training loss: 0.4363, Training accuracy: 86.6464, Val loss: 0.5742, Val accuracy: 80.7061, \n","\n","Epoch : 27\n","Training loss: 0.4338, Training accuracy: 86.8086, Val loss: 0.5893, Val accuracy: 80.0633, \n","Epoch : 28\n","Training loss: 0.4268, Training accuracy: 87.1206, Val loss: 0.5744, Val accuracy: 80.9731, \n","\n","Epoch : 29\n","Training loss: 0.4191, Training accuracy: 87.3852, Val loss: 0.5812, Val accuracy: 80.7061, \n","=\u003e Best: 80.9731\n","lamda = 0.4\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7224, Training accuracy: 36.3968, Val loss: 1.5239, Val accuracy: 45.1938, \n","\n","Epoch : 1\n","Training loss: 1.3730, Training accuracy: 50.7713, Val loss: 1.3459, Val accuracy: 52.4822, \n","\n","Epoch : 2\n","Training loss: 1.1683, Training accuracy: 58.3217, Val loss: 1.1550, Val accuracy: 60.0870, \n","\n","Epoch : 3\n","Training loss: 1.0506, Training accuracy: 63.4684, Val loss: 1.0520, Val accuracy: 62.7868, \n","\n","Epoch : 4\n","Training loss: 0.9430, Training accuracy: 67.0253, Val loss: 0.9633, Val accuracy: 67.1282, \n","\n","Epoch : 5\n","Training loss: 0.8656, Training accuracy: 70.0904, Val loss: 0.8751, Val accuracy: 69.7093, \n","\n","Epoch : 6\n","Training loss: 0.8254, Training accuracy: 71.5730, Val loss: 0.8649, Val accuracy: 70.5202, \n","\n","Epoch : 7\n","Training loss: 0.7686, Training accuracy: 73.9567, Val loss: 0.8146, Val accuracy: 72.4090, \n","\n","Epoch : 8\n","Training loss: 0.7284, Training accuracy: 75.1498, Val loss: 0.7914, Val accuracy: 72.9826, \n","\n","Epoch : 9\n","Training loss: 0.7051, Training accuracy: 76.2305, Val loss: 0.7504, Val accuracy: 74.1001, \n","\n","Epoch : 10\n","Training loss: 0.6769, Training accuracy: 77.4286, Val loss: 0.7377, Val accuracy: 74.3671, \n","\n","Epoch : 11\n","Training loss: 0.6535, Training accuracy: 78.3771, Val loss: 0.7041, Val accuracy: 75.9988, \n","\n","Epoch : 12\n","Training loss: 0.6330, Training accuracy: 79.2532, Val loss: 0.6834, Val accuracy: 76.6218, \n","\n","Epoch : 13\n","Training loss: 0.6261, Training accuracy: 79.4803, Val loss: 0.6919, Val accuracy: 76.1274, \n","Epoch : 14\n","Training loss: 0.6077, Training accuracy: 80.4962, Val loss: 0.7033, Val accuracy: 76.1373, \n","Epoch : 15\n","Training loss: 0.6023, Training accuracy: 80.7034, Val loss: 0.6697, Val accuracy: 77.3141, \n","\n","Epoch : 16\n","Training loss: 0.5965, Training accuracy: 81.0778, Val loss: 0.6876, Val accuracy: 76.9877, \n","Epoch : 17\n","Training loss: 0.5766, Training accuracy: 81.7342, Val loss: 0.6661, Val accuracy: 77.6701, \n","\n","Epoch : 18\n","Training loss: 0.5724, Training accuracy: 82.1810, Val loss: 0.6440, Val accuracy: 78.3722, \n","\n","Epoch : 19\n","Training loss: 0.5622, Training accuracy: 82.6852, Val loss: 0.6539, Val accuracy: 77.8778, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5054, Training accuracy: 84.9740, Val loss: 0.5964, Val accuracy: 79.7172, \n","\n","Epoch : 21\n","Training loss: 0.4892, Training accuracy: 85.6430, Val loss: 0.5795, Val accuracy: 79.8754, \n","\n","Epoch : 22\n","Training loss: 0.4847, Training accuracy: 85.9350, Val loss: 0.5698, Val accuracy: 80.6863, \n","\n","Epoch : 23\n","Training loss: 0.4805, Training accuracy: 86.1072, Val loss: 0.5740, Val accuracy: 80.1721, \n","Epoch : 24\n","Training loss: 0.4761, Training accuracy: 86.4417, Val loss: 0.5732, Val accuracy: 80.4490, \n","Epoch : 25\n","Training loss: 0.4748, Training accuracy: 86.4667, Val loss: 0.5737, Val accuracy: 80.2116, \n","Epoch : 26\n","Training loss: 0.4700, Training accuracy: 86.6089, Val loss: 0.5801, Val accuracy: 79.9644, \n","Epoch : 27\n","Training loss: 0.4713, Training accuracy: 86.6189, Val loss: 0.5833, Val accuracy: 79.7864, \n","Epoch : 28\n","Training loss: 0.4691, Training accuracy: 86.6738, Val loss: 0.5711, Val accuracy: 80.5281, \n","Epoch : 29\n","Training loss: 0.4664, Training accuracy: 86.8211, Val loss: 0.5886, Val accuracy: 79.9347, \n","=\u003e Best: 80.6863\n","lamda = 0.6\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7700, Training accuracy: 35.0115, Val loss: 1.5519, Val accuracy: 43.5918, \n","\n","Epoch : 1\n","Training loss: 1.4398, Training accuracy: 48.4225, Val loss: 1.3133, Val accuracy: 52.8382, \n","\n","Epoch : 2\n","Training loss: 1.2132, Training accuracy: 56.8291, Val loss: 1.1723, Val accuracy: 58.9300, \n","\n","Epoch : 3\n","Training loss: 1.0604, Training accuracy: 62.7771, Val loss: 1.0464, Val accuracy: 63.8548, \n","\n","Epoch : 4\n","Training loss: 0.9456, Training accuracy: 66.7232, Val loss: 0.9326, Val accuracy: 67.7512, \n","\n","Epoch : 5\n","Training loss: 0.8605, Training accuracy: 69.9905, Val loss: 0.8847, Val accuracy: 69.0961, \n","\n","Epoch : 6\n","Training loss: 0.8086, Training accuracy: 72.0572, Val loss: 0.8629, Val accuracy: 70.1048, \n","\n","Epoch : 7\n","Training loss: 0.7582, Training accuracy: 73.9791, Val loss: 0.8128, Val accuracy: 72.3002, \n","\n","Epoch : 8\n","Training loss: 0.7244, Training accuracy: 75.5491, Val loss: 0.8031, Val accuracy: 72.3794, \n","\n","Epoch : 9\n","Training loss: 0.6931, Training accuracy: 76.7871, Val loss: 0.7427, Val accuracy: 74.2583, \n","\n","Epoch : 10\n","Training loss: 0.6722, Training accuracy: 77.6832, Val loss: 0.7352, Val accuracy: 75.1978, \n","\n","Epoch : 11\n","Training loss: 0.6495, Training accuracy: 78.6367, Val loss: 0.7483, Val accuracy: 75.3066, \n","\n","Epoch : 12\n","Training loss: 0.6390, Training accuracy: 79.2931, Val loss: 0.7118, Val accuracy: 75.7714, \n","\n","Epoch : 13\n","Training loss: 0.6219, Training accuracy: 80.0993, Val loss: 0.6835, Val accuracy: 76.4339, \n","\n","Epoch : 14\n","Training loss: 0.6132, Training accuracy: 80.7034, Val loss: 0.6977, Val accuracy: 76.0384, \n","Epoch : 15\n","Training loss: 0.6011, Training accuracy: 80.9580, Val loss: 0.6552, Val accuracy: 77.4525, \n","\n","Epoch : 16\n","Training loss: 0.6030, Training accuracy: 80.9804, Val loss: 0.6687, Val accuracy: 77.1064, \n","Epoch : 17\n","Training loss: 0.5863, Training accuracy: 81.7866, Val loss: 0.6545, Val accuracy: 77.6503, \n","\n","Epoch : 18\n","Training loss: 0.5780, Training accuracy: 82.0312, Val loss: 0.6403, Val accuracy: 78.1250, \n","\n","Epoch : 19\n","Training loss: 0.5711, Training accuracy: 82.5754, Val loss: 0.6344, Val accuracy: 78.2536, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5318, Training accuracy: 84.2377, Val loss: 0.5873, Val accuracy: 79.5886, \n","\n","Epoch : 21\n","Training loss: 0.5218, Training accuracy: 84.9641, Val loss: 0.5924, Val accuracy: 79.6875, \n","\n","Epoch : 22\n","Training loss: 0.5156, Training accuracy: 84.9466, Val loss: 0.5908, Val accuracy: 79.6974, \n","\n","Epoch : 23\n","Training loss: 0.5134, Training accuracy: 85.4308, Val loss: 0.5825, Val accuracy: 79.8754, \n","\n","Epoch : 24\n","Training loss: 0.5082, Training accuracy: 85.6729, Val loss: 0.5983, Val accuracy: 79.6381, \n","Epoch : 25\n","Training loss: 0.5107, Training accuracy: 85.3285, Val loss: 0.5878, Val accuracy: 79.9248, \n","\n","Epoch : 26\n","Training loss: 0.5055, Training accuracy: 85.4583, Val loss: 0.5813, Val accuracy: 80.4490, \n","\n","Epoch : 27\n","Training loss: 0.5073, Training accuracy: 85.4358, Val loss: 0.5799, Val accuracy: 80.2215, \n","Epoch : 28\n","Training loss: 0.5025, Training accuracy: 85.7378, Val loss: 0.5763, Val accuracy: 80.5775, \n","\n","Epoch : 29\n","Training loss: 0.5029, Training accuracy: 85.8576, Val loss: 0.5825, Val accuracy: 79.8853, \n","=\u003e Best: 80.5775\n","lamda = 0.8\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7167, Training accuracy: 36.8910, Val loss: 1.5732, Val accuracy: 43.2160, \n","\n","Epoch : 1\n","Training loss: 1.3737, Training accuracy: 50.4518, Val loss: 1.3257, Val accuracy: 52.9272, \n","\n","Epoch : 2\n","Training loss: 1.1644, Training accuracy: 58.5363, Val loss: 1.1641, Val accuracy: 59.7903, \n","\n","Epoch : 3\n","Training loss: 1.0166, Training accuracy: 64.1623, Val loss: 1.0353, Val accuracy: 62.9549, \n","\n","Epoch : 4\n","Training loss: 0.9048, Training accuracy: 68.0137, Val loss: 0.9423, Val accuracy: 66.9601, \n","\n","Epoch : 5\n","Training loss: 0.8237, Training accuracy: 71.0613, Val loss: 0.8850, Val accuracy: 69.4818, \n","\n","Epoch : 6\n","Training loss: 0.7860, Training accuracy: 72.7910, Val loss: 0.8445, Val accuracy: 70.8960, \n","\n","Epoch : 7\n","Training loss: 0.7397, Training accuracy: 74.4833, Val loss: 0.7989, Val accuracy: 72.8639, \n","\n","Epoch : 8\n","Training loss: 0.7010, Training accuracy: 75.8761, Val loss: 0.7837, Val accuracy: 72.7156, \n","Epoch : 9\n","Training loss: 0.6815, Training accuracy: 76.8096, Val loss: 0.7572, Val accuracy: 73.5562, \n","\n","Epoch : 10\n","Training loss: 0.6616, Training accuracy: 77.4636, Val loss: 0.7487, Val accuracy: 74.1891, \n","\n","Epoch : 11\n","Training loss: 0.6539, Training accuracy: 78.4919, Val loss: 0.7295, Val accuracy: 75.2868, \n","\n","Epoch : 12\n","Training loss: 0.6390, Training accuracy: 79.0360, Val loss: 0.7052, Val accuracy: 75.7714, \n","\n","Epoch : 13\n","Training loss: 0.6243, Training accuracy: 79.2806, Val loss: 0.6854, Val accuracy: 76.6021, \n","\n","Epoch : 14\n","Training loss: 0.6137, Training accuracy: 80.2591, Val loss: 0.6981, Val accuracy: 76.2164, \n","Epoch : 15\n","Training loss: 0.5966, Training accuracy: 80.6959, Val loss: 0.6773, Val accuracy: 76.9086, \n","\n","Epoch : 16\n","Training loss: 0.5991, Training accuracy: 80.8831, Val loss: 0.6696, Val accuracy: 76.6416, \n","Epoch : 17\n","Training loss: 0.5893, Training accuracy: 81.1926, Val loss: 0.6683, Val accuracy: 76.8987, \n","Epoch : 18\n","Training loss: 0.5822, Training accuracy: 81.6094, Val loss: 0.6563, Val accuracy: 77.5020, \n","\n","Epoch : 19\n","Training loss: 0.5770, Training accuracy: 81.7367, Val loss: 0.6527, Val accuracy: 77.3833, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5440, Training accuracy: 83.3317, Val loss: 0.6166, Val accuracy: 78.5601, \n","\n","Epoch : 21\n","Training loss: 0.5375, Training accuracy: 83.4964, Val loss: 0.6160, Val accuracy: 78.4711, \n","Epoch : 22\n","Training loss: 0.5351, Training accuracy: 83.6686, Val loss: 0.5993, Val accuracy: 79.8062, \n","\n","Epoch : 23\n","Training loss: 0.5326, Training accuracy: 83.8733, Val loss: 0.6145, Val accuracy: 78.7085, \n","Epoch : 24\n","Training loss: 0.5300, Training accuracy: 83.8508, Val loss: 0.6043, Val accuracy: 79.2326, \n","Epoch : 25\n","Training loss: 0.5303, Training accuracy: 83.9282, Val loss: 0.6092, Val accuracy: 78.4415, \n","Epoch : 26\n","Training loss: 0.5254, Training accuracy: 84.1354, Val loss: 0.6032, Val accuracy: 79.1040, \n","Epoch : 27\n","Training loss: 0.5287, Training accuracy: 84.1653, Val loss: 0.6084, Val accuracy: 79.1040, \n","Epoch : 28\n","Training loss: 0.5255, Training accuracy: 84.2402, Val loss: 0.6165, Val accuracy: 78.4415, \n","Epoch : 29\n","Training loss: 0.5266, Training accuracy: 84.2452, Val loss: 0.5957, Val accuracy: 79.5985, \n","=\u003e Best: 79.8062\n","0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.13.1\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7869, Training accuracy: 34.0880, Val loss: 1.6270, Val accuracy: 37.6780, \n","\n","1\n","Training loss: 1.4640, Training accuracy: 46.8151, Val loss: 1.3923, Val accuracy: 50.0297, \n","\n","2\n","Training loss: 1.2914, Training accuracy: 54.2507, Val loss: 1.2770, Val accuracy: 54.4007, \n","\n","3\n","Training loss: 1.1616, Training accuracy: 59.0031, Val loss: 1.1777, Val accuracy: 58.2971, \n","\n","4\n","Training loss: 1.0640, Training accuracy: 62.5824, Val loss: 1.0802, Val accuracy: 61.7583, \n","\n","5\n","Training loss: 1.0009, Training accuracy: 65.1782, Val loss: 1.0492, Val accuracy: 62.4506, \n","\n","6\n","Training loss: 0.9303, Training accuracy: 67.8065, Val loss: 0.9626, Val accuracy: 66.6535, \n","\n","7\n","Training loss: 0.8870, Training accuracy: 69.1194, Val loss: 0.9544, Val accuracy: 67.5040, \n","\n","8\n","Training loss: 0.8367, Training accuracy: 70.8342, Val loss: 0.8787, Val accuracy: 69.6598, \n","\n","9\n","Training loss: 0.7903, Training accuracy: 72.5614, Val loss: 0.8720, Val accuracy: 70.1839, \n","\n","10\n","Training loss: 0.7714, Training accuracy: 73.3102, Val loss: 0.8593, Val accuracy: 70.3125, \n","\n","11\n","Training loss: 0.8133, Training accuracy: 71.6878, Val loss: 0.8478, Val accuracy: 70.7180, \n","\n","12\n","Training loss: 0.7361, Training accuracy: 74.3810, Val loss: 0.8196, Val accuracy: 72.3794, \n","\n","13\n","Training loss: 0.6857, Training accuracy: 76.3279, Val loss: 0.7990, Val accuracy: 73.2694, \n","\n","14\n","Training loss: 0.6627, Training accuracy: 77.1216, Val loss: 0.7965, Val accuracy: 72.7551, \n","15\n","Training loss: 0.6435, Training accuracy: 77.6607, Val loss: 0.7725, Val accuracy: 74.4759, \n","\n","16\n","Training loss: 0.6160, Training accuracy: 78.7615, Val loss: 0.7397, Val accuracy: 74.8615, \n","\n","17\n","Training loss: 0.6080, Training accuracy: 79.2856, Val loss: 0.8027, Val accuracy: 72.7057, \n","18\n","Training loss: 0.5966, Training accuracy: 79.5303, Val loss: 0.7019, Val accuracy: 76.0285, \n","\n","19\n","Training loss: 0.5760, Training accuracy: 80.2441, Val loss: 0.7131, Val accuracy: 75.7120, \n","Current learning rate has decayed to 0.010000\n","20\n","Training loss: 0.4744, Training accuracy: 83.5488, Val loss: 0.6543, Val accuracy: 78.5898, \n","\n","21\n","Training loss: 0.4539, Training accuracy: 84.3151, Val loss: 0.6392, Val accuracy: 78.2041, \n","22\n","Training loss: 0.4331, Training accuracy: 84.8692, Val loss: 0.6271, Val accuracy: 79.1832, \n","\n","23\n","Training loss: 0.4276, Training accuracy: 84.9990, Val loss: 0.6303, Val accuracy: 78.9953, \n","24\n","Training loss: 0.4157, Training accuracy: 85.5356, Val loss: 0.6315, Val accuracy: 78.9260, \n","25\n","Training loss: 0.4108, Training accuracy: 85.6080, Val loss: 0.6248, Val accuracy: 79.1238, \n","26\n","Training loss: 0.4036, Training accuracy: 85.8052, Val loss: 0.6353, Val accuracy: 79.0744, \n","27\n","Training loss: 0.4059, Training accuracy: 85.8676, Val loss: 0.6419, Val accuracy: 78.6392, \n","28\n","Training loss: 0.3973, Training accuracy: 86.1322, Val loss: 0.6312, Val accuracy: 79.4304, \n","\n","29\n","Training loss: 0.3875, Training accuracy: 86.2770, Val loss: 0.6276, Val accuracy: 79.1733, \n","=\u003e Best: 79.4304\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:54:30 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:54:34 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:54:38 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.2\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1741\n","baseline churn = 0.1735\n","student accuracy = 0.7761\n","baseline accuracy = 0.8032\n","teacher accuracy = 0.7789\n","student wlr = 0.9293078184127808\n","baseline wlr = 1.4410163164138794\n","churn ratio = 1.0034582132564842\n","student good_churn = 0.0631\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:54:42 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:54:42 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:54:46 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:54:50 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.4\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1694\n","baseline churn = 0.1735\n","student accuracy = 0.7817\n","baseline accuracy = 0.8032\n","teacher accuracy = 0.7789\n","student wlr = 1.0455259084701538\n","baseline wlr = 1.4410163164138794\n","churn ratio = 0.9763688760806917\n","student good_churn = 0.0666\n","student bad_churn = 0.0\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:54:54 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:54:54 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:54:58 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:55:02 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.6\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1682\n","baseline churn = 0.1735\n","student accuracy = 0.7863\n","baseline accuracy = 0.8032\n","teacher accuracy = 0.7789\n","student wlr = 1.125619888305664\n","baseline wlr = 1.4410163164138794\n","churn ratio = 0.9694524495677234\n","student good_churn = 0.0681\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:55:06 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:55:06 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:55:10 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:55:14 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.8\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1641\n","baseline churn = 0.1735\n","student accuracy = 0.7892\n","baseline accuracy = 0.8032\n","teacher accuracy = 0.7789\n","student wlr = 1.0823723077774048\n","baseline wlr = 1.4410163164138794\n","churn ratio = 0.945821325648415\n","student good_churn = 0.0657\n","student bad_churn = 0.0002\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:55:18 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:55:23 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:55:26 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:55:31 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.2\n","\n","student churn = 0.1601\n","baseline churn = 0.1716\n","student accuracy = 0.8126\n","baseline accuracy = 0.8\n","teacher accuracy = 0.7825\n","student wlr = 1.770975112915039\n","baseline wlr = 1.2996575832366943\n","churn ratio = 0.932983682983683\n","student good_churn = 0.0781\n","student bad_churn = 0.0002\n","baseline good_churn = 0.0002\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:55:34 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:55:35 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:55:38 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:55:43 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.4\n","\n","student churn = 0.1479\n","baseline churn = 0.1716\n","student accuracy = 0.8092\n","baseline accuracy = 0.8\n","teacher accuracy = 0.7825\n","student wlr = 1.735576868057251\n","baseline wlr = 1.2996575832366943\n","churn ratio = 0.8618881118881119\n","student good_churn = 0.0722\n","student bad_churn = 0.0002\n","baseline good_churn = 0.0002\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:55:46 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:55:47 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:55:50 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:55:55 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.6\n","\n","student churn = 0.1402\n","baseline churn = 0.1716\n","student accuracy = 0.804\n","baseline accuracy = 0.8\n","teacher accuracy = 0.7825\n","student wlr = 1.563380241394043\n","baseline wlr = 1.2996575832366943\n","churn ratio = 0.8170163170163169\n","student good_churn = 0.0666\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0002\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:55:58 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 14:55:59 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:56:02 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 14:56:07 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.8\n","\n","student churn = 0.123\n","baseline churn = 0.1716\n","student accuracy = 0.7948\n","baseline accuracy = 0.8\n","teacher accuracy = 0.7825\n","student wlr = 1.3798449039459229\n","baseline wlr = 1.2996575832366943\n","churn ratio = 0.7167832167832168\n","student good_churn = 0.0534\n","student bad_churn = 0.0\n","baseline good_churn = 0.0002\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 14:56:10 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 0\n","Training loss: 1.8165, Training accuracy: 32.9854, Val loss: 1.6665, Val accuracy: 38.8944, \n","\n","Epoch : 1\n","Training loss: 1.5529, Training accuracy: 43.3599, Val loss: 1.5179, Val accuracy: 45.6092, \n","\n","Epoch : 2\n","Training loss: 1.3531, Training accuracy: 51.9116, Val loss: 1.3434, Val accuracy: 52.7987, \n","\n","Epoch : 3\n","Training loss: 1.2243, Training accuracy: 56.8418, Val loss: 1.2257, Val accuracy: 57.1005, \n","\n","Epoch : 4\n","Training loss: 1.1324, Training accuracy: 60.0776, Val loss: 1.1454, Val accuracy: 59.7706, \n","\n","Epoch : 5\n","Training loss: 1.0737, Training accuracy: 62.4523, Val loss: 1.0717, Val accuracy: 62.6187, \n","\n","Epoch : 6\n","Training loss: 0.9969, Training accuracy: 65.3125, Val loss: 1.0406, Val accuracy: 63.5186, \n","\n","Epoch : 7\n","Training loss: 0.9527, Training accuracy: 66.7852, Val loss: 1.0137, Val accuracy: 65.1009, \n","\n","Epoch : 8\n","Training loss: 0.8929, Training accuracy: 69.0780, Val loss: 0.9323, Val accuracy: 68.0973, \n","\n","Epoch : 9\n","Training loss: 0.8625, Training accuracy: 70.1086, Val loss: 0.9465, Val accuracy: 66.9007, \n","Epoch : 10\n","Training loss: 0.8294, Training accuracy: 71.6489, Val loss: 0.8920, Val accuracy: 69.2346, \n","\n","Epoch : 11\n","Training loss: 0.7904, Training accuracy: 72.5565, Val loss: 0.8982, Val accuracy: 69.3137, \n","\n","Epoch : 12\n","Training loss: 0.7650, Training accuracy: 73.6259, Val loss: 0.8599, Val accuracy: 70.5795, \n","\n","Epoch : 13\n","Training loss: 0.7490, Training accuracy: 74.2996, Val loss: 0.8412, Val accuracy: 71.2816, \n","\n","Epoch : 14\n","Training loss: 0.7324, Training accuracy: 74.8737, Val loss: 0.8525, Val accuracy: 71.1630, \n","Epoch : 15\n","Training loss: 0.7007, Training accuracy: 75.8511, Val loss: 0.8645, Val accuracy: 70.4015, \n","Epoch : 16\n","Training loss: 0.6885, Training accuracy: 76.2965, Val loss: 0.7873, Val accuracy: 73.4276, \n","\n","Epoch : 17\n","Training loss: 0.6563, Training accuracy: 77.4501, Val loss: 0.7888, Val accuracy: 73.5067, \n","\n","Epoch : 18\n","Training loss: 0.6431, Training accuracy: 77.8834, Val loss: 0.7824, Val accuracy: 73.2199, \n","Epoch : 19\n","Training loss: 0.6289, Training accuracy: 78.4098, Val loss: 0.8051, Val accuracy: 73.1112, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5210, Training accuracy: 81.9614, Val loss: 0.6844, Val accuracy: 76.7801, \n","\n","Epoch : 21\n","Training loss: 0.4742, Training accuracy: 83.6469, Val loss: 0.6807, Val accuracy: 77.4723, \n","\n","Epoch : 22\n","Training loss: 0.4620, Training accuracy: 83.8553, Val loss: 0.6759, Val accuracy: 77.8481, \n","\n","Epoch : 23\n","Training loss: 0.4504, Training accuracy: 84.2908, Val loss: 0.6808, Val accuracy: 77.3438, \n","Epoch : 24\n","Training loss: 0.4444, Training accuracy: 84.8426, Val loss: 0.6920, Val accuracy: 77.2646, \n","Epoch : 25\n","Training loss: 0.4354, Training accuracy: 84.8061, Val loss: 0.6604, Val accuracy: 78.5601, \n","\n","Epoch : 26\n","Training loss: 0.4285, Training accuracy: 85.0565, Val loss: 0.6691, Val accuracy: 77.6503, \n","Epoch : 27\n","Training loss: 0.4211, Training accuracy: 85.4399, Val loss: 0.6744, Val accuracy: 77.6899, \n","Epoch : 28\n","Training loss: 0.4116, Training accuracy: 85.6283, Val loss: 0.6718, Val accuracy: 77.6503, \n","Epoch : 29\n","Training loss: 0.4082, Training accuracy: 85.8400, Val loss: 0.6746, Val accuracy: 78.2931, \n","=\u003e Best: 78.5601\n","alpha = 0.2\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8340, Training accuracy: 32.3149, Val loss: 1.7060, Val accuracy: 37.0352, \n","\n","Epoch : 1\n","Training loss: 1.5535, Training accuracy: 43.7788, Val loss: 1.4946, Val accuracy: 45.3323, \n","\n","Epoch : 2\n","Training loss: 1.3944, Training accuracy: 50.2881, Val loss: 1.3019, Val accuracy: 51.9086, \n","\n","Epoch : 3\n","Training loss: 1.2450, Training accuracy: 55.6549, Val loss: 1.2637, Val accuracy: 55.3896, \n","\n","Epoch : 4\n","Training loss: 1.1433, Training accuracy: 60.2150, Val loss: 1.1640, Val accuracy: 58.6926, \n","\n","Epoch : 5\n","Training loss: 1.0764, Training accuracy: 62.6474, Val loss: 1.1115, Val accuracy: 61.6396, \n","\n","Epoch : 6\n","Training loss: 1.0015, Training accuracy: 65.1008, Val loss: 1.0207, Val accuracy: 64.1911, \n","\n","Epoch : 7\n","Training loss: 0.9452, Training accuracy: 67.5155, Val loss: 0.9842, Val accuracy: 66.0700, \n","\n","Epoch : 8\n","Training loss: 0.8997, Training accuracy: 69.1567, Val loss: 0.9471, Val accuracy: 67.3161, \n","\n","Epoch : 9\n","Training loss: 0.8646, Training accuracy: 70.4865, Val loss: 0.9041, Val accuracy: 69.1258, \n","\n","Epoch : 10\n","Training loss: 0.8237, Training accuracy: 71.9337, Val loss: 0.8603, Val accuracy: 70.0752, \n","\n","Epoch : 11\n","Training loss: 0.7971, Training accuracy: 73.0519, Val loss: 0.8531, Val accuracy: 70.4510, \n","\n","Epoch : 12\n","Training loss: 0.7730, Training accuracy: 73.6137, Val loss: 0.8521, Val accuracy: 70.3521, \n","Epoch : 13\n","Training loss: 0.7411, Training accuracy: 74.9601, Val loss: 0.8241, Val accuracy: 71.5684, \n","\n","Epoch : 14\n","Training loss: 0.7452, Training accuracy: 75.0532, Val loss: 0.8569, Val accuracy: 70.9454, \n","Epoch : 15\n","Training loss: 0.7069, Training accuracy: 76.4029, Val loss: 0.8053, Val accuracy: 72.7354, \n","\n","Epoch : 16\n","Training loss: 0.6771, Training accuracy: 77.4900, Val loss: 0.8016, Val accuracy: 73.0716, \n","\n","Epoch : 17\n","Training loss: 0.6456, Training accuracy: 78.6913, Val loss: 0.7524, Val accuracy: 74.3572, \n","\n","Epoch : 18\n","Training loss: 0.6474, Training accuracy: 78.4187, Val loss: 1.0125, Val accuracy: 68.4335, \n","Epoch : 19\n","Training loss: 0.8751, Training accuracy: 70.6084, Val loss: 0.8180, Val accuracy: 72.0332, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.6192, Training accuracy: 79.4548, Val loss: 0.7236, Val accuracy: 74.8121, \n","\n","Epoch : 21\n","Training loss: 0.5820, Training accuracy: 80.5463, Val loss: 0.7228, Val accuracy: 75.3263, \n","\n","Epoch : 22\n","Training loss: 0.5679, Training accuracy: 81.0051, Val loss: 0.7044, Val accuracy: 76.1472, \n","\n","Epoch : 23\n","Training loss: 0.5514, Training accuracy: 81.6401, Val loss: 0.7132, Val accuracy: 75.5637, \n","Epoch : 24\n","Training loss: 0.5425, Training accuracy: 82.1986, Val loss: 0.6954, Val accuracy: 76.5131, \n","\n","Epoch : 25\n","Training loss: 0.5323, Training accuracy: 82.2296, Val loss: 0.6914, Val accuracy: 76.4834, \n","Epoch : 26\n","Training loss: 0.5278, Training accuracy: 82.7626, Val loss: 0.6940, Val accuracy: 76.0878, \n","Epoch : 27\n","Training loss: 0.5122, Training accuracy: 83.1161, Val loss: 0.6968, Val accuracy: 76.7900, \n","\n","Epoch : 28\n","Training loss: 0.5065, Training accuracy: 83.2879, Val loss: 0.6658, Val accuracy: 76.8691, \n","\n","Epoch : 29\n","Training loss: 0.5047, Training accuracy: 83.4031, Val loss: 0.6870, Val accuracy: 76.9086, \n","\n","=\u003e Best: 76.9086\n","alpha = 0.4\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8370, Training accuracy: 32.2407, Val loss: 1.6434, Val accuracy: 39.1119, \n","\n","Epoch : 1\n","Training loss: 1.5617, Training accuracy: 43.6425, Val loss: 1.4768, Val accuracy: 46.1036, \n","\n","Epoch : 2\n","Training loss: 1.4014, Training accuracy: 49.9911, Val loss: 1.3727, Val accuracy: 50.9691, \n","\n","Epoch : 3\n","Training loss: 1.2716, Training accuracy: 55.0964, Val loss: 1.2170, Val accuracy: 55.5973, \n","\n","Epoch : 4\n","Training loss: 1.1817, Training accuracy: 58.8819, Val loss: 1.1706, Val accuracy: 58.3366, \n","\n","Epoch : 5\n","Training loss: 1.1416, Training accuracy: 60.2770, Val loss: 1.1223, Val accuracy: 60.8386, \n","\n","Epoch : 6\n","Training loss: 1.0629, Training accuracy: 63.2868, Val loss: 1.0418, Val accuracy: 64.0131, \n","\n","Epoch : 7\n","Training loss: 0.9890, Training accuracy: 66.2367, Val loss: 1.0195, Val accuracy: 64.5075, \n","\n","Epoch : 8\n","Training loss: 0.9594, Training accuracy: 67.8158, Val loss: 0.9597, Val accuracy: 66.8216, \n","\n","Epoch : 9\n","Training loss: 0.9230, Training accuracy: 68.7201, Val loss: 0.9546, Val accuracy: 66.7029, \n","Epoch : 10\n","Training loss: 0.8814, Training accuracy: 70.5020, Val loss: 0.8910, Val accuracy: 68.9577, \n","\n","Epoch : 11\n","Training loss: 0.8285, Training accuracy: 72.4911, Val loss: 0.8911, Val accuracy: 69.3928, \n","\n","Epoch : 12\n","Training loss: 0.7987, Training accuracy: 73.5151, Val loss: 0.8568, Val accuracy: 70.6290, \n","\n","Epoch : 13\n","Training loss: 0.8027, Training accuracy: 73.4552, Val loss: 0.8640, Val accuracy: 70.0158, \n","Epoch : 14\n","Training loss: 0.7749, Training accuracy: 74.3994, Val loss: 0.8230, Val accuracy: 72.1915, \n","\n","Epoch : 15\n","Training loss: 0.7331, Training accuracy: 76.2566, Val loss: 0.7763, Val accuracy: 73.1408, \n","\n","Epoch : 16\n","Training loss: 0.7192, Training accuracy: 76.5747, Val loss: 0.8042, Val accuracy: 71.7267, \n","Epoch : 17\n","Training loss: 0.6861, Training accuracy: 78.0109, Val loss: 0.7673, Val accuracy: 73.5166, \n","\n","Epoch : 18\n","Training loss: 0.6951, Training accuracy: 77.6075, Val loss: 0.7591, Val accuracy: 74.3572, \n","\n","Epoch : 19\n","Training loss: 0.6712, Training accuracy: 78.2491, Val loss: 0.7724, Val accuracy: 74.1001, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5816, Training accuracy: 81.6800, Val loss: 0.6859, Val accuracy: 76.1570, \n","\n","Epoch : 21\n","Training loss: 0.5430, Training accuracy: 83.0629, Val loss: 0.6647, Val accuracy: 77.5712, \n","\n","Epoch : 22\n","Training loss: 0.5275, Training accuracy: 83.6625, Val loss: 0.6600, Val accuracy: 77.3635, \n","Epoch : 23\n","Training loss: 0.5234, Training accuracy: 84.0913, Val loss: 0.6472, Val accuracy: 77.6800, \n","\n","Epoch : 24\n","Training loss: 0.5146, Training accuracy: 84.1523, Val loss: 0.6510, Val accuracy: 77.7690, \n","\n","Epoch : 25\n","Training loss: 0.5124, Training accuracy: 84.2420, Val loss: 0.6577, Val accuracy: 77.7195, \n","Epoch : 26\n","Training loss: 0.5023, Training accuracy: 84.7340, Val loss: 0.6651, Val accuracy: 77.5316, \n","Epoch : 27\n","Training loss: 0.4980, Training accuracy: 85.0787, Val loss: 0.6546, Val accuracy: 77.7789, \n","\n","Epoch : 28\n","Training loss: 0.4965, Training accuracy: 85.0266, Val loss: 0.6602, Val accuracy: 77.3042, \n","Epoch : 29\n","Training loss: 0.4876, Training accuracy: 85.1718, Val loss: 0.6517, Val accuracy: 77.8679, \n","\n","=\u003e Best: 77.8679\n","alpha = 0.6\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8310, Training accuracy: 32.7316, Val loss: 1.7879, Val accuracy: 35.9968, \n","\n","Epoch : 1\n","Training loss: 1.5553, Training accuracy: 44.0392, Val loss: 1.4889, Val accuracy: 45.8564, \n","\n","Epoch : 2\n","Training loss: 1.3817, Training accuracy: 51.7099, Val loss: 1.3172, Val accuracy: 53.5799, \n","\n","Epoch : 3\n","Training loss: 1.2478, Training accuracy: 56.7775, Val loss: 1.1884, Val accuracy: 57.9510, \n","\n","Epoch : 4\n","Training loss: 1.1559, Training accuracy: 60.2305, Val loss: 1.1148, Val accuracy: 60.4430, \n","\n","Epoch : 5\n","Training loss: 1.0675, Training accuracy: 63.8675, Val loss: 1.0559, Val accuracy: 62.9252, \n","\n","Epoch : 6\n","Training loss: 1.0192, Training accuracy: 65.7513, Val loss: 0.9647, Val accuracy: 66.2184, \n","\n","Epoch : 7\n","Training loss: 0.9526, Training accuracy: 68.3743, Val loss: 0.9663, Val accuracy: 66.1689, \n","Epoch : 8\n","Training loss: 0.9229, Training accuracy: 69.5301, Val loss: 0.9320, Val accuracy: 67.3161, \n","\n","Epoch : 9\n","Training loss: 0.8863, Training accuracy: 71.0594, Val loss: 0.8999, Val accuracy: 68.2852, \n","\n","Epoch : 10\n","Training loss: 0.8518, Training accuracy: 72.1543, Val loss: 0.8604, Val accuracy: 70.4015, \n","\n","Epoch : 11\n","Training loss: 0.8231, Training accuracy: 73.1782, Val loss: 0.8414, Val accuracy: 71.3707, \n","\n","Epoch : 12\n","Training loss: 0.8090, Training accuracy: 74.0204, Val loss: 0.8208, Val accuracy: 71.3410, \n","Epoch : 13\n","Training loss: 0.7781, Training accuracy: 74.9435, Val loss: 0.8328, Val accuracy: 70.3422, \n","Epoch : 14\n","Training loss: 0.7556, Training accuracy: 75.9652, Val loss: 0.7884, Val accuracy: 73.1112, \n","\n","Epoch : 15\n","Training loss: 0.7257, Training accuracy: 76.8828, Val loss: 0.7834, Val accuracy: 72.6266, \n","Epoch : 16\n","Training loss: 0.7935, Training accuracy: 74.7540, Val loss: 0.8303, Val accuracy: 71.5487, \n","Epoch : 17\n","Training loss: 0.7207, Training accuracy: 77.2429, Val loss: 0.7705, Val accuracy: 73.6056, \n","\n","Epoch : 18\n","Training loss: 0.6932, Training accuracy: 78.4264, Val loss: 0.7575, Val accuracy: 73.7243, \n","\n","Epoch : 19\n","Training loss: 0.6765, Training accuracy: 79.0503, Val loss: 0.7284, Val accuracy: 74.8220, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5965, Training accuracy: 82.5410, Val loss: 0.6631, Val accuracy: 77.1064, \n","\n","Epoch : 21\n","Training loss: 0.5699, Training accuracy: 83.2270, Val loss: 0.6513, Val accuracy: 77.3932, \n","\n","Epoch : 22\n","Training loss: 0.5603, Training accuracy: 83.6680, Val loss: 0.6400, Val accuracy: 78.0657, \n","\n","Epoch : 23\n","Training loss: 0.5516, Training accuracy: 84.0315, Val loss: 0.6474, Val accuracy: 77.8580, \n","Epoch : 24\n","Training loss: 0.5441, Training accuracy: 84.1445, Val loss: 0.6333, Val accuracy: 78.1448, \n","\n","Epoch : 25\n","Training loss: 0.5383, Training accuracy: 84.6930, Val loss: 0.6394, Val accuracy: 77.4822, \n","Epoch : 26\n","Training loss: 0.5329, Training accuracy: 84.8836, Val loss: 0.6257, Val accuracy: 77.9569, \n","Epoch : 27\n","Training loss: 0.5314, Training accuracy: 85.0122, Val loss: 0.6286, Val accuracy: 78.4513, \n","\n","Epoch : 28\n","Training loss: 0.5254, Training accuracy: 85.0399, Val loss: 0.6296, Val accuracy: 78.4909, \n","\n","Epoch : 29\n","Training loss: 0.5184, Training accuracy: 85.2549, Val loss: 0.6273, Val accuracy: 78.5502, \n","\n","=\u003e Best: 78.5502\n","alpha = 0.8\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8452, Training accuracy: 32.3061, Val loss: 1.7057, Val accuracy: 38.3208, \n","\n","Epoch : 1\n","Training loss: 1.5759, Training accuracy: 43.4065, Val loss: 1.5071, Val accuracy: 43.8786, \n","\n","Epoch : 2\n","Training loss: 1.4213, Training accuracy: 49.8593, Val loss: 1.3612, Val accuracy: 51.6911, \n","\n","Epoch : 3\n","Training loss: 1.2927, Training accuracy: 55.6627, Val loss: 1.2117, Val accuracy: 56.5566, \n","\n","Epoch : 4\n","Training loss: 1.1886, Training accuracy: 59.5423, Val loss: 1.1976, Val accuracy: 57.8323, \n","\n","Epoch : 5\n","Training loss: 1.1157, Training accuracy: 62.2606, Val loss: 1.0435, Val accuracy: 63.4098, \n","\n","Epoch : 6\n","Training loss: 1.0415, Training accuracy: 65.1729, Val loss: 0.9840, Val accuracy: 65.5953, \n","\n","Epoch : 7\n","Training loss: 0.9890, Training accuracy: 67.3570, Val loss: 0.9705, Val accuracy: 66.2480, \n","\n","Epoch : 8\n","Training loss: 0.9424, Training accuracy: 68.8985, Val loss: 0.9093, Val accuracy: 68.6610, \n","\n","Epoch : 9\n","Training loss: 0.8994, Training accuracy: 70.8588, Val loss: 0.8892, Val accuracy: 68.6907, \n","\n","Epoch : 10\n","Training loss: 0.8720, Training accuracy: 72.0889, Val loss: 0.8699, Val accuracy: 69.6895, \n","\n","Epoch : 11\n","Training loss: 0.8381, Training accuracy: 73.1848, Val loss: 0.8362, Val accuracy: 70.7773, \n","\n","Epoch : 12\n","Training loss: 0.8344, Training accuracy: 73.1815, Val loss: 0.8413, Val accuracy: 71.1135, \n","\n","Epoch : 13\n","Training loss: 0.7993, Training accuracy: 74.7230, Val loss: 0.8103, Val accuracy: 72.0135, \n","\n","Epoch : 14\n","Training loss: 0.7721, Training accuracy: 75.7535, Val loss: 0.7859, Val accuracy: 73.2397, \n","\n","Epoch : 15\n","Training loss: 0.7510, Training accuracy: 76.8595, Val loss: 0.8172, Val accuracy: 71.6080, \n","Epoch : 16\n","Training loss: 0.8147, Training accuracy: 74.3362, Val loss: 0.8041, Val accuracy: 72.6661, \n","Epoch : 17\n","Training loss: 0.7424, Training accuracy: 77.0556, Val loss: 0.7689, Val accuracy: 73.9023, \n","\n","Epoch : 18\n","Training loss: 0.7153, Training accuracy: 78.0862, Val loss: 0.7492, Val accuracy: 74.4759, \n","\n","Epoch : 19\n","Training loss: 0.7042, Training accuracy: 78.8375, Val loss: 0.7412, Val accuracy: 74.4066, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.6229, Training accuracy: 81.7465, Val loss: 0.6744, Val accuracy: 76.6416, \n","\n","Epoch : 21\n","Training loss: 0.5967, Training accuracy: 83.1339, Val loss: 0.6556, Val accuracy: 77.8481, \n","\n","Epoch : 22\n","Training loss: 0.5893, Training accuracy: 83.3256, Val loss: 0.6498, Val accuracy: 77.2943, \n","Epoch : 23\n","Training loss: 0.5829, Training accuracy: 83.5317, Val loss: 0.6533, Val accuracy: 77.5613, \n","Epoch : 24\n","Training loss: 0.5763, Training accuracy: 84.0680, Val loss: 0.6531, Val accuracy: 77.5119, \n","Epoch : 25\n","Training loss: 0.5735, Training accuracy: 83.7079, Val loss: 0.6445, Val accuracy: 77.6503, \n","Epoch : 26\n","Training loss: 0.5674, Training accuracy: 84.3938, Val loss: 0.6309, Val accuracy: 77.8382, \n","Epoch : 27\n","Training loss: 0.5649, Training accuracy: 84.4736, Val loss: 0.6546, Val accuracy: 77.7789, \n","Epoch : 28\n","Training loss: 0.5601, Training accuracy: 84.6387, Val loss: 0.6427, Val accuracy: 78.1151, \n","\n","Epoch : 29\n","Training loss: 0.5619, Training accuracy: 84.6354, Val loss: 0.6303, Val accuracy: 78.1547, \n","\n","=\u003e Best: 78.1547\n","lamda = 0.2\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7714, Training accuracy: 34.9241, Val loss: 1.5934, Val accuracy: 42.4248, \n","\n","Epoch : 1\n","Training loss: 1.4676, Training accuracy: 47.0497, Val loss: 1.4376, Val accuracy: 48.4474, \n","\n","Epoch : 2\n","Training loss: 1.2649, Training accuracy: 55.0569, Val loss: 1.2487, Val accuracy: 54.9446, \n","\n","Epoch : 3\n","Training loss: 1.1340, Training accuracy: 60.2935, Val loss: 1.1294, Val accuracy: 60.2749, \n","\n","Epoch : 4\n","Training loss: 1.0359, Training accuracy: 63.8254, Val loss: 0.9959, Val accuracy: 65.4865, \n","\n","Epoch : 5\n","Training loss: 0.9570, Training accuracy: 66.7482, Val loss: 0.9662, Val accuracy: 66.9996, \n","\n","Epoch : 6\n","Training loss: 0.8871, Training accuracy: 69.2168, Val loss: 0.9041, Val accuracy: 68.4632, \n","\n","Epoch : 7\n","Training loss: 0.8343, Training accuracy: 71.1736, Val loss: 0.8852, Val accuracy: 69.8279, \n","\n","Epoch : 8\n","Training loss: 0.8126, Training accuracy: 71.8001, Val loss: 0.8925, Val accuracy: 69.4917, \n","Epoch : 9\n","Training loss: 0.7535, Training accuracy: 74.2387, Val loss: 0.7794, Val accuracy: 73.1705, \n","\n","Epoch : 10\n","Training loss: 0.7307, Training accuracy: 74.9676, Val loss: 0.8651, Val accuracy: 70.8663, \n","Epoch : 11\n","Training loss: 0.7098, Training accuracy: 75.9235, Val loss: 0.7889, Val accuracy: 72.8046, \n","Epoch : 12\n","Training loss: 0.6730, Training accuracy: 77.1890, Val loss: 0.7413, Val accuracy: 75.1582, \n","\n","Epoch : 13\n","Training loss: 0.6457, Training accuracy: 78.2348, Val loss: 0.7355, Val accuracy: 75.2176, \n","\n","Epoch : 14\n","Training loss: 0.6178, Training accuracy: 79.2632, Val loss: 0.7116, Val accuracy: 75.8604, \n","\n","Epoch : 15\n","Training loss: 0.6045, Training accuracy: 79.7649, Val loss: 0.6956, Val accuracy: 76.2460, \n","\n","Epoch : 16\n","Training loss: 0.5865, Training accuracy: 80.5112, Val loss: 0.6784, Val accuracy: 76.5922, \n","\n","Epoch : 17\n","Training loss: 0.5718, Training accuracy: 81.0204, Val loss: 0.6823, Val accuracy: 76.5131, \n","Epoch : 18\n","Training loss: 0.5614, Training accuracy: 81.5295, Val loss: 0.6802, Val accuracy: 77.1163, \n","\n","Epoch : 19\n","Training loss: 0.5484, Training accuracy: 81.9364, Val loss: 0.6867, Val accuracy: 76.7504, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.4787, Training accuracy: 84.5921, Val loss: 0.5918, Val accuracy: 80.0633, \n","\n","Epoch : 21\n","Training loss: 0.4537, Training accuracy: 85.4732, Val loss: 0.5858, Val accuracy: 79.9051, \n","Epoch : 22\n","Training loss: 0.4417, Training accuracy: 86.0274, Val loss: 0.5953, Val accuracy: 79.9051, \n","Epoch : 23\n","Training loss: 0.4360, Training accuracy: 86.3169, Val loss: 0.5683, Val accuracy: 80.4292, \n","\n","Epoch : 24\n","Training loss: 0.4314, Training accuracy: 86.5515, Val loss: 0.5825, Val accuracy: 80.3105, \n","Epoch : 25\n","Training loss: 0.4255, Training accuracy: 86.6389, Val loss: 0.5726, Val accuracy: 80.7753, \n","\n","Epoch : 26\n","Training loss: 0.4236, Training accuracy: 86.8036, Val loss: 0.5674, Val accuracy: 80.7852, \n","\n","Epoch : 27\n","Training loss: 0.4168, Training accuracy: 87.1331, Val loss: 0.5862, Val accuracy: 80.3006, \n","Epoch : 28\n","Training loss: 0.4146, Training accuracy: 87.1630, Val loss: 0.5921, Val accuracy: 80.2017, \n","Epoch : 29\n","Training loss: 0.4126, Training accuracy: 87.1630, Val loss: 0.5777, Val accuracy: 80.1029, \n","=\u003e Best: 80.7852\n","lamda = 0.4\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7617, Training accuracy: 35.3459, Val loss: 1.5641, Val accuracy: 41.6634, \n","\n","Epoch : 1\n","Training loss: 1.4247, Training accuracy: 48.6047, Val loss: 1.3514, Val accuracy: 51.2263, \n","\n","Epoch : 2\n","Training loss: 1.2161, Training accuracy: 56.8765, Val loss: 1.1725, Val accuracy: 58.0597, \n","\n","Epoch : 3\n","Training loss: 1.0587, Training accuracy: 62.7671, Val loss: 1.0747, Val accuracy: 62.2033, \n","\n","Epoch : 4\n","Training loss: 0.9663, Training accuracy: 66.4412, Val loss: 0.9735, Val accuracy: 66.3172, \n","\n","Epoch : 5\n","Training loss: 0.8793, Training accuracy: 69.2242, Val loss: 0.9275, Val accuracy: 67.8501, \n","\n","Epoch : 6\n","Training loss: 0.8155, Training accuracy: 71.8800, Val loss: 0.8690, Val accuracy: 69.9466, \n","\n","Epoch : 7\n","Training loss: 0.7698, Training accuracy: 73.5623, Val loss: 0.8571, Val accuracy: 70.0257, \n","\n","Epoch : 8\n","Training loss: 0.7391, Training accuracy: 74.6630, Val loss: 0.7734, Val accuracy: 73.3683, \n","\n","Epoch : 9\n","Training loss: 0.7016, Training accuracy: 76.3428, Val loss: 0.7585, Val accuracy: 74.1495, \n","\n","Epoch : 10\n","Training loss: 0.6773, Training accuracy: 76.8970, Val loss: 0.7615, Val accuracy: 73.9913, \n","Epoch : 11\n","Training loss: 0.6536, Training accuracy: 78.1525, Val loss: 0.7381, Val accuracy: 74.7231, \n","\n","Epoch : 12\n","Training loss: 0.6346, Training accuracy: 78.9437, Val loss: 0.7133, Val accuracy: 75.2373, \n","\n","Epoch : 13\n","Training loss: 0.6146, Training accuracy: 79.5452, Val loss: 0.6892, Val accuracy: 76.4438, \n","\n","Epoch : 14\n","Training loss: 0.6022, Training accuracy: 80.3340, Val loss: 0.6775, Val accuracy: 76.7405, \n","\n","Epoch : 15\n","Training loss: 0.5935, Training accuracy: 80.6210, Val loss: 0.6689, Val accuracy: 77.0471, \n","\n","Epoch : 16\n","Training loss: 0.5776, Training accuracy: 81.5096, Val loss: 0.6758, Val accuracy: 76.7603, \n","Epoch : 17\n","Training loss: 0.5687, Training accuracy: 81.9189, Val loss: 0.6566, Val accuracy: 77.3734, \n","\n","Epoch : 18\n","Training loss: 0.5519, Training accuracy: 82.2958, Val loss: 0.6307, Val accuracy: 78.2140, \n","\n","Epoch : 19\n","Training loss: 0.5456, Training accuracy: 82.6777, Val loss: 0.6439, Val accuracy: 77.8184, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.4895, Training accuracy: 85.2137, Val loss: 0.5868, Val accuracy: 79.8853, \n","\n","Epoch : 21\n","Training loss: 0.4726, Training accuracy: 85.9026, Val loss: 0.5763, Val accuracy: 80.2907, \n","\n","Epoch : 22\n","Training loss: 0.4693, Training accuracy: 85.9824, Val loss: 0.5679, Val accuracy: 80.5578, \n","\n","Epoch : 23\n","Training loss: 0.4631, Training accuracy: 86.2395, Val loss: 0.5785, Val accuracy: 80.3896, \n","Epoch : 24\n","Training loss: 0.4584, Training accuracy: 86.5166, Val loss: 0.5678, Val accuracy: 80.4391, \n","Epoch : 25\n","Training loss: 0.4563, Training accuracy: 86.6763, Val loss: 0.5723, Val accuracy: 80.3402, \n","Epoch : 26\n","Training loss: 0.4518, Training accuracy: 86.8610, Val loss: 0.5672, Val accuracy: 80.7358, \n","\n","Epoch : 27\n","Training loss: 0.4534, Training accuracy: 86.8460, Val loss: 0.5601, Val accuracy: 80.8643, \n","\n","Epoch : 28\n","Training loss: 0.4497, Training accuracy: 86.8785, Val loss: 0.5594, Val accuracy: 80.5973, \n","Epoch : 29\n","Training loss: 0.4475, Training accuracy: 87.1855, Val loss: 0.5711, Val accuracy: 80.7457, \n","=\u003e Best: 80.8643\n","lamda = 0.6\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7367, Training accuracy: 36.1896, Val loss: 1.5940, Val accuracy: 40.8722, \n","\n","Epoch : 1\n","Training loss: 1.3837, Training accuracy: 49.9651, Val loss: 1.3712, Val accuracy: 51.0483, \n","\n","Epoch : 2\n","Training loss: 1.1862, Training accuracy: 57.6003, Val loss: 1.1493, Val accuracy: 59.5036, \n","\n","Epoch : 3\n","Training loss: 1.0410, Training accuracy: 63.5708, Val loss: 1.0586, Val accuracy: 62.8362, \n","\n","Epoch : 4\n","Training loss: 0.9452, Training accuracy: 66.7182, Val loss: 1.0080, Val accuracy: 64.7646, \n","\n","Epoch : 5\n","Training loss: 0.8915, Training accuracy: 68.8049, Val loss: 0.9688, Val accuracy: 66.8908, \n","\n","Epoch : 6\n","Training loss: 0.8161, Training accuracy: 71.9524, Val loss: 0.8832, Val accuracy: 69.9367, \n","\n","Epoch : 7\n","Training loss: 0.7835, Training accuracy: 72.9608, Val loss: 0.8278, Val accuracy: 71.5091, \n","\n","Epoch : 8\n","Training loss: 0.7389, Training accuracy: 74.5058, Val loss: 0.8182, Val accuracy: 71.7662, \n","\n","Epoch : 9\n","Training loss: 0.6973, Training accuracy: 76.2555, Val loss: 0.7542, Val accuracy: 74.2385, \n","\n","Epoch : 10\n","Training loss: 0.6746, Training accuracy: 77.1965, Val loss: 0.7499, Val accuracy: 73.7243, \n","Epoch : 11\n","Training loss: 0.6594, Training accuracy: 77.7506, Val loss: 0.7237, Val accuracy: 75.2868, \n","\n","Epoch : 12\n","Training loss: 0.6379, Training accuracy: 78.7066, Val loss: 0.7262, Val accuracy: 75.3956, \n","\n","Epoch : 13\n","Training loss: 0.6145, Training accuracy: 79.9096, Val loss: 0.6810, Val accuracy: 76.3746, \n","\n","Epoch : 14\n","Training loss: 0.6024, Training accuracy: 80.4288, Val loss: 0.6971, Val accuracy: 75.4945, \n","Epoch : 15\n","Training loss: 0.5950, Training accuracy: 80.7183, Val loss: 0.6680, Val accuracy: 77.1163, \n","\n","Epoch : 16\n","Training loss: 0.5854, Training accuracy: 81.1976, Val loss: 0.6626, Val accuracy: 77.5316, \n","\n","Epoch : 17\n","Training loss: 0.5691, Training accuracy: 82.2833, Val loss: 0.6769, Val accuracy: 76.8097, \n","Epoch : 18\n","Training loss: 0.5627, Training accuracy: 82.5704, Val loss: 0.6424, Val accuracy: 78.2338, \n","\n","Epoch : 19\n","Training loss: 0.5585, Training accuracy: 82.4880, Val loss: 0.6683, Val accuracy: 76.7998, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5148, Training accuracy: 84.3475, Val loss: 0.6090, Val accuracy: 78.6689, \n","\n","Epoch : 21\n","Training loss: 0.4997, Training accuracy: 85.0664, Val loss: 0.6000, Val accuracy: 79.2623, \n","\n","Epoch : 22\n","Training loss: 0.4949, Training accuracy: 85.2386, Val loss: 0.6001, Val accuracy: 79.3414, \n","\n","Epoch : 23\n","Training loss: 0.4922, Training accuracy: 85.5007, Val loss: 0.5938, Val accuracy: 79.7765, \n","\n","Epoch : 24\n","Training loss: 0.4904, Training accuracy: 85.6480, Val loss: 0.5811, Val accuracy: 80.1226, \n","\n","Epoch : 25\n","Training loss: 0.4855, Training accuracy: 85.8451, Val loss: 0.5850, Val accuracy: 80.0040, \n","Epoch : 26\n","Training loss: 0.4852, Training accuracy: 85.7328, Val loss: 0.5914, Val accuracy: 79.6875, \n","Epoch : 27\n","Training loss: 0.4848, Training accuracy: 85.8052, Val loss: 0.5863, Val accuracy: 79.8457, \n","Epoch : 28\n","Training loss: 0.4846, Training accuracy: 85.8451, Val loss: 0.5780, Val accuracy: 80.1325, \n","\n","Epoch : 29\n","Training loss: 0.4847, Training accuracy: 86.0049, Val loss: 0.5856, Val accuracy: 79.9743, \n","=\u003e Best: 80.1325\n","lamda = 0.8\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7132, Training accuracy: 37.5474, Val loss: 1.5563, Val accuracy: 43.5324, \n","\n","Epoch : 1\n","Training loss: 1.3690, Training accuracy: 50.5891, Val loss: 1.2884, Val accuracy: 53.0953, \n","\n","Epoch : 2\n","Training loss: 1.1423, Training accuracy: 59.4199, Val loss: 1.1357, Val accuracy: 60.6804, \n","\n","Epoch : 3\n","Training loss: 0.9933, Training accuracy: 64.8537, Val loss: 0.9736, Val accuracy: 66.3172, \n","\n","Epoch : 4\n","Training loss: 0.8878, Training accuracy: 68.7924, Val loss: 0.9177, Val accuracy: 68.6313, \n","\n","Epoch : 5\n","Training loss: 0.8159, Training accuracy: 71.3958, Val loss: 0.8431, Val accuracy: 70.9157, \n","\n","Epoch : 6\n","Training loss: 0.7664, Training accuracy: 73.1579, Val loss: 0.8202, Val accuracy: 71.9146, \n","\n","Epoch : 7\n","Training loss: 0.7263, Training accuracy: 75.0948, Val loss: 0.7881, Val accuracy: 73.3683, \n","\n","Epoch : 8\n","Training loss: 0.6984, Training accuracy: 75.9160, Val loss: 0.7596, Val accuracy: 73.8133, \n","\n","Epoch : 9\n","Training loss: 0.6750, Training accuracy: 77.0792, Val loss: 0.7469, Val accuracy: 74.5055, \n","\n","Epoch : 10\n","Training loss: 0.6531, Training accuracy: 78.1225, Val loss: 0.7572, Val accuracy: 74.5154, \n","\n","Epoch : 11\n","Training loss: 0.6338, Training accuracy: 78.8613, Val loss: 0.7485, Val accuracy: 74.0210, \n","Epoch : 12\n","Training loss: 0.6262, Training accuracy: 79.0410, Val loss: 0.7103, Val accuracy: 75.2967, \n","\n","Epoch : 13\n","Training loss: 0.6149, Training accuracy: 79.6526, Val loss: 0.6866, Val accuracy: 76.5131, \n","\n","Epoch : 14\n","Training loss: 0.5991, Training accuracy: 80.5386, Val loss: 0.6768, Val accuracy: 77.1163, \n","\n","Epoch : 15\n","Training loss: 0.5923, Training accuracy: 80.7034, Val loss: 0.6823, Val accuracy: 76.5823, \n","Epoch : 16\n","Training loss: 0.5826, Training accuracy: 80.9455, Val loss: 0.6746, Val accuracy: 77.3438, \n","\n","Epoch : 17\n","Training loss: 0.5769, Training accuracy: 81.5121, Val loss: 0.6659, Val accuracy: 77.3240, \n","Epoch : 18\n","Training loss: 0.5682, Training accuracy: 81.8740, Val loss: 0.6495, Val accuracy: 78.4612, \n","\n","Epoch : 19\n","Training loss: 0.5658, Training accuracy: 82.0113, Val loss: 0.6385, Val accuracy: 78.0558, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5263, Training accuracy: 83.8933, Val loss: 0.6132, Val accuracy: 79.2425, \n","\n","Epoch : 21\n","Training loss: 0.5181, Training accuracy: 83.8733, Val loss: 0.6027, Val accuracy: 79.0744, \n","Epoch : 22\n","Training loss: 0.5138, Training accuracy: 84.1229, Val loss: 0.6129, Val accuracy: 79.1436, \n","Epoch : 23\n","Training loss: 0.5094, Training accuracy: 84.4399, Val loss: 0.6015, Val accuracy: 79.5490, \n","\n","Epoch : 24\n","Training loss: 0.5101, Training accuracy: 84.2951, Val loss: 0.5953, Val accuracy: 79.4304, \n","Epoch : 25\n","Training loss: 0.5079, Training accuracy: 84.4224, Val loss: 0.5955, Val accuracy: 79.4007, \n","Epoch : 26\n","Training loss: 0.5071, Training accuracy: 84.5447, Val loss: 0.5917, Val accuracy: 79.6974, \n","\n","Epoch : 27\n","Training loss: 0.5033, Training accuracy: 84.4923, Val loss: 0.6007, Val accuracy: 78.7381, \n","Epoch : 28\n","Training loss: 0.5049, Training accuracy: 84.6496, Val loss: 0.5893, Val accuracy: 79.3908, \n","Epoch : 29\n","Training loss: 0.5031, Training accuracy: 84.7070, Val loss: 0.5895, Val accuracy: 79.8062, \n","\n","=\u003e Best: 79.8062\n","0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.13.1\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7872, Training accuracy: 34.2402, Val loss: 1.6479, Val accuracy: 40.5657, \n","\n","1\n","Training loss: 1.4687, Training accuracy: 46.8226, Val loss: 1.4142, Val accuracy: 48.6650, \n","\n","2\n","Training loss: 1.2821, Training accuracy: 54.2657, Val loss: 1.2143, Val accuracy: 56.5269, \n","\n","3\n","Training loss: 1.1484, Training accuracy: 59.4624, Val loss: 1.1751, Val accuracy: 59.1871, \n","\n","4\n","Training loss: 1.0891, Training accuracy: 61.8236, Val loss: 1.0403, Val accuracy: 63.1032, \n","\n","5\n","Training loss: 0.9904, Training accuracy: 65.7398, Val loss: 1.0250, Val accuracy: 64.5372, \n","\n","6\n","Training loss: 0.9168, Training accuracy: 68.0886, Val loss: 0.9333, Val accuracy: 67.3457, \n","\n","7\n","Training loss: 0.8630, Training accuracy: 69.9656, Val loss: 0.8885, Val accuracy: 68.6511, \n","\n","8\n","Training loss: 0.8170, Training accuracy: 71.5081, Val loss: 0.8596, Val accuracy: 70.7773, \n","\n","9\n","Training loss: 0.7925, Training accuracy: 72.7386, Val loss: 0.8811, Val accuracy: 69.5016, \n","10\n","Training loss: 0.7632, Training accuracy: 73.7021, Val loss: 0.8396, Val accuracy: 71.6871, \n","\n","11\n","Training loss: 0.7155, Training accuracy: 75.2845, Val loss: 0.8073, Val accuracy: 72.5574, \n","\n","12\n","Training loss: 0.7095, Training accuracy: 75.3794, Val loss: 0.8036, Val accuracy: 72.8343, \n","\n","13\n","Training loss: 0.6930, Training accuracy: 76.1057, Val loss: 0.7775, Val accuracy: 73.7243, \n","\n","14\n","Training loss: 0.6556, Training accuracy: 77.4810, Val loss: 0.7601, Val accuracy: 74.7429, \n","\n","15\n","Training loss: 0.6237, Training accuracy: 78.5343, Val loss: 0.7429, Val accuracy: 75.1187, \n","\n","16\n","Training loss: 0.6161, Training accuracy: 78.7215, Val loss: 0.8820, Val accuracy: 70.9652, \n","17\n","Training loss: 0.6113, Training accuracy: 79.0485, Val loss: 0.7018, Val accuracy: 76.3845, \n","\n","18\n","Training loss: 0.5822, Training accuracy: 79.9046, Val loss: 0.6916, Val accuracy: 76.4933, \n","\n","19\n","Training loss: 0.5777, Training accuracy: 80.1243, Val loss: 0.6995, Val accuracy: 76.8888, \n","\n","Current learning rate has decayed to 0.010000\n","20\n","Training loss: 0.4697, Training accuracy: 83.6961, Val loss: 0.6387, Val accuracy: 78.5206, \n","\n","21\n","Training loss: 0.4364, Training accuracy: 84.8742, Val loss: 0.6191, Val accuracy: 79.4996, \n","\n","22\n","Training loss: 0.4262, Training accuracy: 85.2012, Val loss: 0.6318, Val accuracy: 79.0941, \n","23\n","Training loss: 0.4171, Training accuracy: 85.6030, Val loss: 0.6162, Val accuracy: 79.5688, \n","\n","24\n","Training loss: 0.4062, Training accuracy: 85.8676, Val loss: 0.6115, Val accuracy: 79.5392, \n","25\n","Training loss: 0.3991, Training accuracy: 86.1197, Val loss: 0.6058, Val accuracy: 79.7468, \n","\n","26\n","Training loss: 0.3893, Training accuracy: 86.2969, Val loss: 0.6012, Val accuracy: 79.8754, \n","\n","27\n","Training loss: 0.3882, Training accuracy: 86.5415, Val loss: 0.6002, Val accuracy: 80.2017, \n","\n","28\n","Training loss: 0.3760, Training accuracy: 86.9634, Val loss: 0.6008, Val accuracy: 80.1523, \n","29\n","Training loss: 0.3774, Training accuracy: 86.8585, Val loss: 0.6059, Val accuracy: 80.3105, \n","\n","=\u003e Best: 80.3105\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 15:50:23 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:50:27 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:50:31 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.2\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1777\n","baseline churn = 0.1709\n","student accuracy = 0.7724\n","baseline accuracy = 0.8125\n","teacher accuracy = 0.7905\n","student wlr = 0.8114973306655884\n","baseline wlr = 1.3992739915847778\n","churn ratio = 1.039789350497367\n","student good_churn = 0.0607\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 15:50:35 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 15:50:35 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:50:39 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:50:43 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.4\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1657\n","baseline churn = 0.1709\n","student accuracy = 0.7841\n","baseline accuracy = 0.8125\n","teacher accuracy = 0.7905\n","student wlr = 0.9282442927360535\n","baseline wlr = 1.3992739915847778\n","churn ratio = 0.9695728496196606\n","student good_churn = 0.0608\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 15:50:47 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 15:50:47 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:50:51 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:50:55 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.6\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1662\n","baseline churn = 0.1709\n","student accuracy = 0.7884\n","baseline accuracy = 0.8125\n","teacher accuracy = 0.7905\n","student wlr = 0.9815950989723206\n","baseline wlr = 1.3992739915847778\n","churn ratio = 0.9724985371562317\n","student good_churn = 0.064\n","student bad_churn = 0.0002\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 15:50:59 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 15:50:59 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:51:03 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:51:07 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.8\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1595\n","baseline churn = 0.1709\n","student accuracy = 0.7885\n","baseline accuracy = 0.8125\n","teacher accuracy = 0.7905\n","student wlr = 0.9566613435745239\n","baseline wlr = 1.3992739915847778\n","churn ratio = 0.9332943241661791\n","student good_churn = 0.0596\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0001\n","baseline bad_churn = 0.0002\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 15:51:11 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 15:51:16 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:51:20 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:51:24 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.2\n","\n","student churn = 0.1597\n","baseline churn = 0.1699\n","student accuracy = 0.81\n","baseline accuracy = 0.8066\n","teacher accuracy = 0.7882\n","student wlr = 1.4038095474243164\n","baseline wlr = 1.3291592597961426\n","churn ratio = 0.9399646851088876\n","student good_churn = 0.0737\n","student bad_churn = 0.0003\n","baseline good_churn = 0.0\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 15:51:28 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 15:51:28 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:51:32 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:51:36 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.4\n","\n","student churn = 0.1485\n","baseline churn = 0.1699\n","student accuracy = 0.8104\n","baseline accuracy = 0.8066\n","teacher accuracy = 0.7882\n","student wlr = 1.4453781843185425\n","baseline wlr = 1.3291592597961426\n","churn ratio = 0.874043555032372\n","student good_churn = 0.0688\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 15:51:40 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 15:51:40 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:51:44 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:51:48 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.6\n","\n","student churn = 0.1338\n","baseline churn = 0.1699\n","student accuracy = 0.8037\n","baseline accuracy = 0.8066\n","teacher accuracy = 0.7882\n","student wlr = 1.3075170516967773\n","baseline wlr = 1.3291592597961426\n","churn ratio = 0.7875220718069453\n","student good_churn = 0.0574\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 15:51:52 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 15:51:53 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:51:56 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 15:52:01 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.8\n","\n","student churn = 0.1292\n","baseline churn = 0.1699\n","student accuracy = 0.7982\n","baseline accuracy = 0.8066\n","teacher accuracy = 0.7882\n","student wlr = 1.2305986881256104\n","baseline wlr = 1.3291592597961426\n","churn ratio = 0.7604473219540907\n","student good_churn = 0.0555\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 15:52:04 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 0\n","Training loss: 1.8177, Training accuracy: 33.3921, Val loss: 1.6588, Val accuracy: 39.1021, \n","\n","Epoch : 1\n","Training loss: 1.5514, Training accuracy: 44.0481, Val loss: 1.4820, Val accuracy: 46.8750, \n","\n","Epoch : 2\n","Training loss: 1.3856, Training accuracy: 50.2748, Val loss: 1.3414, Val accuracy: 52.5415, \n","\n","Epoch : 3\n","Training loss: 1.2530, Training accuracy: 55.5685, Val loss: 1.2140, Val accuracy: 56.9917, \n","\n","Epoch : 4\n","Training loss: 1.1586, Training accuracy: 59.1933, Val loss: 1.1236, Val accuracy: 60.3343, \n","\n","Epoch : 5\n","Training loss: 1.0907, Training accuracy: 61.8828, Val loss: 1.0968, Val accuracy: 61.6594, \n","\n","Epoch : 6\n","Training loss: 1.0119, Training accuracy: 64.3218, Val loss: 1.0661, Val accuracy: 63.7955, \n","\n","Epoch : 7\n","Training loss: 0.9689, Training accuracy: 65.9530, Val loss: 1.0175, Val accuracy: 64.8042, \n","\n","Epoch : 8\n","Training loss: 0.9126, Training accuracy: 68.1715, Val loss: 0.9915, Val accuracy: 65.7338, \n","\n","Epoch : 9\n","Training loss: 0.8741, Training accuracy: 69.1279, Val loss: 0.9253, Val accuracy: 67.8501, \n","\n","Epoch : 10\n","Training loss: 0.8404, Training accuracy: 70.6039, Val loss: 0.9248, Val accuracy: 68.5720, \n","\n","Epoch : 11\n","Training loss: 0.8167, Training accuracy: 71.6179, Val loss: 0.9075, Val accuracy: 68.4731, \n","Epoch : 12\n","Training loss: 0.7824, Training accuracy: 72.9532, Val loss: 0.8961, Val accuracy: 69.2247, \n","\n","Epoch : 13\n","Training loss: 0.7770, Training accuracy: 72.9987, Val loss: 0.8509, Val accuracy: 70.5004, \n","\n","Epoch : 14\n","Training loss: 0.7336, Training accuracy: 74.6243, Val loss: 0.8287, Val accuracy: 71.3113, \n","\n","Epoch : 15\n","Training loss: 0.7180, Training accuracy: 75.2205, Val loss: 0.8557, Val accuracy: 70.8762, \n","Epoch : 16\n","Training loss: 0.6873, Training accuracy: 76.1769, Val loss: 0.8266, Val accuracy: 71.3904, \n","\n","Epoch : 17\n","Training loss: 0.6902, Training accuracy: 76.2312, Val loss: 0.8041, Val accuracy: 72.8837, \n","\n","Epoch : 18\n","Training loss: 0.6587, Training accuracy: 77.3925, Val loss: 0.7593, Val accuracy: 73.9913, \n","\n","Epoch : 19\n","Training loss: 0.6391, Training accuracy: 77.7704, Val loss: 0.8210, Val accuracy: 72.0431, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5534, Training accuracy: 80.5330, Val loss: 0.7090, Val accuracy: 76.3054, \n","\n","Epoch : 21\n","Training loss: 0.5027, Training accuracy: 82.4003, Val loss: 0.6911, Val accuracy: 76.7900, \n","\n","Epoch : 22\n","Training loss: 0.4756, Training accuracy: 83.5383, Val loss: 0.6897, Val accuracy: 77.1855, \n","\n","Epoch : 23\n","Training loss: 0.4684, Training accuracy: 83.4386, Val loss: 0.6809, Val accuracy: 76.8691, \n","Epoch : 24\n","Training loss: 0.4569, Training accuracy: 83.9783, Val loss: 0.6856, Val accuracy: 76.5922, \n","Epoch : 25\n","Training loss: 0.4458, Training accuracy: 84.5080, Val loss: 0.6725, Val accuracy: 77.7591, \n","\n","Epoch : 26\n","Training loss: 0.4406, Training accuracy: 84.4858, Val loss: 0.6783, Val accuracy: 77.9668, \n","\n","Epoch : 27\n","Training loss: 0.4364, Training accuracy: 84.8105, Val loss: 0.6710, Val accuracy: 77.4624, \n","Epoch : 28\n","Training loss: 0.4245, Training accuracy: 85.1374, Val loss: 0.6737, Val accuracy: 77.7690, \n","Epoch : 29\n","Training loss: 0.4195, Training accuracy: 85.2405, Val loss: 0.6645, Val accuracy: 78.4612, \n","\n","=\u003e Best: 78.4612\n","alpha = 0.2\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8581, Training accuracy: 31.1026, Val loss: 1.6675, Val accuracy: 37.9648, \n","\n","Epoch : 1\n","Training loss: 1.5689, Training accuracy: 43.1250, Val loss: 1.4779, Val accuracy: 46.4597, \n","\n","Epoch : 2\n","Training loss: 1.3968, Training accuracy: 50.2261, Val loss: 1.3399, Val accuracy: 51.7801, \n","\n","Epoch : 3\n","Training loss: 1.2489, Training accuracy: 55.5042, Val loss: 1.2220, Val accuracy: 56.3885, \n","\n","Epoch : 4\n","Training loss: 1.1479, Training accuracy: 59.7363, Val loss: 1.1577, Val accuracy: 58.8608, \n","\n","Epoch : 5\n","Training loss: 1.0784, Training accuracy: 62.6341, Val loss: 1.0901, Val accuracy: 61.5012, \n","\n","Epoch : 6\n","Training loss: 1.0137, Training accuracy: 64.8016, Val loss: 1.0286, Val accuracy: 63.8054, \n","\n","Epoch : 7\n","Training loss: 0.9513, Training accuracy: 67.2717, Val loss: 0.9867, Val accuracy: 65.8030, \n","\n","Epoch : 8\n","Training loss: 0.9244, Training accuracy: 68.3090, Val loss: 0.9415, Val accuracy: 67.1578, \n","\n","Epoch : 9\n","Training loss: 0.8728, Training accuracy: 70.0676, Val loss: 0.9474, Val accuracy: 67.6226, \n","\n","Epoch : 10\n","Training loss: 0.8473, Training accuracy: 71.2289, Val loss: 0.9015, Val accuracy: 68.8983, \n","\n","Epoch : 11\n","Training loss: 0.8580, Training accuracy: 70.8677, Val loss: 0.9314, Val accuracy: 67.6127, \n","Epoch : 12\n","Training loss: 0.8397, Training accuracy: 71.4583, Val loss: 0.8818, Val accuracy: 69.6796, \n","\n","Epoch : 13\n","Training loss: 0.8224, Training accuracy: 72.0789, Val loss: 0.8710, Val accuracy: 69.8082, \n","\n","Epoch : 14\n","Training loss: 0.8017, Training accuracy: 72.8779, Val loss: 0.8276, Val accuracy: 72.2211, \n","\n","Epoch : 15\n","Training loss: 0.7349, Training accuracy: 75.3701, Val loss: 0.8939, Val accuracy: 69.5906, \n","Epoch : 16\n","Training loss: 0.7109, Training accuracy: 76.3032, Val loss: 0.8771, Val accuracy: 72.2607, \n","\n","Epoch : 17\n","Training loss: 0.6916, Training accuracy: 76.9537, Val loss: 0.7881, Val accuracy: 73.4869, \n","\n","Epoch : 18\n","Training loss: 0.6684, Training accuracy: 77.6319, Val loss: 0.7794, Val accuracy: 73.6748, \n","\n","Epoch : 19\n","Training loss: 0.6541, Training accuracy: 78.1638, Val loss: 0.7910, Val accuracy: 72.4782, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5646, Training accuracy: 81.1215, Val loss: 0.6927, Val accuracy: 76.4537, \n","\n","Epoch : 21\n","Training loss: 0.5316, Training accuracy: 82.5266, Val loss: 0.6761, Val accuracy: 76.8196, \n","\n","Epoch : 22\n","Training loss: 0.5186, Training accuracy: 82.8901, Val loss: 0.6669, Val accuracy: 77.0372, \n","\n","Epoch : 23\n","Training loss: 0.5135, Training accuracy: 83.2580, Val loss: 0.6688, Val accuracy: 77.1163, \n","\n","Epoch : 24\n","Training loss: 0.4985, Training accuracy: 83.8442, Val loss: 0.6693, Val accuracy: 76.6515, \n","Epoch : 25\n","Training loss: 0.4930, Training accuracy: 84.0625, Val loss: 0.6600, Val accuracy: 77.6404, \n","\n","Epoch : 26\n","Training loss: 0.4908, Training accuracy: 83.9694, Val loss: 0.6588, Val accuracy: 77.6009, \n","Epoch : 27\n","Training loss: 0.4810, Training accuracy: 84.2210, Val loss: 0.6598, Val accuracy: 77.3734, \n","Epoch : 28\n","Training loss: 0.4788, Training accuracy: 84.5401, Val loss: 0.6618, Val accuracy: 77.5316, \n","Epoch : 29\n","Training loss: 0.4698, Training accuracy: 84.7817, Val loss: 0.6642, Val accuracy: 77.6800, \n","\n","=\u003e Best: 77.6800\n","alpha = 0.4\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8279, Training accuracy: 32.6152, Val loss: 1.7038, Val accuracy: 37.1242, \n","\n","Epoch : 1\n","Training loss: 1.5711, Training accuracy: 43.2513, Val loss: 1.4967, Val accuracy: 45.0455, \n","\n","Epoch : 2\n","Training loss: 1.4011, Training accuracy: 50.6316, Val loss: 1.3926, Val accuracy: 49.9209, \n","\n","Epoch : 3\n","Training loss: 1.2662, Training accuracy: 55.4532, Val loss: 1.2623, Val accuracy: 55.0534, \n","\n","Epoch : 4\n","Training loss: 1.1737, Training accuracy: 59.1090, Val loss: 1.1348, Val accuracy: 60.3639, \n","\n","Epoch : 5\n","Training loss: 1.1047, Training accuracy: 61.6212, Val loss: 1.1155, Val accuracy: 59.9585, \n","Epoch : 6\n","Training loss: 1.0339, Training accuracy: 64.4249, Val loss: 1.0246, Val accuracy: 63.7164, \n","\n","Epoch : 7\n","Training loss: 0.9851, Training accuracy: 66.2378, Val loss: 1.0241, Val accuracy: 64.2010, \n","\n","Epoch : 8\n","Training loss: 0.9472, Training accuracy: 68.0829, Val loss: 0.9785, Val accuracy: 65.7832, \n","\n","Epoch : 9\n","Training loss: 0.8890, Training accuracy: 70.0632, Val loss: 0.9258, Val accuracy: 67.4743, \n","\n","Epoch : 10\n","Training loss: 0.8541, Training accuracy: 71.3165, Val loss: 0.8779, Val accuracy: 69.3335, \n","\n","Epoch : 11\n","Training loss: 0.8314, Training accuracy: 72.2784, Val loss: 0.8964, Val accuracy: 69.2148, \n","Epoch : 12\n","Training loss: 0.7957, Training accuracy: 73.5129, Val loss: 0.8341, Val accuracy: 70.9157, \n","\n","Epoch : 13\n","Training loss: 0.7705, Training accuracy: 74.4470, Val loss: 0.8217, Val accuracy: 71.6080, \n","\n","Epoch : 14\n","Training loss: 0.7470, Training accuracy: 75.4976, Val loss: 0.8241, Val accuracy: 71.4893, \n","Epoch : 15\n","Training loss: 0.7300, Training accuracy: 76.1425, Val loss: 0.8174, Val accuracy: 71.7069, \n","\n","Epoch : 16\n","Training loss: 0.7109, Training accuracy: 76.9448, Val loss: 0.7684, Val accuracy: 73.6847, \n","\n","Epoch : 17\n","Training loss: 0.6910, Training accuracy: 77.6928, Val loss: 0.7915, Val accuracy: 72.7354, \n","Epoch : 18\n","Training loss: 0.6808, Training accuracy: 78.1460, Val loss: 0.7628, Val accuracy: 73.8627, \n","\n","Epoch : 19\n","Training loss: 0.6605, Training accuracy: 78.8996, Val loss: 0.7471, Val accuracy: 74.6044, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5615, Training accuracy: 82.5222, Val loss: 0.6845, Val accuracy: 77.2547, \n","\n","Epoch : 21\n","Training loss: 0.5320, Training accuracy: 83.7456, Val loss: 0.6524, Val accuracy: 77.3932, \n","\n","Epoch : 22\n","Training loss: 0.5243, Training accuracy: 83.7422, Val loss: 0.6533, Val accuracy: 77.5910, \n","\n","Epoch : 23\n","Training loss: 0.5131, Training accuracy: 84.3096, Val loss: 0.6313, Val accuracy: 78.3920, \n","\n","Epoch : 24\n","Training loss: 0.5071, Training accuracy: 84.6321, Val loss: 0.6540, Val accuracy: 77.7294, \n","Epoch : 25\n","Training loss: 0.4976, Training accuracy: 85.1684, Val loss: 0.6476, Val accuracy: 77.7195, \n","Epoch : 26\n","Training loss: 0.4978, Training accuracy: 84.9258, Val loss: 0.6350, Val accuracy: 78.5107, \n","\n","Epoch : 27\n","Training loss: 0.4943, Training accuracy: 85.1862, Val loss: 0.6406, Val accuracy: 77.8778, \n","Epoch : 28\n","Training loss: 0.4892, Training accuracy: 85.3014, Val loss: 0.6571, Val accuracy: 77.5415, \n","Epoch : 29\n","Training loss: 0.4794, Training accuracy: 85.6605, Val loss: 0.6414, Val accuracy: 77.8976, \n","=\u003e Best: 78.5107\n","alpha = 0.6\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8146, Training accuracy: 33.6458, Val loss: 1.6390, Val accuracy: 40.7239, \n","\n","Epoch : 1\n","Training loss: 1.5400, Training accuracy: 44.5844, Val loss: 1.4088, Val accuracy: 48.3089, \n","\n","Epoch : 2\n","Training loss: 1.3611, Training accuracy: 51.9215, Val loss: 1.3590, Val accuracy: 50.7219, \n","\n","Epoch : 3\n","Training loss: 1.2469, Training accuracy: 56.6633, Val loss: 1.2014, Val accuracy: 57.4070, \n","\n","Epoch : 4\n","Training loss: 1.1439, Training accuracy: 60.5020, Val loss: 1.1421, Val accuracy: 59.5629, \n","\n","Epoch : 5\n","Training loss: 1.0673, Training accuracy: 63.6536, Val loss: 1.0490, Val accuracy: 63.1329, \n","\n","Epoch : 6\n","Training loss: 1.0153, Training accuracy: 65.7037, Val loss: 0.9914, Val accuracy: 65.0514, \n","\n","Epoch : 7\n","Training loss: 0.9757, Training accuracy: 66.9481, Val loss: 0.9810, Val accuracy: 65.0811, \n","\n","Epoch : 8\n","Training loss: 0.9200, Training accuracy: 69.3362, Val loss: 0.9147, Val accuracy: 68.2061, \n","\n","Epoch : 9\n","Training loss: 0.8813, Training accuracy: 70.5918, Val loss: 0.9077, Val accuracy: 68.3445, \n","\n","Epoch : 10\n","Training loss: 0.8936, Training accuracy: 70.0809, Val loss: 0.9079, Val accuracy: 68.5127, \n","\n","Epoch : 11\n","Training loss: 0.8380, Training accuracy: 72.3848, Val loss: 0.9084, Val accuracy: 68.9972, \n","\n","Epoch : 12\n","Training loss: 0.8057, Training accuracy: 73.5871, Val loss: 0.8441, Val accuracy: 70.6487, \n","\n","Epoch : 13\n","Training loss: 0.7723, Training accuracy: 74.9723, Val loss: 0.7843, Val accuracy: 73.3386, \n","\n","Epoch : 14\n","Training loss: 0.7443, Training accuracy: 76.1292, Val loss: 0.7949, Val accuracy: 72.6859, \n","Epoch : 15\n","Training loss: 0.8285, Training accuracy: 72.9433, Val loss: 0.8167, Val accuracy: 72.1222, \n","Epoch : 16\n","Training loss: 0.7372, Training accuracy: 76.4062, Val loss: 0.7969, Val accuracy: 72.7947, \n","Epoch : 17\n","Training loss: 0.7264, Training accuracy: 76.7509, Val loss: 0.8591, Val accuracy: 69.7884, \n","Epoch : 18\n","Training loss: 0.7268, Training accuracy: 77.1520, Val loss: 0.7640, Val accuracy: 73.7342, \n","\n","Epoch : 19\n","Training loss: 0.6848, Training accuracy: 78.5483, Val loss: 0.7503, Val accuracy: 74.5055, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5967, Training accuracy: 82.0401, Val loss: 0.6774, Val accuracy: 76.8592, \n","\n","Epoch : 21\n","Training loss: 0.5698, Training accuracy: 82.9289, Val loss: 0.6646, Val accuracy: 77.1163, \n","\n","Epoch : 22\n","Training loss: 0.5625, Training accuracy: 83.1416, Val loss: 0.6736, Val accuracy: 76.7504, \n","Epoch : 23\n","Training loss: 0.5557, Training accuracy: 83.7976, Val loss: 0.6503, Val accuracy: 77.6701, \n","\n","Epoch : 24\n","Training loss: 0.5514, Training accuracy: 83.6968, Val loss: 0.6435, Val accuracy: 78.0459, \n","\n","Epoch : 25\n","Training loss: 0.5455, Training accuracy: 83.9871, Val loss: 0.6531, Val accuracy: 77.5218, \n","Epoch : 26\n","Training loss: 0.5368, Training accuracy: 84.3872, Val loss: 0.6620, Val accuracy: 77.3833, \n","Epoch : 27\n","Training loss: 0.5337, Training accuracy: 84.3916, Val loss: 0.6498, Val accuracy: 77.1262, \n","Epoch : 28\n","Training loss: 0.5298, Training accuracy: 84.6299, Val loss: 0.6409, Val accuracy: 78.4810, \n","\n","Epoch : 29\n","Training loss: 0.5231, Training accuracy: 84.8449, Val loss: 0.6485, Val accuracy: 77.9074, \n","=\u003e Best: 78.4810\n","alpha = 0.8\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8344, Training accuracy: 32.3870, Val loss: 1.6748, Val accuracy: 37.9747, \n","\n","Epoch : 1\n","Training loss: 1.5800, Training accuracy: 43.0086, Val loss: 1.4380, Val accuracy: 47.2607, \n","\n","Epoch : 2\n","Training loss: 1.3978, Training accuracy: 50.3424, Val loss: 1.3568, Val accuracy: 50.1187, \n","\n","Epoch : 3\n","Training loss: 1.2851, Training accuracy: 54.8936, Val loss: 1.2731, Val accuracy: 54.7666, \n","\n","Epoch : 4\n","Training loss: 1.1975, Training accuracy: 58.4497, Val loss: 1.1587, Val accuracy: 59.2860, \n","\n","Epoch : 5\n","Training loss: 1.1168, Training accuracy: 62.1698, Val loss: 1.1168, Val accuracy: 60.7595, \n","\n","Epoch : 6\n","Training loss: 1.0539, Training accuracy: 64.5800, Val loss: 1.0576, Val accuracy: 62.7472, \n","\n","Epoch : 7\n","Training loss: 1.0099, Training accuracy: 66.3774, Val loss: 1.0277, Val accuracy: 64.2405, \n","\n","Epoch : 8\n","Training loss: 0.9518, Training accuracy: 68.5838, Val loss: 0.9448, Val accuracy: 67.1282, \n","\n","Epoch : 9\n","Training loss: 0.9095, Training accuracy: 70.2460, Val loss: 0.9296, Val accuracy: 66.9502, \n","Epoch : 10\n","Training loss: 0.8796, Training accuracy: 71.5459, Val loss: 0.8682, Val accuracy: 70.0851, \n","\n","Epoch : 11\n","Training loss: 0.8583, Training accuracy: 72.5942, Val loss: 0.8638, Val accuracy: 70.4608, \n","\n","Epoch : 12\n","Training loss: 0.8296, Training accuracy: 73.5295, Val loss: 0.8461, Val accuracy: 70.9751, \n","\n","Epoch : 13\n","Training loss: 0.8029, Training accuracy: 74.3440, Val loss: 0.8017, Val accuracy: 72.5079, \n","\n","Epoch : 14\n","Training loss: 0.7888, Training accuracy: 74.9789, Val loss: 0.8284, Val accuracy: 71.9047, \n","Epoch : 15\n","Training loss: 0.7638, Training accuracy: 75.6449, Val loss: 0.7894, Val accuracy: 72.7057, \n","\n","Epoch : 16\n","Training loss: 0.7434, Training accuracy: 76.9215, Val loss: 0.7741, Val accuracy: 72.7848, \n","\n","Epoch : 17\n","Training loss: 0.7256, Training accuracy: 77.7394, Val loss: 0.7594, Val accuracy: 73.3782, \n","\n","Epoch : 18\n","Training loss: 0.7286, Training accuracy: 77.4712, Val loss: 0.7552, Val accuracy: 74.1693, \n","\n","Epoch : 19\n","Training loss: 0.7170, Training accuracy: 78.3012, Val loss: 0.7442, Val accuracy: 73.6847, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.6313, Training accuracy: 81.2611, Val loss: 0.6822, Val accuracy: 76.3351, \n","\n","Epoch : 21\n","Training loss: 0.5981, Training accuracy: 82.6585, Val loss: 0.6717, Val accuracy: 76.6614, \n","\n","Epoch : 22\n","Training loss: 0.5890, Training accuracy: 83.3367, Val loss: 0.6585, Val accuracy: 77.0570, \n","\n","Epoch : 23\n","Training loss: 0.5851, Training accuracy: 83.4851, Val loss: 0.6574, Val accuracy: 76.9877, \n","Epoch : 24\n","Training loss: 0.5809, Training accuracy: 83.6492, Val loss: 0.6561, Val accuracy: 77.2152, \n","\n","Epoch : 25\n","Training loss: 0.5716, Training accuracy: 83.9450, Val loss: 0.6524, Val accuracy: 77.4130, \n","\n","Epoch : 26\n","Training loss: 0.5658, Training accuracy: 84.1833, Val loss: 0.6467, Val accuracy: 77.6404, \n","\n","Epoch : 27\n","Training loss: 0.5614, Training accuracy: 84.3661, Val loss: 0.6523, Val accuracy: 77.8085, \n","\n","Epoch : 28\n","Training loss: 0.5604, Training accuracy: 84.6044, Val loss: 0.6470, Val accuracy: 77.9173, \n","\n","Epoch : 29\n","Training loss: 0.5551, Training accuracy: 84.8615, Val loss: 0.6632, Val accuracy: 77.0767, \n","=\u003e Best: 77.9173\n","lamda = 0.2\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7418, Training accuracy: 36.3968, Val loss: 1.5534, Val accuracy: 44.6104, \n","\n","Epoch : 1\n","Training loss: 1.4205, Training accuracy: 48.9392, Val loss: 1.3271, Val accuracy: 51.9086, \n","\n","Epoch : 2\n","Training loss: 1.2306, Training accuracy: 56.2700, Val loss: 1.1462, Val accuracy: 60.5320, \n","\n","Epoch : 3\n","Training loss: 1.1044, Training accuracy: 60.9200, Val loss: 1.0714, Val accuracy: 63.0340, \n","\n","Epoch : 4\n","Training loss: 1.0029, Training accuracy: 64.7314, Val loss: 1.0520, Val accuracy: 62.7769, \n","Epoch : 5\n","Training loss: 0.9272, Training accuracy: 67.4920, Val loss: 0.9889, Val accuracy: 66.1689, \n","\n","Epoch : 6\n","Training loss: 0.8707, Training accuracy: 69.4688, Val loss: 0.8904, Val accuracy: 69.5807, \n","\n","Epoch : 7\n","Training loss: 0.8187, Training accuracy: 71.6479, Val loss: 0.8520, Val accuracy: 70.8465, \n","\n","Epoch : 8\n","Training loss: 0.7887, Training accuracy: 72.8035, Val loss: 0.8262, Val accuracy: 71.6772, \n","\n","Epoch : 9\n","Training loss: 0.7583, Training accuracy: 73.8144, Val loss: 0.8240, Val accuracy: 71.0740, \n","Epoch : 10\n","Training loss: 0.7120, Training accuracy: 75.7613, Val loss: 0.8099, Val accuracy: 71.8948, \n","\n","Epoch : 11\n","Training loss: 0.6922, Training accuracy: 76.1457, Val loss: 0.7804, Val accuracy: 73.0419, \n","\n","Epoch : 12\n","Training loss: 0.6664, Training accuracy: 77.3213, Val loss: 0.8000, Val accuracy: 72.6464, \n","Epoch : 13\n","Training loss: 0.6440, Training accuracy: 78.1924, Val loss: 0.7286, Val accuracy: 75.1582, \n","\n","Epoch : 14\n","Training loss: 0.6334, Training accuracy: 78.7190, Val loss: 0.7200, Val accuracy: 75.2868, \n","\n","Epoch : 15\n","Training loss: 0.6126, Training accuracy: 79.5128, Val loss: 0.7226, Val accuracy: 75.5142, \n","\n","Epoch : 16\n","Training loss: 0.6059, Training accuracy: 79.7524, Val loss: 0.6990, Val accuracy: 76.0384, \n","\n","Epoch : 17\n","Training loss: 0.5856, Training accuracy: 80.7658, Val loss: 0.6899, Val accuracy: 76.6416, \n","\n","Epoch : 18\n","Training loss: 0.6138, Training accuracy: 79.5877, Val loss: 0.7278, Val accuracy: 75.3165, \n","Epoch : 19\n","Training loss: 0.5861, Training accuracy: 80.5711, Val loss: 0.6872, Val accuracy: 76.7405, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.4998, Training accuracy: 83.9956, Val loss: 0.6281, Val accuracy: 78.7975, \n","\n","Epoch : 21\n","Training loss: 0.4749, Training accuracy: 84.7145, Val loss: 0.6120, Val accuracy: 79.4007, \n","\n","Epoch : 22\n","Training loss: 0.4625, Training accuracy: 85.2811, Val loss: 0.6128, Val accuracy: 79.3117, \n","Epoch : 23\n","Training loss: 0.4559, Training accuracy: 85.5955, Val loss: 0.5992, Val accuracy: 79.6875, \n","\n","Epoch : 24\n","Training loss: 0.4505, Training accuracy: 85.8302, Val loss: 0.5962, Val accuracy: 79.9150, \n","\n","Epoch : 25\n","Training loss: 0.4414, Training accuracy: 86.1047, Val loss: 0.5901, Val accuracy: 80.3006, \n","\n","Epoch : 26\n","Training loss: 0.4352, Training accuracy: 86.1971, Val loss: 0.5768, Val accuracy: 80.2611, \n","Epoch : 27\n","Training loss: 0.4349, Training accuracy: 86.3394, Val loss: 0.5915, Val accuracy: 80.0336, \n","Epoch : 28\n","Training loss: 0.4252, Training accuracy: 86.9958, Val loss: 0.5890, Val accuracy: 80.2710, \n","Epoch : 29\n","Training loss: 0.4236, Training accuracy: 86.8735, Val loss: 0.6061, Val accuracy: 79.7073, \n","=\u003e Best: 80.3006\n","lamda = 0.4\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7276, Training accuracy: 36.9434, Val loss: 1.5441, Val accuracy: 42.6028, \n","\n","Epoch : 1\n","Training loss: 1.3872, Training accuracy: 49.8827, Val loss: 1.3221, Val accuracy: 52.7591, \n","\n","Epoch : 2\n","Training loss: 1.1733, Training accuracy: 58.2892, Val loss: 1.1510, Val accuracy: 59.3157, \n","\n","Epoch : 3\n","Training loss: 1.0389, Training accuracy: 63.6631, Val loss: 1.0945, Val accuracy: 61.6990, \n","\n","Epoch : 4\n","Training loss: 0.9508, Training accuracy: 66.9554, Val loss: 0.9613, Val accuracy: 66.1294, \n","\n","Epoch : 5\n","Training loss: 0.8883, Training accuracy: 69.0246, Val loss: 0.9460, Val accuracy: 67.4644, \n","\n","Epoch : 6\n","Training loss: 0.8195, Training accuracy: 71.6504, Val loss: 0.8748, Val accuracy: 69.4324, \n","\n","Epoch : 7\n","Training loss: 0.7726, Training accuracy: 73.1305, Val loss: 0.8501, Val accuracy: 71.0542, \n","\n","Epoch : 8\n","Training loss: 0.7338, Training accuracy: 75.0549, Val loss: 0.8000, Val accuracy: 72.4782, \n","\n","Epoch : 9\n","Training loss: 0.7047, Training accuracy: 76.2705, Val loss: 0.7571, Val accuracy: 73.6946, \n","\n","Epoch : 10\n","Training loss: 0.6797, Training accuracy: 77.0867, Val loss: 0.7305, Val accuracy: 74.7033, \n","\n","Epoch : 11\n","Training loss: 0.6673, Training accuracy: 77.4935, Val loss: 0.7684, Val accuracy: 73.7342, \n","Epoch : 12\n","Training loss: 0.6433, Training accuracy: 78.5668, Val loss: 0.7186, Val accuracy: 75.2769, \n","\n","Epoch : 13\n","Training loss: 0.6188, Training accuracy: 79.4429, Val loss: 0.7076, Val accuracy: 75.7714, \n","\n","Epoch : 14\n","Training loss: 0.6020, Training accuracy: 80.0819, Val loss: 0.6817, Val accuracy: 76.6614, \n","\n","Epoch : 15\n","Training loss: 0.5892, Training accuracy: 80.9580, Val loss: 0.6976, Val accuracy: 76.0582, \n","Epoch : 16\n","Training loss: 0.5758, Training accuracy: 81.5021, Val loss: 0.6651, Val accuracy: 77.2251, \n","\n","Epoch : 17\n","Training loss: 0.5673, Training accuracy: 81.9189, Val loss: 0.6579, Val accuracy: 77.0965, \n","Epoch : 18\n","Training loss: 0.5585, Training accuracy: 82.3233, Val loss: 0.6439, Val accuracy: 78.2239, \n","\n","Epoch : 19\n","Training loss: 0.5471, Training accuracy: 83.1145, Val loss: 0.6502, Val accuracy: 77.5811, \n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.4928, Training accuracy: 85.1937, Val loss: 0.5984, Val accuracy: 79.8655, \n","\n","Epoch : 21\n","Training loss: 0.4742, Training accuracy: 85.8726, Val loss: 0.5741, Val accuracy: 80.0534, \n","\n","Epoch : 22\n","Training loss: 0.4675, Training accuracy: 86.3319, Val loss: 0.5658, Val accuracy: 80.3600, \n","\n","Epoch : 23\n","Training loss: 0.4624, Training accuracy: 86.5216, Val loss: 0.5720, Val accuracy: 79.8952, \n","Epoch : 24\n","Training loss: 0.4642, Training accuracy: 86.3943, Val loss: 0.5755, Val accuracy: 80.2710, \n","Epoch : 25\n","Training loss: 0.4580, Training accuracy: 86.5565, Val loss: 0.5608, Val accuracy: 80.6072, \n","\n","Epoch : 26\n","Training loss: 0.4551, Training accuracy: 86.8810, Val loss: 0.5643, Val accuracy: 80.3699, \n","Epoch : 27\n","Training loss: 0.4520, Training accuracy: 86.9534, Val loss: 0.5644, Val accuracy: 80.5479, \n","Epoch : 28\n","Training loss: 0.4545, Training accuracy: 86.9035, Val loss: 0.5650, Val accuracy: 80.4490, \n","Epoch : 29\n","Training loss: 0.4475, Training accuracy: 87.3428, Val loss: 0.5626, Val accuracy: 80.5874, \n","=\u003e Best: 80.6072\n","lamda = 0.6\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7212, Training accuracy: 36.6489, Val loss: 1.5038, Val accuracy: 46.1036, \n","\n","Epoch : 1\n","Training loss: 1.3696, Training accuracy: 50.5791, Val loss: 1.2841, Val accuracy: 53.7975, \n","\n","Epoch : 2\n","Training loss: 1.1517, Training accuracy: 59.0905, Val loss: 1.1078, Val accuracy: 61.2737, \n","\n","Epoch : 3\n","Training loss: 1.0223, Training accuracy: 63.4635, Val loss: 1.0094, Val accuracy: 64.7646, \n","\n","Epoch : 4\n","Training loss: 0.9238, Training accuracy: 67.4196, Val loss: 0.9745, Val accuracy: 65.9711, \n","\n","Epoch : 5\n","Training loss: 0.8809, Training accuracy: 69.3141, Val loss: 0.9274, Val accuracy: 68.1764, \n","\n","Epoch : 6\n","Training loss: 0.8147, Training accuracy: 71.8326, Val loss: 0.8478, Val accuracy: 71.1828, \n","\n","Epoch : 7\n","Training loss: 0.7676, Training accuracy: 73.7170, Val loss: 0.8357, Val accuracy: 71.6673, \n","\n","Epoch : 8\n","Training loss: 0.7402, Training accuracy: 74.5956, Val loss: 0.7960, Val accuracy: 72.9134, \n","\n","Epoch : 9\n","Training loss: 0.7096, Training accuracy: 75.5841, Val loss: 0.7697, Val accuracy: 73.8232, \n","\n","Epoch : 10\n","Training loss: 0.6778, Training accuracy: 76.9718, Val loss: 0.7395, Val accuracy: 74.4858, \n","\n","Epoch : 11\n","Training loss: 0.6541, Training accuracy: 77.8979, Val loss: 0.7255, Val accuracy: 74.5055, \n","\n","Epoch : 12\n","Training loss: 0.6453, Training accuracy: 78.4844, Val loss: 0.7003, Val accuracy: 75.9494, \n","\n","Epoch : 13\n","Training loss: 0.6264, Training accuracy: 79.5003, Val loss: 0.6980, Val accuracy: 76.4043, \n","\n","Epoch : 14\n","Training loss: 0.6115, Training accuracy: 80.3514, Val loss: 0.6912, Val accuracy: 76.4933, \n","\n","Epoch : 15\n","Training loss: 0.6049, Training accuracy: 80.2241, Val loss: 0.6788, Val accuracy: 76.5131, \n","\n","Epoch : 16\n","Training loss: 0.5902, Training accuracy: 80.9405, Val loss: 0.6820, Val accuracy: 76.6614, \n","\n","Epoch : 17\n","Training loss: 0.5849, Training accuracy: 81.1951, Val loss: 0.6778, Val accuracy: 77.0273, \n","\n","Epoch : 18\n","Training loss: 0.5786, Training accuracy: 81.6593, Val loss: 0.6662, Val accuracy: 76.8592, \n","Epoch : 19\n","Training loss: 0.5664, Training accuracy: 82.1261, Val loss: 0.6587, Val accuracy: 77.3042, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5239, Training accuracy: 84.1379, Val loss: 0.6140, Val accuracy: 79.1139, \n","\n","Epoch : 21\n","Training loss: 0.5110, Training accuracy: 84.5547, Val loss: 0.6157, Val accuracy: 79.3513, \n","\n","Epoch : 22\n","Training loss: 0.5059, Training accuracy: 84.8717, Val loss: 0.6003, Val accuracy: 79.1040, \n","Epoch : 23\n","Training loss: 0.5020, Training accuracy: 84.9141, Val loss: 0.6018, Val accuracy: 79.0051, \n","Epoch : 24\n","Training loss: 0.5017, Training accuracy: 85.0589, Val loss: 0.5966, Val accuracy: 78.7876, \n","Epoch : 25\n","Training loss: 0.4956, Training accuracy: 85.2261, Val loss: 0.5877, Val accuracy: 80.0138, \n","\n","Epoch : 26\n","Training loss: 0.4956, Training accuracy: 85.4682, Val loss: 0.5962, Val accuracy: 79.5194, \n","Epoch : 27\n","Training loss: 0.4954, Training accuracy: 85.3235, Val loss: 0.5942, Val accuracy: 79.5392, \n","Epoch : 28\n","Training loss: 0.4951, Training accuracy: 85.3584, Val loss: 0.5950, Val accuracy: 79.6776, \n","Epoch : 29\n","Training loss: 0.4964, Training accuracy: 85.4707, Val loss: 0.5822, Val accuracy: 79.8260, \n","=\u003e Best: 80.0138\n","lamda = 0.8\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7101, Training accuracy: 36.8535, Val loss: 1.5117, Val accuracy: 45.9652, \n","\n","Epoch : 1\n","Training loss: 1.3690, Training accuracy: 50.4917, Val loss: 1.3302, Val accuracy: 53.4217, \n","\n","Epoch : 2\n","Training loss: 1.1380, Training accuracy: 59.2053, Val loss: 1.0972, Val accuracy: 61.7583, \n","\n","Epoch : 3\n","Training loss: 0.9940, Training accuracy: 64.7439, Val loss: 1.0263, Val accuracy: 64.7844, \n","\n","Epoch : 4\n","Training loss: 0.8941, Training accuracy: 68.0711, Val loss: 0.9041, Val accuracy: 69.3335, \n","\n","Epoch : 5\n","Training loss: 0.8138, Training accuracy: 71.2310, Val loss: 0.8757, Val accuracy: 69.7389, \n","\n","Epoch : 6\n","Training loss: 0.7653, Training accuracy: 73.1929, Val loss: 0.8273, Val accuracy: 71.1531, \n","\n","Epoch : 7\n","Training loss: 0.7272, Training accuracy: 74.5482, Val loss: 0.8042, Val accuracy: 72.5969, \n","\n","Epoch : 8\n","Training loss: 0.6894, Training accuracy: 75.9435, Val loss: 0.7762, Val accuracy: 73.6650, \n","\n","Epoch : 9\n","Training loss: 0.6682, Training accuracy: 77.1291, Val loss: 0.7541, Val accuracy: 74.5847, \n","\n","Epoch : 10\n","Training loss: 0.6581, Training accuracy: 77.6757, Val loss: 0.7324, Val accuracy: 74.6341, \n","\n","Epoch : 11\n","Training loss: 0.6329, Training accuracy: 78.4595, Val loss: 0.7196, Val accuracy: 75.1483, \n","\n","Epoch : 12\n","Training loss: 0.6229, Training accuracy: 78.9487, Val loss: 0.7099, Val accuracy: 75.6131, \n","\n","Epoch : 13\n","Training loss: 0.6100, Training accuracy: 79.5153, Val loss: 0.7110, Val accuracy: 75.7911, \n","\n","Epoch : 14\n","Training loss: 0.5996, Training accuracy: 80.1268, Val loss: 0.6878, Val accuracy: 76.6713, \n","\n","Epoch : 15\n","Training loss: 0.5919, Training accuracy: 80.4163, Val loss: 0.6751, Val accuracy: 77.2547, \n","\n","Epoch : 16\n","Training loss: 0.5816, Training accuracy: 80.7708, Val loss: 0.6650, Val accuracy: 77.1954, \n","Epoch : 17\n","Training loss: 0.5761, Training accuracy: 81.2750, Val loss: 0.6605, Val accuracy: 77.4031, \n","\n","Epoch : 18\n","Training loss: 0.5702, Training accuracy: 81.5071, Val loss: 0.6420, Val accuracy: 77.6800, \n","\n","Epoch : 19\n","Training loss: 0.5646, Training accuracy: 81.6718, Val loss: 0.6512, Val accuracy: 77.6998, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5280, Training accuracy: 83.2418, Val loss: 0.6084, Val accuracy: 79.3809, \n","\n","Epoch : 21\n","Training loss: 0.5188, Training accuracy: 83.6437, Val loss: 0.6200, Val accuracy: 78.4909, \n","Epoch : 22\n","Training loss: 0.5120, Training accuracy: 83.8758, Val loss: 0.6088, Val accuracy: 78.9557, \n","Epoch : 23\n","Training loss: 0.5147, Training accuracy: 83.6861, Val loss: 0.6135, Val accuracy: 78.5898, \n","Epoch : 24\n","Training loss: 0.5095, Training accuracy: 84.0281, Val loss: 0.6031, Val accuracy: 79.5589, \n","\n","Epoch : 25\n","Training loss: 0.5091, Training accuracy: 84.0630, Val loss: 0.6040, Val accuracy: 79.1930, \n","Epoch : 26\n","Training loss: 0.5087, Training accuracy: 84.2028, Val loss: 0.6088, Val accuracy: 79.2524, \n","Epoch : 27\n","Training loss: 0.5084, Training accuracy: 84.0405, Val loss: 0.6063, Val accuracy: 78.9260, \n","Epoch : 28\n","Training loss: 0.5045, Training accuracy: 84.3176, Val loss: 0.5961, Val accuracy: 79.7073, \n","\n","Epoch : 29\n","Training loss: 0.5065, Training accuracy: 84.2352, Val loss: 0.5921, Val accuracy: 79.5787, \n","=\u003e Best: 79.7073\n","0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.13.1\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.7740, Training accuracy: 35.1113, Val loss: 1.6028, Val accuracy: 40.1701, \n","\n","1\n","Training loss: 1.4594, Training accuracy: 47.2918, Val loss: 1.3890, Val accuracy: 49.1001, \n","\n","2\n","Training loss: 1.2607, Training accuracy: 54.8997, Val loss: 1.2454, Val accuracy: 55.2116, \n","\n","3\n","Training loss: 1.1491, Training accuracy: 59.5822, Val loss: 1.1135, Val accuracy: 61.0166, \n","\n","4\n","Training loss: 1.0405, Training accuracy: 63.5358, Val loss: 1.0873, Val accuracy: 62.8857, \n","\n","5\n","Training loss: 0.9663, Training accuracy: 66.5410, Val loss: 0.9643, Val accuracy: 66.3667, \n","\n","6\n","Training loss: 0.8867, Training accuracy: 69.4564, Val loss: 0.9582, Val accuracy: 66.7227, \n","\n","7\n","Training loss: 0.8459, Training accuracy: 70.7768, Val loss: 0.9021, Val accuracy: 68.8093, \n","\n","8\n","Training loss: 0.8079, Training accuracy: 72.1695, Val loss: 0.8762, Val accuracy: 69.8873, \n","\n","9\n","Training loss: 0.7779, Training accuracy: 73.1505, Val loss: 0.8670, Val accuracy: 70.9454, \n","\n","10\n","Training loss: 0.7308, Training accuracy: 74.9875, Val loss: 0.8087, Val accuracy: 72.5771, \n","\n","11\n","Training loss: 0.7062, Training accuracy: 75.8636, Val loss: 0.7734, Val accuracy: 73.1903, \n","\n","12\n","Training loss: 0.7066, Training accuracy: 75.7313, Val loss: 0.7818, Val accuracy: 73.4078, \n","\n","13\n","Training loss: 0.6662, Training accuracy: 77.3662, Val loss: 0.7514, Val accuracy: 75.0297, \n","\n","14\n","Training loss: 0.6406, Training accuracy: 78.1000, Val loss: 0.7369, Val accuracy: 74.8220, \n","15\n","Training loss: 0.6147, Training accuracy: 78.8289, Val loss: 0.7239, Val accuracy: 75.6131, \n","\n","16\n","Training loss: 0.5910, Training accuracy: 79.5178, Val loss: 0.6791, Val accuracy: 77.1460, \n","\n","17\n","Training loss: 0.5864, Training accuracy: 79.6251, Val loss: 0.7253, Val accuracy: 75.7219, \n","18\n","Training loss: 0.5660, Training accuracy: 80.4138, Val loss: 0.7072, Val accuracy: 76.4438, \n","19\n","Training loss: 0.5512, Training accuracy: 80.9130, Val loss: 0.6712, Val accuracy: 77.2251, \n","\n","Current learning rate has decayed to 0.010000\n","20\n","Training loss: 0.4537, Training accuracy: 84.1803, Val loss: 0.6258, Val accuracy: 79.0348, \n","\n","21\n","Training loss: 0.4175, Training accuracy: 85.4133, Val loss: 0.6117, Val accuracy: 79.2722, \n","\n","22\n","Training loss: 0.4053, Training accuracy: 85.7877, Val loss: 0.6079, Val accuracy: 79.6282, \n","\n","23\n","Training loss: 0.3955, Training accuracy: 86.0598, Val loss: 0.6030, Val accuracy: 80.0930, \n","\n","24\n","Training loss: 0.3856, Training accuracy: 86.5241, Val loss: 0.6213, Val accuracy: 79.7271, \n","25\n","Training loss: 0.3783, Training accuracy: 86.6563, Val loss: 0.6016, Val accuracy: 80.2116, \n","\n","26\n","Training loss: 0.3670, Training accuracy: 87.1331, Val loss: 0.6046, Val accuracy: 80.2710, \n","\n","27\n","Training loss: 0.3707, Training accuracy: 86.9334, Val loss: 0.6042, Val accuracy: 80.3699, \n","\n","28\n","Training loss: 0.3609, Training accuracy: 87.3727, Val loss: 0.6099, Val accuracy: 80.2907, \n","29\n","Training loss: 0.3634, Training accuracy: 87.2130, Val loss: 0.6040, Val accuracy: 80.2314, \n","=\u003e Best: 80.3699\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 16:46:21 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:46:24 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:46:29 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.2\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1731\n","baseline churn = 0.1713\n","student accuracy = 0.7805\n","baseline accuracy = 0.8091\n","teacher accuracy = 0.786\n","student wlr = 0.9209370613098145\n","baseline wlr = 1.4342105388641357\n","churn ratio = 1.0105078809106829\n","student good_churn = 0.0629\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0002\n","baseline bad_churn = 0.0004\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 16:46:32 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 16:46:33 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:46:37 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:46:41 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.4\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1707\n","baseline churn = 0.1713\n","student accuracy = 0.7846\n","baseline accuracy = 0.8091\n","teacher accuracy = 0.786\n","student wlr = 1.029687523841858\n","baseline wlr = 1.4342105388641357\n","churn ratio = 0.9964973730297723\n","student good_churn = 0.0659\n","student bad_churn = 0.0\n","baseline good_churn = 0.0002\n","baseline bad_churn = 0.0004\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 16:46:45 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 16:46:45 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:46:49 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:46:53 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.6\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1664\n","baseline churn = 0.1713\n","student accuracy = 0.7817\n","baseline accuracy = 0.8091\n","teacher accuracy = 0.786\n","student wlr = 0.9263157844543457\n","baseline wlr = 1.4342105388641357\n","churn ratio = 0.9713952130764739\n","student good_churn = 0.0616\n","student bad_churn = 0.0002\n","baseline good_churn = 0.0002\n","baseline bad_churn = 0.0004\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 16:46:57 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 16:46:57 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:01 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:05 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","alpha = 0.8\n","\n","\n","\n","Epsilon = 1.0\n","\n","student churn = 0.1748\n","baseline churn = 0.1713\n","student accuracy = 0.7772\n","baseline accuracy = 0.8091\n","teacher accuracy = 0.786\n","student wlr = 0.9553313851356506\n","baseline wlr = 1.4342105388641357\n","churn ratio = 1.0204319906596615\n","student good_churn = 0.0663\n","student bad_churn = 0.0002\n","baseline good_churn = 0.0002\n","baseline bad_churn = 0.0004\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 16:47:09 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 16:47:14 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:18 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:22 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.2\n","\n","student churn = 0.1607\n","baseline churn = 0.17\n","student accuracy = 0.8052\n","baseline accuracy = 0.8096\n","teacher accuracy = 0.7838\n","student wlr = 1.3802281618118286\n","baseline wlr = 1.4886363744735718\n","churn ratio = 0.9452941176470588\n","student good_churn = 0.0726\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 16:47:26 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 16:47:26 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:30 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:34 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.4\n","\n","student churn = 0.149\n","baseline churn = 0.17\n","student accuracy = 0.809\n","baseline accuracy = 0.8096\n","teacher accuracy = 0.7838\n","student wlr = 1.617511510848999\n","baseline wlr = 1.4886363744735718\n","churn ratio = 0.876470588235294\n","student good_churn = 0.0702\n","student bad_churn = 0.0002\n","baseline good_churn = 0.0\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 16:47:38 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 16:47:38 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:42 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:46 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.6\n","\n","student churn = 0.1406\n","baseline churn = 0.17\n","student accuracy = 0.8013\n","baseline accuracy = 0.8096\n","teacher accuracy = 0.7838\n","student wlr = 1.4105960130691528\n","baseline wlr = 1.4886363744735718\n","churn ratio = 0.8270588235294117\n","student good_churn = 0.0639\n","student bad_churn = 0.0\n","baseline good_churn = 0.0\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 16:47:50 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","2022/11/14 16:47:50 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:54 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","2022/11/14 16:47:58 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","lamda = 0.8\n","\n","student churn = 0.1278\n","baseline churn = 0.17\n","student accuracy = 0.7995\n","baseline accuracy = 0.8096\n","teacher accuracy = 0.7838\n","student wlr = 1.3734643459320068\n","baseline wlr = 1.4886363744735718\n","churn ratio = 0.7517647058823529\n","student good_churn = 0.0559\n","student bad_churn = 0.0001\n","baseline good_churn = 0.0\n","baseline bad_churn = 0.0001\n"]},{"name":"stderr","output_type":"stream","text":["2022/11/14 16:48:02 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.13.1+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torchvision==0.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n","Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 0\n","Training loss: 1.8314, Training accuracy: 32.3404, Val loss: 1.6966, Val accuracy: 36.5605, \n","\n","Epoch : 1\n","Training loss: 1.5472, Training accuracy: 43.7245, Val loss: 1.4759, Val accuracy: 46.3014, \n","\n","Epoch : 2\n","Training loss: 1.3676, Training accuracy: 50.8754, Val loss: 1.3462, Val accuracy: 51.9482, \n","\n","Epoch : 3\n","Training loss: 1.2426, Training accuracy: 55.9286, Val loss: 1.2341, Val accuracy: 56.2401, \n","\n","Epoch : 4\n","Training loss: 1.1425, Training accuracy: 59.9080, Val loss: 1.1136, Val accuracy: 61.3034, \n","\n","Epoch : 5\n","Training loss: 1.0646, Training accuracy: 63.0452, Val loss: 1.0783, Val accuracy: 62.2330, \n","\n","Epoch : 6\n","Training loss: 1.0252, Training accuracy: 64.2797, Val loss: 1.1144, Val accuracy: 61.2836, \n","Epoch : 7\n","Training loss: 0.9534, Training accuracy: 66.7952, Val loss: 1.0006, Val accuracy: 65.3877, \n","\n","Epoch : 8\n","Training loss: 0.9027, Training accuracy: 68.5173, Val loss: 0.9237, Val accuracy: 67.4842, \n","\n","Epoch : 9\n","Training loss: 0.8714, Training accuracy: 69.7584, Val loss: 0.9087, Val accuracy: 68.4632, \n","\n","Epoch : 10\n","Training loss: 0.8284, Training accuracy: 71.3752, Val loss: 0.9150, Val accuracy: 69.1851, \n","\n","Epoch : 11\n","Training loss: 0.8219, Training accuracy: 71.5215, Val loss: 0.8926, Val accuracy: 69.2049, \n","\n","Epoch : 12\n","Training loss: 0.7742, Training accuracy: 73.3887, Val loss: 0.8464, Val accuracy: 70.6982, \n","\n","Epoch : 13\n","Training loss: 0.7450, Training accuracy: 74.3163, Val loss: 0.8066, Val accuracy: 71.9838, \n","\n","Epoch : 14\n","Training loss: 0.7366, Training accuracy: 74.4803, Val loss: 0.8186, Val accuracy: 71.5882, \n","Epoch : 15\n","Training loss: 0.7075, Training accuracy: 75.6150, Val loss: 0.8160, Val accuracy: 72.4387, \n","\n","Epoch : 16\n","Training loss: 0.6945, Training accuracy: 76.1569, Val loss: 0.8709, Val accuracy: 70.6784, \n","Epoch : 17\n","Training loss: 0.6965, Training accuracy: 75.8887, Val loss: 0.8147, Val accuracy: 72.4189, \n","Epoch : 18\n","Training loss: 0.6557, Training accuracy: 77.4490, Val loss: 0.8063, Val accuracy: 72.9826, \n","\n","Epoch : 19\n","Training loss: 0.6364, Training accuracy: 78.2236, Val loss: 0.7887, Val accuracy: 73.7540, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5403, Training accuracy: 81.1724, Val loss: 0.6811, Val accuracy: 76.9284, \n","\n","Epoch : 21\n","Training loss: 0.4935, Training accuracy: 82.5787, Val loss: 0.7010, Val accuracy: 76.4438, \n","Epoch : 22\n","Training loss: 0.4797, Training accuracy: 83.3621, Val loss: 0.6808, Val accuracy: 77.1163, \n","\n","Epoch : 23\n","Training loss: 0.4607, Training accuracy: 83.7079, Val loss: 0.6890, Val accuracy: 77.1559, \n","\n","Epoch : 24\n","Training loss: 0.4571, Training accuracy: 83.8542, Val loss: 0.6593, Val accuracy: 77.6899, \n","\n","Epoch : 25\n","Training loss: 0.4445, Training accuracy: 84.3706, Val loss: 0.6622, Val accuracy: 77.5811, \n","Epoch : 26\n","Training loss: 0.4466, Training accuracy: 84.2343, Val loss: 0.6638, Val accuracy: 77.6305, \n","Epoch : 27\n","Training loss: 0.4337, Training accuracy: 84.8349, Val loss: 0.6627, Val accuracy: 78.4415, \n","\n","Epoch : 28\n","Training loss: 0.4262, Training accuracy: 84.9723, Val loss: 0.6692, Val accuracy: 77.6503, \n","Epoch : 29\n","Training loss: 0.4248, Training accuracy: 85.0166, Val loss: 0.6653, Val accuracy: 78.1547, \n","=\u003e Best: 78.4415\n","alpha = 0.2\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8465, Training accuracy: 31.5869, Val loss: 1.6250, Val accuracy: 39.0922, \n","\n","Epoch : 1\n","Training loss: 1.5772, Training accuracy: 42.7460, Val loss: 1.5267, Val accuracy: 44.0368, \n","\n","Epoch : 2\n","Training loss: 1.4252, Training accuracy: 49.0193, Val loss: 1.3409, Val accuracy: 51.6218, \n","\n","Epoch : 3\n","Training loss: 1.2850, Training accuracy: 54.6554, Val loss: 1.2118, Val accuracy: 57.8224, \n","\n","Epoch : 4\n","Training loss: 1.1705, Training accuracy: 59.1090, Val loss: 1.1739, Val accuracy: 58.9893, \n","\n","Epoch : 5\n","Training loss: 1.0807, Training accuracy: 62.6939, Val loss: 1.1224, Val accuracy: 60.8584, \n","\n","Epoch : 6\n","Training loss: 1.0152, Training accuracy: 65.4311, Val loss: 0.9963, Val accuracy: 65.0119, \n","\n","Epoch : 7\n","Training loss: 0.9592, Training accuracy: 67.1664, Val loss: 0.9850, Val accuracy: 65.3184, \n","\n","Epoch : 8\n","Training loss: 0.9141, Training accuracy: 68.8198, Val loss: 0.9454, Val accuracy: 67.6523, \n","\n","Epoch : 9\n","Training loss: 0.8664, Training accuracy: 70.4610, Val loss: 0.9259, Val accuracy: 67.8896, \n","\n","Epoch : 10\n","Training loss: 0.8257, Training accuracy: 72.0080, Val loss: 0.8826, Val accuracy: 69.8279, \n","\n","Epoch : 11\n","Training loss: 0.7931, Training accuracy: 73.2724, Val loss: 0.8584, Val accuracy: 70.0356, \n","\n","Epoch : 12\n","Training loss: 0.7565, Training accuracy: 74.4637, Val loss: 0.8404, Val accuracy: 71.1234, \n","\n","Epoch : 13\n","Training loss: 0.7439, Training accuracy: 74.8648, Val loss: 0.8618, Val accuracy: 70.5795, \n","Epoch : 14\n","Training loss: 0.7224, Training accuracy: 75.6826, Val loss: 0.8212, Val accuracy: 71.8058, \n","\n","Epoch : 15\n","Training loss: 0.6906, Training accuracy: 77.0013, Val loss: 0.7710, Val accuracy: 73.9616, \n","\n","Epoch : 16\n","Training loss: 0.6694, Training accuracy: 77.5931, Val loss: 0.8130, Val accuracy: 72.2409, \n","Epoch : 17\n","Training loss: 0.6553, Training accuracy: 78.2569, Val loss: 0.7607, Val accuracy: 74.0407, \n","\n","Epoch : 18\n","Training loss: 0.6360, Training accuracy: 78.8708, Val loss: 0.7537, Val accuracy: 74.5451, \n","\n","Epoch : 19\n","Training loss: 0.6187, Training accuracy: 79.2409, Val loss: 0.7441, Val accuracy: 75.0198, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5243, Training accuracy: 83.3355, Val loss: 0.6856, Val accuracy: 76.7900, \n","\n","Epoch : 21\n","Training loss: 0.4949, Training accuracy: 83.8963, Val loss: 0.6687, Val accuracy: 77.0075, \n","\n","Epoch : 22\n","Training loss: 0.4824, Training accuracy: 84.3318, Val loss: 0.6627, Val accuracy: 77.5316, \n","\n","Epoch : 23\n","Training loss: 0.4768, Training accuracy: 84.8615, Val loss: 0.6623, Val accuracy: 77.7097, \n","\n","Epoch : 24\n","Training loss: 0.4637, Training accuracy: 85.3158, Val loss: 0.6624, Val accuracy: 77.6602, \n","Epoch : 25\n","Training loss: 0.4575, Training accuracy: 85.2815, Val loss: 0.6570, Val accuracy: 77.7294, \n","\n","Epoch : 26\n","Training loss: 0.4556, Training accuracy: 85.5097, Val loss: 0.6492, Val accuracy: 78.2536, \n","\n","Epoch : 27\n","Training loss: 0.4449, Training accuracy: 85.8189, Val loss: 0.6491, Val accuracy: 78.4316, \n","\n","Epoch : 28\n","Training loss: 0.4434, Training accuracy: 85.8599, Val loss: 0.6458, Val accuracy: 78.2437, \n","Epoch : 29\n","Training loss: 0.4393, Training accuracy: 86.2312, Val loss: 0.6422, Val accuracy: 78.6294, \n","\n","=\u003e Best: 78.6294\n","alpha = 0.4\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8247, Training accuracy: 32.8480, Val loss: 1.6441, Val accuracy: 37.8659, \n","\n","Epoch : 1\n","Training loss: 1.5329, Training accuracy: 44.3163, Val loss: 1.4330, Val accuracy: 48.5067, \n","\n","Epoch : 2\n","Training loss: 1.3530, Training accuracy: 51.6611, Val loss: 1.3213, Val accuracy: 52.3339, \n","\n","Epoch : 3\n","Training loss: 1.2226, Training accuracy: 57.6164, Val loss: 1.2473, Val accuracy: 56.5763, \n","\n","Epoch : 4\n","Training loss: 1.1340, Training accuracy: 61.1370, Val loss: 1.1322, Val accuracy: 60.7199, \n","\n","Epoch : 5\n","Training loss: 1.0448, Training accuracy: 64.4459, Val loss: 1.0518, Val accuracy: 62.7373, \n","\n","Epoch : 6\n","Training loss: 1.0075, Training accuracy: 65.8688, Val loss: 0.9995, Val accuracy: 65.2393, \n","\n","Epoch : 7\n","Training loss: 0.9447, Training accuracy: 68.2535, Val loss: 0.9638, Val accuracy: 66.1986, \n","\n","Epoch : 8\n","Training loss: 0.9430, Training accuracy: 68.3500, Val loss: 0.9444, Val accuracy: 67.0392, \n","\n","Epoch : 9\n","Training loss: 0.9062, Training accuracy: 69.8227, Val loss: 0.9330, Val accuracy: 67.6424, \n","\n","Epoch : 10\n","Training loss: 0.9166, Training accuracy: 69.2963, Val loss: 0.9247, Val accuracy: 67.8303, \n","\n","Epoch : 11\n","Training loss: 0.8400, Training accuracy: 72.2861, Val loss: 0.8754, Val accuracy: 70.0455, \n","\n","Epoch : 12\n","Training loss: 0.7854, Training accuracy: 74.2775, Val loss: 0.8221, Val accuracy: 71.7365, \n","\n","Epoch : 13\n","Training loss: 0.7481, Training accuracy: 75.5463, Val loss: 0.8521, Val accuracy: 71.7563, \n","\n","Epoch : 14\n","Training loss: 0.7275, Training accuracy: 76.2699, Val loss: 0.7818, Val accuracy: 72.9529, \n","\n","Epoch : 15\n","Training loss: 0.7056, Training accuracy: 77.2108, Val loss: 0.7588, Val accuracy: 74.0704, \n","\n","Epoch : 16\n","Training loss: 0.6842, Training accuracy: 78.1959, Val loss: 0.7476, Val accuracy: 74.5649, \n","\n","Epoch : 17\n","Training loss: 0.6748, Training accuracy: 78.4940, Val loss: 0.7671, Val accuracy: 73.4474, \n","Epoch : 18\n","Training loss: 0.6508, Training accuracy: 79.2531, Val loss: 0.7487, Val accuracy: 74.1792, \n","Epoch : 19\n","Training loss: 0.6391, Training accuracy: 79.7983, Val loss: 0.7470, Val accuracy: 74.9604, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5526, Training accuracy: 83.1704, Val loss: 0.6613, Val accuracy: 77.3042, \n","\n","Epoch : 21\n","Training loss: 0.5243, Training accuracy: 84.2287, Val loss: 0.6370, Val accuracy: 78.5404, \n","\n","Epoch : 22\n","Training loss: 0.5143, Training accuracy: 84.6509, Val loss: 0.6362, Val accuracy: 78.1151, \n","Epoch : 23\n","Training loss: 0.5095, Training accuracy: 84.8659, Val loss: 0.6480, Val accuracy: 77.9173, \n","Epoch : 24\n","Training loss: 0.5032, Training accuracy: 85.0022, Val loss: 0.6457, Val accuracy: 78.1942, \n","Epoch : 25\n","Training loss: 0.4915, Training accuracy: 85.5519, Val loss: 0.6336, Val accuracy: 78.4316, \n","Epoch : 26\n","Training loss: 0.4895, Training accuracy: 85.5120, Val loss: 0.6346, Val accuracy: 78.2140, \n","Epoch : 27\n","Training loss: 0.4844, Training accuracy: 85.6549, Val loss: 0.6262, Val accuracy: 78.7678, \n","\n","Epoch : 28\n","Training loss: 0.4834, Training accuracy: 85.7735, Val loss: 0.6391, Val accuracy: 78.2437, \n","Epoch : 29\n","Training loss: 0.4803, Training accuracy: 86.0361, Val loss: 0.6378, Val accuracy: 77.9964, \n","=\u003e Best: 78.7678\n","alpha = 0.6\n","epsilon = 1.0\n","Epoch : 0\n"]},{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]},{"name":"stdout","output_type":"stream","text":["Training loss: 1.8303, Training accuracy: 33.2702, Val loss: 1.6606, Val accuracy: 39.3097, \n","\n","Epoch : 1\n","Training loss: 1.5680, Training accuracy: 43.7677, Val loss: 1.5388, Val accuracy: 42.5534, \n","\n","Epoch : 2\n","Training loss: 1.4021, Training accuracy: 50.1496, Val loss: 1.3237, Val accuracy: 51.5131, \n","\n","Epoch : 3\n","Training loss: 1.2622, Training accuracy: 56.2555, Val loss: 1.2771, Val accuracy: 54.3414, \n","\n","Epoch : 4\n","Training loss: 1.1710, Training accuracy: 59.8969, Val loss: 1.1399, Val accuracy: 59.4937, \n","\n","Epoch : 5\n","Training loss: 1.0915, Training accuracy: 62.7914, Val loss: 1.0849, Val accuracy: 62.2231, \n","\n","Epoch : 6\n","Training loss: 1.0342, Training accuracy: 65.2083, Val loss: 1.0394, Val accuracy: 64.2306, \n","\n","Epoch : 7\n","Training loss: 0.9799, Training accuracy: 67.0512, Val loss: 0.9740, Val accuracy: 65.2097, \n","\n","Epoch : 8\n","Training loss: 0.9281, Training accuracy: 69.4060, Val loss: 0.9568, Val accuracy: 66.3074, \n","\n","Epoch : 9\n","Training loss: 0.8914, Training accuracy: 70.8976, Val loss: 0.9202, Val accuracy: 68.0874, \n","\n","Epoch : 10\n","Training loss: 0.8672, Training accuracy: 71.8894, Val loss: 0.8888, Val accuracy: 69.3532, \n","\n","Epoch : 11\n","Training loss: 0.8327, Training accuracy: 72.9255, Val loss: 0.8688, Val accuracy: 69.9763, \n","\n","Epoch : 12\n","Training loss: 0.8087, Training accuracy: 73.7988, Val loss: 0.8454, Val accuracy: 71.1333, \n","\n","Epoch : 13\n","Training loss: 0.7816, Training accuracy: 74.9368, Val loss: 0.8404, Val accuracy: 70.7971, \n","Epoch : 14\n","Training loss: 0.7648, Training accuracy: 75.8588, Val loss: 0.8071, Val accuracy: 71.7267, \n","\n","Epoch : 15\n","Training loss: 0.7428, Training accuracy: 76.8517, Val loss: 0.7759, Val accuracy: 72.8343, \n","\n","Epoch : 16\n","Training loss: 0.7247, Training accuracy: 77.1387, Val loss: 0.7733, Val accuracy: 73.3979, \n","\n","Epoch : 17\n","Training loss: 0.7076, Training accuracy: 77.8879, Val loss: 0.7611, Val accuracy: 74.2385, \n","\n","Epoch : 18\n","Training loss: 0.6955, Training accuracy: 78.2757, Val loss: 0.7647, Val accuracy: 73.7045, \n","Epoch : 19\n","Training loss: 0.6718, Training accuracy: 79.5235, Val loss: 0.7331, Val accuracy: 74.7528, \n","\n","Epoch : 20\n","Current learning rate has decayed to 0.010000\n","Training loss: 0.5969, Training accuracy: 82.8092, Val loss: 0.6566, Val accuracy: 77.5119, \n","\n","Epoch : 21\n","Training loss: 0.5658, Training accuracy: 83.6968, Val loss: 0.6615, Val accuracy: 77.5316, \n","\n","Epoch : 22\n","Training loss: 0.5569, Training accuracy: 84.0270, Val loss: 0.6551, Val accuracy: 77.3734, \n","Epoch : 23\n","Training loss: 0.5507, Training accuracy: 84.4382, Val loss: 0.6581, Val accuracy: 78.2239, \n","\n","Epoch : 24\n","Training loss: 0.5477, Training accuracy: 84.6598, Val loss: 0.6442, Val accuracy: 77.8481, \n","Epoch : 25\n","Training loss: 0.5439, Training accuracy: 84.6432, Val loss: 0.6509, Val accuracy: 77.4822, \n","Epoch : 26\n"]}],"source":["with mlflow.start_run(run_name=\"Ten Runs\"):\n","    for run_no in range(10):\n","        teacher_model = teacher_chunk()\n","        rcp_models = student_chunk_rcp(teacher_model)\n","        dist_models = student_chunk_dist(teacher_model)\n","        base_model = baseline_chunk()\n","        metric_chunk_rcp(teacher_model, base_model, run_no)\n","        metric_chunk_dist(teacher_model, base_model, run_no)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hr3CCN6yYy8m"},"outputs":[],"source":["while True:\n","  a=torch.Tensor([1,2,3,4,5])\n","  a.cuda()\n","  a=a*2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"j2uFyrAN1mCv"},"outputs":[],"source":["!pip3 install pyngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"n5cQMoYP1k7D"},"outputs":[],"source":["\n","from pyngrok import ngrok\n","#Terminate open tunnels if exist\n","ngrok.kill()\n","\n","#Setting the authtoken (optional)\n","#Get your authtoken from https://dashboard.ngrok.com/auth\n","NGROK_AUTH_TOKEN = \"2HBNx1D7YdjGMMU5LPQQLxcTHeP_2GMdqwVRUMHyfftBwD9WV\"\n","ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n","\n","#Open an HTTPs tunnel on port 5000 for http://localhost:5000\n","ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n","print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9bOiF0zKSomS"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2022-11-14 17:48:07 +0000] [58408] [INFO] Starting gunicorn 20.1.0\n","[2022-11-14 17:48:07 +0000] [58408] [INFO] Listening at: http://127.0.0.1:5000 (58408)\n","[2022-11-14 17:48:07 +0000] [58408] [INFO] Using worker: sync\n","[2022-11-14 17:48:07 +0000] [58411] [INFO] Booting worker with pid: 58411\n"]}],"source":["!mlflow ui"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"","version":""},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5b8af75da8244ce18b653a495d0d5477":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc9490875b7244f2b9b53cacc2e84a35","placeholder":"​","style":"IPY_MODEL_974277dba95b41d5b547ed61571254b1","value":"100%"}},"5d54ea54511b47309d18485b6b66e42f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3a38c53a6024b6f85222d282efc8c9a","placeholder":"​","style":"IPY_MODEL_901b305933d8439baf678c0e33e0ee70","value":" 170498071/170498071 [00:13\u0026lt;00:00, 13588240.50it/s]"}},"7df2f150eb0c4641be62c7ffc79d0d6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"901b305933d8439baf678c0e33e0ee70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"974277dba95b41d5b547ed61571254b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1bdb419db274700a36eb28d26557641":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3a38c53a6024b6f85222d282efc8c9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c41c59e7a5134d598c32c2301b432382":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b8af75da8244ce18b653a495d0d5477","IPY_MODEL_d3d10804597d4a63aaf4388bebee8871","IPY_MODEL_5d54ea54511b47309d18485b6b66e42f"],"layout":"IPY_MODEL_b1bdb419db274700a36eb28d26557641"}},"d3d10804597d4a63aaf4388bebee8871":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea2fa5a809e74919a8c3df1daf7960e1","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7df2f150eb0c4641be62c7ffc79d0d6f","value":170498071}},"dc9490875b7244f2b9b53cacc2e84a35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea2fa5a809e74919a8c3df1daf7960e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}